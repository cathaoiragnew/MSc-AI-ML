{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "6_PCA_Manual_Train_Test_HandCraft_Thesis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrVWaVNkPW2k"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDjv2eMjASXA"
      },
      "source": [
        "#!pip install imbalanced-learn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtX5iMQHPDII"
      },
      "source": [
        "\n",
        "########################### (https://github.com/curiousily/TensorFlow-on-Android-for-Human-Activity-Recognition-with-LSTMs/blob/master/human_activity_recognition.ipynb) imports\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "from scipy import stats\n",
        "import tensorflow as tf\n",
        "import seaborn as sns\n",
        "from pylab import rcParams\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "%matplotlib inline\n",
        "sns.set(style='whitegrid', palette='muted', font_scale=1.5)\n",
        "rcParams['figure.figsize'] = 14, 8\n",
        "RANDOM_SEED = 42\n",
        "\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from collections import Counter\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "from matplotlib.pyplot import figure\n",
        "\n",
        "from sklearn.metrics import accuracy_score, log_loss\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.linear_model import PassiveAggressiveClassifier\n",
        "from sklearn.semi_supervised import LabelPropagation\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.tree import ExtraTreeClassifier\n",
        "\n",
        "from sklearn.decomposition import PCA"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_M5F5DwPrKk"
      },
      "source": [
        "# Upload Data \n",
        "\n",
        "---------------------------------\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZX9OGsWPzvD"
      },
      "source": [
        "Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IyDYp-eLY8K"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded_signal_train = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "juXPVt1AP0v1"
      },
      "source": [
        "Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDlYInx_Pyx5"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded_signal_test = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFIL8q5nvqUf"
      },
      "source": [
        "### Reading in segments & labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y70o5U5mSOUU"
      },
      "source": [
        "Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxXU40eBttE6"
      },
      "source": [
        "# getting keys, which is file names of npy \n",
        "list_of_dataframes_train = [key for key in uploaded_signal_train.keys()]\n",
        "\n",
        "\n",
        "# set up list to hold all loaded npy \n",
        "all_dataframe_train = [] \n",
        "\n",
        "\n",
        "for i in range(len(list_of_dataframes_train)):\n",
        "\n",
        "    # load in the data \n",
        "    dataframe_train = pd.read_csv(list_of_dataframes_train[i])\n",
        "\n",
        "\n",
        "    # append the data to 'all' list\n",
        "    all_dataframe_train.append(dataframe_train) \n",
        "\n",
        "\n",
        "all_df_train = pd.concat(all_dataframe_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXzYX7vVSPqK"
      },
      "source": [
        "Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4s9Wo8YGSQeN"
      },
      "source": [
        "# getting keys, which is file names of npy \n",
        "list_of_dataframes_test = [key for key in uploaded_signal_test.keys()]\n",
        "\n",
        "\n",
        "# set up list to hold all loaded npy \n",
        "all_dataframe_test = [] \n",
        "\n",
        "\n",
        "for i in range(len(list_of_dataframes_test)):\n",
        "\n",
        "    # load in the data \n",
        "    dataframe_test = pd.read_csv(list_of_dataframes_test[i])\n",
        "\n",
        "\n",
        "    # append the data to 'all' list\n",
        "    all_dataframe_test.append(dataframe_test) \n",
        "\n",
        "\n",
        "all_df_test = pd.concat(all_dataframe_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8jsSnExgGesF"
      },
      "source": [
        "# Quick Look "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCEZ0lTrGiz3"
      },
      "source": [
        "all_df_train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJ-KTwnDGhYv"
      },
      "source": [
        "all_df_test.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVPv0iQ6SPeH"
      },
      "source": [
        "# Train Test Split "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlyxtKg4SRMP"
      },
      "source": [
        "# Getting X_train & y_train'\n",
        "X_train = all_df_train.drop(['Unnamed: 0' , 'Label_segment' , 'Participant_ID' , 'Participant_Run', 'X_Acc_Move_FFT_EnergyBands', \t'Y_Acc_Move_FFT_EnergyBands', \t'Z_Acc_Move_FFT_EnergyBands'\t], axis = 1)\n",
        "y_train = all_df_train['Label_segment'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyOL-dTlTDbw"
      },
      "source": [
        "# Getting X_train & y_train\n",
        "X_test = all_df_test.drop(['Unnamed: 0' , 'Label_segment' , 'Participant_ID' , 'Participant_Run',  'X_Acc_Move_FFT_EnergyBands', \t'Y_Acc_Move_FFT_EnergyBands', \t'Z_Acc_Move_FFT_EnergyBands'], axis = 1)\n",
        "y_test = all_df_test['Label_segment'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vM6doFdbvla"
      },
      "source": [
        "---------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tVnwD0csNgw"
      },
      "source": [
        "Standard Scale "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFhyhbcjsO7K"
      },
      "source": [
        "# Set up ss for non-shuffled data\n",
        "ss = StandardScaler()\n",
        "\n",
        "\n",
        "# fit train & transform test\n",
        "X_train_scale = ss.fit_transform(X_train)\n",
        "X_test_scale = ss.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bpApWRNA4f0"
      },
      "source": [
        "-----------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Q9ED2cpU9UY"
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# PCA set for 95% of variance \n",
        "pca = PCA(n_components=0.95)\n",
        "\n",
        "pca.fit(X_train_scale)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7RRf43cVU1X"
      },
      "source": [
        "# PCA set for 95% of variance  \n",
        "\n",
        "X_train_scale_pca = pca.transform(X_train_scale)\n",
        "X_test_scale_pca = pca.transform(X_test_scale)\n",
        "\n",
        "# quick print of shapes to see difference\n",
        "print(f'Train data:\\nBefore pca shape: {X_train_scale.shape} , after pca applied: {X_train_scale_pca.shape} ')\n",
        "print(f'\\nTest data:\\nBefore pca shape: {X_test_scale.shape} , after pca applied: {X_test_scale_pca.shape} ')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AY2CvefFA3Pd"
      },
      "source": [
        "Check if SMOTE helps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ivu4MogoA3Pe"
      },
      "source": [
        "print(Counter(y_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iIID62gA3Pf"
      },
      "source": [
        "# transform the dataset\n",
        "oversample = SMOTE()\n",
        "X_train_scale_smote, y_train_smote = oversample.fit_resample(X_train_scale_pca, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCzRxVv6A3Ph"
      },
      "source": [
        "print(Counter(y_train_smote))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMdoaGkNWjTL"
      },
      "source": [
        "# quick print of shapes to see difference\n",
        "print(f'Train data:\\nBefore pca shape: {X_train_scale.shape} , after pca applied: {X_train_scale_smote.shape} ')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZSss6u0jQN_"
      },
      "source": [
        "----------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cgzUsp7ZvsfE"
      },
      "source": [
        "# PCA - No SMOTE \n",
        "\n",
        "Check Some Classifiers "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nu9bDnSz3bZl"
      },
      "source": [
        "\n",
        "import time\n",
        "from sklearn.metrics import accuracy_score, log_loss , recall_score , f1_score, precision_score , roc_auc_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.linear_model import PassiveAggressiveClassifier , LogisticRegression\n",
        "from sklearn.semi_supervised import LabelPropagation\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.tree import ExtraTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "classifiers = [\n",
        "               \n",
        "    # Too much computation to run now since using entire data and not segmenting on location \n",
        "    ##KNeighborsClassifier(),\n",
        "    ##GradientBoostingClassifier(),\n",
        "    ##LabelPropagation(),\n",
        "    # DecisionTreeClassifier(),\n",
        "    # RandomForestClassifier(),\n",
        "    # AdaBoostClassifier(),\n",
        "    # GaussianNB(),\n",
        "    # LinearDiscriminantAnalysis(),\n",
        "    # QuadraticDiscriminantAnalysis(),\n",
        "    # LinearSVC(),\n",
        "    # SGDClassifier(),\n",
        "    # MLPClassifier(),\n",
        "    # PassiveAggressiveClassifier(),\n",
        "    # ExtraTreesClassifier(),\n",
        "    # BaggingClassifier(),\n",
        "\n",
        "    DecisionTreeClassifier(criterion = 'entropy' , max_depth = 10 , min_samples_leaf = 8 , min_samples_split = 3  ),\n",
        "    MLPClassifier(hidden_layer_sizes = (50, 20) , activation = 'tanh' , solver = 'adam' , alpha = 0.01 , learning_rate = 'adaptive' ),\n",
        "    LogisticRegression(C = 1 , multi_class = 'multinomial' , penalty = 'l2' , solver = 'newton-cg' )\n",
        "\n",
        "\n",
        "  \n",
        "    \n",
        "     ]\n",
        "\n",
        "\n",
        "# list to hold for dataframe\n",
        "classifier_name_list = []\n",
        "train_acc_list = []\n",
        "train_bacc_list = []\n",
        "test_acc_list = []\n",
        "test_bacc_list = []\n",
        "train_recall_list = []\n",
        "test_recall_list = []\n",
        "train_precision_list = []\n",
        "test_precision_list = []\n",
        "train_f1_list = []\n",
        "test_f1_list = []\n",
        "training_timing = [] \n",
        "training_pred_timing = [] \n",
        "testing_pred_timing = [] \n",
        "\n",
        "\n",
        "for clf in classifiers:\n",
        "\n",
        "    name = clf.__class__.__name__\n",
        "    \n",
        "    print(\"=\"*50)\n",
        "    print(name)\n",
        "\n",
        "    # just for timing model\n",
        "    training_time0 = time.time()\n",
        "\n",
        "\n",
        "    ################### This changes across runs ####################################################\n",
        "    clf.fit(X_train_scale_pca, y_train)\n",
        "\n",
        "    # finished training \n",
        "    training_time1 = time.time()\n",
        "\n",
        "    training_time = training_time1 - training_time0 \n",
        "    \n",
        "    print('****Results****')\n",
        "\n",
        "    # just for timing model\n",
        "    test_time0 = time.time()\n",
        "    # Test Predictions\n",
        "\n",
        "    ################### This changes across runs ####################################################\n",
        "    test_predictions = clf.predict(X_test_scale_pca)\n",
        "    # just for timing model\n",
        "    test_time1 = time.time()\n",
        "\n",
        "    test_time = test_time1 - test_time0\n",
        "\n",
        "\n",
        "    # Test Metrics\n",
        "    acc            = accuracy_score(y_test, test_predictions)\n",
        "    bal_acc        = balanced_accuracy_score(y_test, test_predictions)\n",
        "    recall_test    = recall_score(y_test, test_predictions, average = 'weighted')\n",
        "    f1_test        = f1_score(y_test, test_predictions ,  average = 'weighted')\n",
        "    precision_test = precision_score(y_test, test_predictions,  average = 'weighted') \n",
        "\n",
        "\n",
        "    # just for timing model\n",
        "    training_p_time0 = time.time()\n",
        "\n",
        "    # Train Predictions\n",
        "\n",
        "    ################### This changes across runs ####################################################\n",
        "    train_predictions = clf.predict(X_train_scale_pca)\n",
        "\n",
        "    # just for timing model\n",
        "    training_p_time1 = time.time()\n",
        "\n",
        "    training_p_time = training_p_time1 - training_p_time0\n",
        "\n",
        "    # Train Metrics\n",
        "\n",
        "    ################### This changes across runs ####################################################\n",
        "    train_acc       = accuracy_score(y_train, train_predictions)\n",
        "    train_bal_acc   = balanced_accuracy_score(y_train, train_predictions)\n",
        "    recall_train    = recall_score(y_train, train_predictions , average = 'weighted')\n",
        "    f1_train        = f1_score(y_train, train_predictions ,  average = 'weighted')\n",
        "    precision_train = precision_score(y_train, train_predictions,  average = 'weighted') \n",
        "\n",
        "    print(\"\\n\\nTest Classification Report\\n\")\n",
        "    print(classification_report(y_test, test_predictions))\n",
        "\n",
        "\n",
        "    # append to list to make a dataframe \n",
        "    classifier_name_list.append(name)\n",
        "    \n",
        "    training_timing.append(training_time)\n",
        "    training_pred_timing.append(training_p_time)\n",
        "    testing_pred_timing.append(test_time)\n",
        "\n",
        "\n",
        "    train_acc_list.append(train_acc)\n",
        "    test_acc_list.append(acc)\n",
        "\n",
        "    train_bacc_list.append(train_bal_acc)\n",
        "    test_bacc_list.append(bal_acc)\n",
        "\n",
        "    train_recall_list.append(recall_train)\n",
        "    test_recall_list.append(recall_test)\n",
        "\n",
        "    train_precision_list.append(precision_train)\n",
        "    test_precision_list.append(precision_test)\n",
        "\n",
        "    train_f1_list.append(f1_train)\n",
        "    test_f1_list.append(f1_test)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"=\"*50)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvJWRblfuUEh"
      },
      "source": [
        "train_metrics_df = pd.DataFrame()\n",
        "test_metrics_df = pd.DataFrame()\n",
        "\n",
        "\n",
        "train_metrics_df['Classifier'] = classifier_name_list\n",
        "test_metrics_df['Classifier'] = classifier_name_list\n",
        "\n",
        "\n",
        "# F1 Score First \n",
        "train_metrics_df['Train F1'] = train_f1_list\n",
        "test_metrics_df['Test F1'] = test_f1_list \n",
        "\n",
        "# Recall\n",
        "train_metrics_df['Train Recall'] = train_recall_list\n",
        "test_metrics_df['Test Recall'] = test_recall_list\n",
        "\n",
        "# Precision \n",
        "train_metrics_df['Train Precision'] = train_precision_list\n",
        "test_metrics_df['Test Precision'] = test_precision_list\n",
        "\n",
        "# Bal Acc\n",
        "train_metrics_df['Train Balanced Accuracy'] = train_bacc_list\n",
        "test_metrics_df['Test Balanced Accuracy'] = test_bacc_list\n",
        "\n",
        "# Accuracy \n",
        "train_metrics_df['Train Accuracy'] = train_acc_list\n",
        "test_metrics_df['Test Accuracy'] = test_acc_list \n",
        "\n",
        "\n",
        "#train_metrics_df.sort_values(\"Train F1\" , ascending=False , inplace=True)\n",
        "train_metrics_df.set_index('Classifier' , inplace=True)\n",
        "\n",
        "#test_metrics_df.sort_values(\"Test F1\" , ascending=False , inplace=True)\n",
        "test_metrics_df.set_index('Classifier' , inplace=True)\n",
        "\n",
        "train_metrics_df['Model Training Taken (seconds)']  = training_timing\n",
        "test_metrics_df['Model Training Taken (seconds)']  = training_timing\n",
        "\n",
        "train_metrics_df['Model Prediction Time Taken (seconds)']  = training_pred_timing\n",
        "test_metrics_df['Model Prediction Time Taken (seconds)']  = testing_pred_timing\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# display df\n",
        "display(train_metrics_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzBF3L-dwVlA"
      },
      "source": [
        "# display df\n",
        "display(test_metrics_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rcBBSUHvqYv"
      },
      "source": [
        "---------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHdchGKGdJiu"
      },
      "source": [
        "SVM "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwV1T9qIda7_"
      },
      "source": [
        "from sklearn.svm import SVC"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HIwcmkzdKsJ"
      },
      "source": [
        "svc_clf = SVC(C = 0.3)\n",
        "\n",
        "\n",
        "svc_clf.fit(X_train_scale_pca , y_train)\n",
        "\n",
        "# Predict Train\n",
        "preds_svc = svc_clf.predict(X_train_scale_pca)\n",
        "\n",
        "# Classification report \n",
        "print(\"Train Data\")\n",
        "print(classification_report(y_train,preds_svc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucj8PBeweA4M"
      },
      "source": [
        "# Predict Test\n",
        "preds_svc = svc_clf.predict(X_test_scale_pca)\n",
        "\n",
        "print(\"Test Data\")\n",
        "# Classification report \n",
        "print(classification_report(y_test,preds_svc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BfxEcLW9e4SE"
      },
      "source": [
        "---------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HuGIj0Y6fn8w"
      },
      "source": [
        "svc_clf_smote = SVC(C = 0.3)\n",
        "\n",
        "\n",
        "svc_clf.fit(X_train_scale_smote , y_train_smote)\n",
        "\n",
        "# Predict Train\n",
        "preds_svc = svc_clf.predict(X_train_scale_smote)\n",
        "\n",
        "# Classification report \n",
        "print(\"Train Data\")\n",
        "print(classification_report(y_train , preds_svc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RZV7lz-e5UL"
      },
      "source": [
        "def holdout_checker_svc(smote = False ):\n",
        "\n",
        "  # Read in Fresh Data to see what predictions looks like\n",
        "  from google.colab import files\n",
        "  uploaded_test = files.upload()\n",
        "\n",
        "  # getting keys, which is file names of csv\n",
        "  val_file_name = [key for key in uploaded_test.keys()]\n",
        "\n",
        "  # read in csv \n",
        "  signal_test = pd.read_csv(val_file_name[0])\n",
        "\n",
        "\n",
        "  # Getting X_train & y_train\n",
        "  X_data = signal_test.drop(['Unnamed: 0' , 'Label_segment' , 'Participant_ID' , 'Participant_Run','X_Acc_Move_FFT_EnergyBands', \t'Y_Acc_Move_FFT_EnergyBands', \t'Z_Acc_Move_FFT_EnergyBands' ], axis = 1)\n",
        "  y_data = signal_test['Label_segment'].values\n",
        "\n",
        "  # scale with already fit ss \n",
        "  X_data_scale = ss.transform(X_data)\n",
        "\n",
        "  # feature selection\n",
        "  X_data_scale_pca = pca.transform(X_data_scale)\n",
        "\n",
        "\n",
        "\n",
        "  # if selecting smote trained model\n",
        "  if smote == True:\n",
        "    hold_preds = model_smote.predict(X_data_scale_fs)\n",
        "\n",
        "  # else non-smote trained model\n",
        "  else:\n",
        "    hold_preds = svc_clf.predict(X_data_scale_pca)\n",
        "\n",
        "  # take max of predictions \n",
        "  #max_predictions = np.argmax(hold_preds, axis=1)\n",
        "\n",
        "  # metrics \n",
        "  print(\"\\n---------------------- Metrics ----------------------------------------\")\n",
        "\n",
        "  print(\"Accuracy : \\t\\t\" ,accuracy_score(y_data, hold_preds))\n",
        "  print(\"Balanced Accuracy : \\t\" , balanced_accuracy_score(y_data, hold_preds))\n",
        "  #print(\"F1 Score : \\t\\t\" , f1_score(y_data, hold_preds, average='weighted'))\n",
        "\n",
        "\n",
        "  # set up labels \n",
        "  LABELS = ['Go', 'Turn1',  'Turn2' , 'Walk1', 'Walk2', 'Sit']\n",
        "\n",
        "  # classification report \n",
        "  print(\"\\n------------------- HoldOut Classification Report ---------------\")\n",
        "  print(classification_report(y_data , hold_preds))\n",
        "  print(\" \")\n",
        "\n",
        "  # confusion matrix\n",
        "  confusion_matrix_out = metrics.confusion_matrix(y_data, hold_preds )\n",
        "\n",
        "  plt.figure(figsize=(14, 10))\n",
        "  sns.heatmap(confusion_matrix_out, xticklabels=LABELS, yticklabels=LABELS, annot=True ,fmt=\"d\" );\n",
        "  plt.title(\"HoldOut Data Confusion matrix\")\n",
        "  plt.ylabel('True label')\n",
        "  plt.xlabel('Predicted label')\n",
        "  plt.show()\n",
        "\n",
        "  # lastly just printing actual predictions\n",
        "  print(\"\\n0 = Go \\t\\t 1 = Turn 1 \\t 2 = Turn 2\")\n",
        "  print(\"\\n3 = Walk 1 \\t 4 = Walk 2 \\t 5 = Sit\")\n",
        "\n",
        "  print(\" \")\n",
        "  print(hold_preds)\n",
        "\n",
        "  print(Counter(hold_preds))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxS7yqLyfTYN"
      },
      "source": [
        "holdout_checker_knn()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}