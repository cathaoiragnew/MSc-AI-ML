{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "9_Calibration_Cathaoir_MassProduction_Preprocess_notebook_original.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_A3dR5azjJAZ"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZlR1zTCjJXU"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt \n",
        "import datetime\n",
        "import statistics\n",
        "\n",
        "# \n",
        "import csv\n",
        "import numpy as np\n",
        "import math\n",
        "import pandas as pd\n",
        "from scipy import signal\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#\n",
        "from scipy import stats\n",
        "from scipy.stats import median_absolute_deviation\n",
        "\n",
        "#\n",
        "from google.colab import files\n",
        "from scipy.fft import fft, fftfreq , rfft , rfftfreq\n",
        "from scipy.stats import skew\n",
        "from scipy.stats import kurtosis"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCSG-nOLf73O"
      },
      "source": [
        "For Saving and Loading numpy arrays\n",
        "\n",
        "https://stackoverflow.com/questions/37996295/how-to-save-numpy-array-into-computer-for-later-use-in-python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmgwO5fviIXE"
      },
      "source": [
        "# Load in data "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbpcJc7bJDh8"
      },
      "source": [
        "--------------------- Params --------------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "n-zSuMUDiAeE",
        "outputId": "f4e53687-e799-48af-9220-bb173eeccfcd"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded_params = files.upload()\n",
        "\n",
        "# SHOULD BE 32 FILES SELECTED (4 Measurements * 8 Runs = 32 , usually)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-28bb590f-d949-417f-ac7d-3f0014994d96\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-28bb590f-d949-417f-ac7d-3f0014994d96\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLwOMGnuJKNn"
      },
      "source": [
        "--------------------- Markers --------------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40QIHbqpQ5mA"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded_markers = files.upload()\n",
        "\n",
        "# SHOULD BE 8 FILES SELECTED (8 runs usually)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6ve0HWoQSPr"
      },
      "source": [
        "# # # Accleration\n",
        "# accel = \"08-04-2015 04.08.05.518 - Right Coat Pocket - TrialFPSV3502 - Raw Acceleration.csv\" \n",
        "                        \n",
        "\n",
        "# # True Orientation \n",
        "# tog = \"08-04-2015 04.08.05.482 - Right Coat Pocket - TrialFPSV3502 - True Orientation Data.csv\" \n",
        "                       \n",
        "\n",
        "# # Magnetometer\n",
        "# maget = \"08-04-2015 04.08.05.545 - Right Coat Pocket - TrialFPSV3502 - Raw Magnetometer.csv\"\n",
        "\n",
        "# # Gyro\n",
        "# gyro = \"08-04-2015 04.08.05.572 - Right Coat Pocket - TrialFPSV3502 - Raw Gyro.csv\" \n",
        "                        \n",
        "\n",
        "# # Markers\n",
        "# markers = '08-04-2015 13.06.09.853 - TrialFPSV3502 - Markers.csv'\n",
        "                       \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpcC2U6VCHe7"
      },
      "source": [
        "# Quick look at uploaded to help automatic preprocess"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prUq0zkvuyYY"
      },
      "source": [
        "\n",
        "\n",
        "# # getting keys, which is file names of cvs \n",
        "# list_of_params = [key for key in uploaded_params.keys()]\n",
        "\n",
        "# # print out to check\n",
        "# #print(list_of_params)\n",
        "\n",
        "# # now select first one and split it by white space so can access individual parts of interest\n",
        "# for i in list_of_params:\n",
        "\n",
        "#   split_list = i.split(\" \") \n",
        "#   print(split_list)\n",
        "\n",
        "# #print(split_list)\n",
        "\n",
        "# # so we want 'TrialFPSV3509' item which is [7] , to ensure all parameters are same run \n",
        "# # we also want 10 to select the relevant measures, to store then in a structured way\n",
        "# for i in split_list:\n",
        "\n",
        "#   if \"TrialFPSV\" in i:\n",
        "#     Id = i[9:11]\n",
        "#     Run = i[-1]\n",
        "\n",
        "#print(Id)\n",
        "#print(Run)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wduarxB9Y00"
      },
      "source": [
        "# # split on - to find location of phone during test \n",
        "\n",
        "# placement = []\n",
        "\n",
        "# for k in list_of_params:\n",
        "\n",
        "#   split_list = k.split(\"-\")\n",
        "\n",
        "#   print(split_list)\n",
        "\n",
        "#   if split_list[3] == ' Other ':\n",
        "\n",
        "#     print(\"YY\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jSI9f_9yTel"
      },
      "source": [
        "\n",
        "# # getting keys, which is file names of cvs \n",
        "# list_of_params = [key for key in uploaded_params.keys()]\n",
        "\n",
        "# # print out to check\n",
        "# #print(list_of_params)\n",
        "\n",
        "# # now select first one and split it by white space so can access individual parts of interest\n",
        "# for i in list_of_params:\n",
        "\n",
        "#   split_list = i.split(\" \") \n",
        "#   print(split_list)\n",
        "\n",
        "# print(split_list)\n",
        "\n",
        "# # so we want 'TrialFPSV3509' item which is [7] , to ensure all parameters are same run \n",
        "# # we also want 10 to select the relevant measures, to store then in a structured way\n",
        "\n",
        "# print(split_list[7])\n",
        "# print(split_list[10])\n",
        "\n",
        "# #finally print run number\n",
        "\n",
        "# print(split_list[7][-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugbY9zpt7Efn"
      },
      "source": [
        "# # now markers look \n",
        "# # getting keys, which is file names of cvs \n",
        "# list_of_markers = [key for key in uploaded_markers.keys()]\n",
        "\n",
        "# # print out to check\n",
        "# #print(list_of_markers)\n",
        "\n",
        "# # now select first one and split it by white space so can access individual parts of interest\n",
        "# for i in list_of_markers:\n",
        "\n",
        "#   split_list_m = i.split(\" \") \n",
        "#   print(split_list_m)\n",
        "\n",
        "# #print(split_list)\n",
        "\n",
        "# # so we want 'TrialFPSV3509' item which is [3] , to ensure all parameters are same run \n",
        "# # we also want 10 to select the relevant measures, to store then in a structured way\n",
        "\n",
        "# print(split_list_m[3])\n",
        "# print(split_list_m[3][-1])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXIWmPLybZGL"
      },
      "source": [
        "# Test "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlfOxt1mbsBr"
      },
      "source": [
        "# # getting keys, which is file names of params cvs \n",
        "# list_of_params = [key for key in uploaded_params.keys()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCVRvc06bsvj"
      },
      "source": [
        "#list_of_params"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJ7EYgXAgM7l"
      },
      "source": [
        "   Per ID     -   8 Runs (approx)   - 5 measures"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brBu0MEPhYiD"
      },
      "source": [
        "-------- pull all particiapant ID's --------------------------------------- "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mXlBYTDhdfn"
      },
      "source": [
        "list_ID =  [] \n",
        "list_Run_number = [] \n",
        "\n",
        "unique_ID_List = []\n",
        "\n",
        "# want 5 rows (one for each measurement) and 8 cols usually (one for each run) , but use len(uploaded_markers) incase there is less runs\n",
        "\n",
        "array_setup =  [ [ None for y in range( len(uploaded_markers) ) ] for x in range( 5 ) ]\n",
        "\n",
        "# getting keys, which is file names of params cvs \n",
        "list_of_params = [key for key in uploaded_params.keys()]\n",
        "\n",
        "# getting keys, which is file names of markers cvs \n",
        "list_of_markers = [key for key in uploaded_markers.keys()]\n",
        "\n",
        "unique_ID = 0\n",
        "\n",
        "for i in list_of_params:\n",
        "\n",
        "  #split each element to extract out info we want \n",
        "  split_list = i.split(\" \")\n",
        "\n",
        "  for j in split_list:\n",
        "\n",
        "  # saving Trial number to ensure parameters are same trial run \n",
        "    if \"TrialFPSV\" in j:\n",
        "      Id = j[9:11]\n",
        "      Run = j[-1]\n",
        "\n",
        "  trial_id     = int(Id)\n",
        "\n",
        "  # Actual ID run number\n",
        "  trial_id_run = int(Run)\n",
        "\n",
        "  if trial_id not in list_ID: \n",
        "    unique_ID += 1\n",
        "    unique_ID_List.append(trial_id)\n",
        "\n",
        "  # append this to list \n",
        "  list_ID.append(trial_id)\n",
        "  list_Run_number.append(trial_id_run)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpW1XyRKiBjN"
      },
      "source": [
        "unique_ID"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3VuNIqFKKxO"
      },
      "source": [
        "unique_ID_List"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YikDWoXYK-Sf"
      },
      "source": [
        "# list_Run_number.count(2)\n",
        "# list_Run_number.count(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUzTJzarbYwJ"
      },
      "source": [
        "big_array =  [ [ [ None for y in range( 8 ) ] for x in range( 5 ) ] for z in range(unique_ID) ]\n",
        "\n",
        "for m in range(len(unique_ID_List)):\n",
        "\n",
        "  # want 5 rows (one for each measurement) and 8 cols usually (one for each run) , but use len(uploaded_markers) incase there is less runs\n",
        "\n",
        "  array_setup =  [  [ None for y in range( 8 ) ] for x in range( 5 )  ]\n",
        "\n",
        "  # getting keys, which is file names of params cvs \n",
        "  list_of_params = [key for key in uploaded_params.keys()]\n",
        "\n",
        "  # getting keys, which is file names of markers cvs \n",
        "  list_of_markers = [key for key in uploaded_markers.keys()]\n",
        "\n",
        "  for i in list_of_params:\n",
        "\n",
        "    #split each element to extract out info we want \n",
        "    split_list = i.split(\" \")\n",
        "\n",
        "    for j in split_list:\n",
        "\n",
        "    # saving Trial number to ensure parameters are same trial run \n",
        "      if \"TrialFPSV\" in j:\n",
        "        Id = j[9:11]\n",
        "        Run = j[-1]\n",
        "\n",
        "    trial_id     = int(Id)\n",
        "\n",
        "    # Actual ID run number\n",
        "    trial_id_run = int(Run)\n",
        "\n",
        "    # we also want measurement type, to store then in a structured way\n",
        "    measurement_type = split_list[-1]\n",
        "\n",
        "\n",
        "    # first if statement to keep participants ID the same \n",
        "\n",
        "    if int(trial_id) == int(unique_ID_List[m]):\n",
        "\n",
        "      # now if  statements to sort them in order \n",
        "\n",
        "    ################################################################################\n",
        "      \n",
        "        # filter by run number and insert where it matches\n",
        "\n",
        "      if trial_id_run == 2:\n",
        "        \n",
        "        # this will be secend index 0, to imply its first run\n",
        "\n",
        "        # Acceleration\n",
        "        if measurement_type=='Acceleration.csv':\n",
        "          array_setup[0][0] =i \n",
        "\n",
        "        # True Orientation - this is the only measurement that will have data.csv as last element of split list \n",
        "        if measurement_type=='Data.csv':\n",
        "          array_setup[1][0] =i \n",
        "\n",
        "        # Magnetometer\n",
        "        if measurement_type=='Magnetometer.csv':\n",
        "          array_setup[2][0] =i \n",
        "\n",
        "        # Gyro\n",
        "        if measurement_type=='Gyro.csv':\n",
        "          array_setup[3][0] =i \n",
        "\n",
        "\n",
        "    ################################################################################\n",
        "\n",
        "      if trial_id_run == 3:\n",
        "        \n",
        "        # this will be secend index 0, to imply its first run\n",
        "\n",
        "        # Acceleration\n",
        "        if measurement_type=='Acceleration.csv':\n",
        "          array_setup[0][1] =i \n",
        "\n",
        "        # True Orientation\n",
        "        if measurement_type=='Data.csv':\n",
        "          array_setup[1][1] =i \n",
        "\n",
        "        # Magnetometer\n",
        "        if measurement_type=='Magnetometer.csv':\n",
        "          array_setup[2][1] =i \n",
        "\n",
        "        # Gyro\n",
        "        if measurement_type=='Gyro.csv':\n",
        "          array_setup[3][1] =i \n",
        "\n",
        "\n",
        "    ################################################################################\n",
        "\n",
        "      if trial_id_run == 4:\n",
        "        \n",
        "        # this will be secend index 0, to imply its first run\n",
        "\n",
        "        # Acceleration\n",
        "        if measurement_type=='Acceleration.csv':\n",
        "          array_setup[0][2] =i \n",
        "\n",
        "        # True Orientation\n",
        "        if measurement_type=='Data.csv':\n",
        "          array_setup[1][2] =i \n",
        "\n",
        "        # Magnetometer\n",
        "        if measurement_type=='Magnetometer.csv':\n",
        "          array_setup[2][2] =i \n",
        "\n",
        "        # Gyro\n",
        "        if measurement_type=='Gyro.csv':\n",
        "          array_setup[3][2] =i \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    ################################################################################\n",
        "\n",
        "      if trial_id_run == 5:\n",
        "        \n",
        "        # this will be secend index 0, to imply its first run\n",
        "\n",
        "        # Acceleration\n",
        "        if measurement_type=='Acceleration.csv':\n",
        "          array_setup[0][3] =i \n",
        "\n",
        "        # True Orientation\n",
        "        if measurement_type=='Data.csv':\n",
        "          array_setup[1][3] =i \n",
        "\n",
        "        # Magnetometer\n",
        "        if measurement_type=='Magnetometer.csv':\n",
        "          array_setup[2][3] =i \n",
        "\n",
        "        # Gyro\n",
        "        if measurement_type=='Gyro.csv':\n",
        "          array_setup[3][3] =i \n",
        "\n",
        "\n",
        "    ################################################################################\n",
        "\n",
        "      if trial_id_run == 6:\n",
        "        \n",
        "        # this will be secend index 0, to imply its first run\n",
        "\n",
        "        # Acceleration\n",
        "        if measurement_type=='Acceleration.csv':\n",
        "          array_setup[0][4] =i \n",
        "\n",
        "        # True Orientation\n",
        "        if measurement_type=='Data.csv':\n",
        "          array_setup[1][4] =i \n",
        "\n",
        "        # Magnetometer\n",
        "        if measurement_type=='Magnetometer.csv':\n",
        "          array_setup[2][4] =i \n",
        "\n",
        "        # Gyro\n",
        "        if measurement_type=='Gyro.csv':\n",
        "          array_setup[3][4] =i \n",
        "\n",
        "\n",
        "    ################################################################################\n",
        "\n",
        "      if trial_id_run == 7:\n",
        "        \n",
        "        # this will be secend index 0, to imply its first run\n",
        "\n",
        "        # Acceleration\n",
        "        if measurement_type=='Acceleration.csv':\n",
        "          array_setup[0][5] =i \n",
        "\n",
        "        # True Orientation\n",
        "        if measurement_type=='Data.csv':\n",
        "          array_setup[1][5] =i \n",
        "\n",
        "        # Magnetometer\n",
        "        if measurement_type=='Magnetometer.csv':\n",
        "          array_setup[2][5] =i \n",
        "\n",
        "        # Gyro\n",
        "        if measurement_type=='Gyro.csv':\n",
        "          array_setup[3][5] =i \n",
        "\n",
        "\n",
        "\n",
        "    ################################################################################\n",
        "\n",
        "      if trial_id_run == 8:\n",
        "        \n",
        "        # this will be secend index 0, to imply its first run\n",
        "\n",
        "        # Acceleration\n",
        "        if measurement_type=='Acceleration.csv':\n",
        "          array_setup[0][6] =i \n",
        "\n",
        "        # True Orientation\n",
        "        if measurement_type=='Data.csv':\n",
        "          array_setup[1][6] =i \n",
        "\n",
        "        # Magnetometer\n",
        "        if measurement_type=='Magnetometer.csv':\n",
        "          array_setup[2][6] =i \n",
        "\n",
        "        # Gyro\n",
        "        if measurement_type=='Gyro.csv':\n",
        "          array_setup[3][6] =i \n",
        "\n",
        "\n",
        "    ################################################################################\n",
        "\n",
        "      if trial_id_run == 9:\n",
        "        \n",
        "        # this will be secend index 0, to imply its first run\n",
        "\n",
        "        # Acceleration\n",
        "        if measurement_type=='Acceleration.csv':\n",
        "          array_setup[0][7] =i \n",
        "\n",
        "        # True Orientation\n",
        "        if measurement_type=='Data.csv':\n",
        "          array_setup[1][7] =i \n",
        "\n",
        "        # Magnetometer\n",
        "        if measurement_type=='Magnetometer.csv':\n",
        "          array_setup[2][7] =i \n",
        "\n",
        "        # Gyro\n",
        "        if measurement_type=='Gyro.csv':\n",
        "          array_setup[3][7] =i \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    ################################################################################\n",
        "\n",
        "    # now add markers as a row \n",
        "\n",
        "    for j in list_of_markers:\n",
        "\n",
        "      #split each element to extract out info we want \n",
        "      split_list_m = j.split(\" \")\n",
        "\n",
        "      # Actual ID  number\n",
        "      trial_id_m = int(split_list_m[3][9:11]) \n",
        "\n",
        "      # Actual ID run number\n",
        "      trial_id_run_m = int(split_list_m[3][-1]) \n",
        "\n",
        "      # now append to previous list of parameters as want one list of all relevant params \n",
        "\n",
        "      # only do the relevant one\n",
        "      if int(trial_id_m) == int(unique_ID_List[m]):\n",
        "\n",
        "        # now filter by run number and append where it matches to appriopte list\n",
        "        if trial_id_run_m == 2:\n",
        "          array_setup[4][0] = j\n",
        "        \n",
        "        if trial_id_run_m == 3:\n",
        "          array_setup[4][1] = j\n",
        "\n",
        "        if trial_id_run_m == 4:\n",
        "          array_setup[4][2] = j\n",
        "\n",
        "        if trial_id_run_m == 5:\n",
        "          array_setup[4][3] = j\n",
        "\n",
        "        if trial_id_run_m == 6:\n",
        "          array_setup[4][4] = j\n",
        "\n",
        "        if trial_id_run_m == 7:\n",
        "          array_setup[4][5] = j\n",
        "\n",
        "        if trial_id_run_m == 8:\n",
        "          array_setup[4][6] = j\n",
        "\n",
        "        if trial_id_run_m == 9:\n",
        "          array_setup[4][7] = j\n",
        "\n",
        "    #############################################################################\n",
        "\n",
        "  # add current filled up array into big array\n",
        "  big_array[m] = array_setup\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCnLao8zNtDR"
      },
      "source": [
        "np.array(big_array).shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vyyBcj2HfCl"
      },
      "source": [
        "\n",
        "for i in range( np.array(big_array).shape[0] ):\n",
        "\n",
        "  print(f\"\\n--------------------------------------- New Run {i} --------------------------------------------------\\n\")\n",
        " \n",
        "  print(f'\\n--------------------- Accel {i} ------------------------------\\n')\n",
        "\n",
        "  # only acceleration\n",
        "  display(big_array[i][0])\n",
        "\n",
        "\n",
        "  print(f'\\n--------------------- True Orientation {i} ------------------------------\\n')\n",
        "\n",
        "  # only true orientation\n",
        "  display(big_array[i][1])\n",
        "\n",
        "  print(f'\\n------------------------ Magnet {i} ---------------------------\\n')\n",
        "\n",
        "  # only magnetometer\n",
        "  display(big_array[i][2])\n",
        "\n",
        "  print(f'\\n-------------------------- Gyro {i} -------------------------\\n')\n",
        "\n",
        "  # only gyro\n",
        "  display(big_array[i][3])\n",
        "\n",
        "  print(f'\\n--------------------------- Markers {i} ------------------------\\n')\n",
        "\n",
        "  # only markers\n",
        "  display(big_array[i][4])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QNKb5mkCjPg"
      },
      "source": [
        "# parts = list_of_params[0].split(' ')\n",
        "\n",
        "# # want this to be ID & Run , so 35 & 2 \n",
        "\n",
        "# print(parts)\n",
        "\n",
        "# ID = parts[7][9:11]\n",
        "# Run = parts[7][12]\n",
        "\n",
        "# print(ID, Run)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OfLv9BoGCOTS"
      },
      "source": [
        "----------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5gOCe2NifEi"
      },
      "source": [
        "# # Accleration\n",
        "# raw_Acc = pd.read_csv(\"08-04-2015 04.08.05.518 - Right Coat Pocket - TrialFPSV3502 - Raw Acceleration.csv\" , \n",
        "#                         skiprows=0 ,  header=1 )\n",
        "\n",
        "# # True Orientation \n",
        "# raw_True_Orientation = pd.read_csv(\"08-04-2015 04.08.05.482 - Right Coat Pocket - TrialFPSV3502 - True Orientation Data.csv\" , \n",
        "#                         skiprows=0 ,  header=1 )\n",
        "\n",
        "# # Magnetometer\n",
        "# raw_Magnet = pd.read_csv(\"08-04-2015 04.08.05.545 - Right Coat Pocket - TrialFPSV3502 - Raw Magnetometer.csv\" , \n",
        "#                         skiprows=0 ,  header=1 )\n",
        "\n",
        "# # Gyro\n",
        "# raw_Gyro = pd.read_csv(\"08-04-2015 04.08.05.572 - Right Coat Pocket - TrialFPSV3502 - Raw Gyro.csv\" , \n",
        "#                         skiprows=0 ,  header=1 )\n",
        "\n",
        "# # Markers\n",
        "# Markers = pd.read_csv(\"08-04-2015 13.06.09.853 - TrialFPSV3502 - Markers.csv\" , \n",
        "#                         skiprows=0 ,  header=1 )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sI4WNHwjRyR"
      },
      "source": [
        "# raw_Acc.rename(columns={'X Axis': 'X_Acc', 'Y Axis': 'Y_Acc' , 'Z Axis': 'Z_Acc'}, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njUUC8H4jWAB"
      },
      "source": [
        "# raw_True_Orientation.rename(columns={'Azimuth': 'TrueOri_Azimuth', 'Pitch': 'TrueOri_Pitch' , 'Roll': 'TrueOri_Roll'}, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpwFmfHyjXWF"
      },
      "source": [
        "# raw_Magnet.rename(columns={'X Axis': 'X_Magnet', 'Y Axis': 'Y_Magnet' , 'Z Axis': 'Z_Magnet'}, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJXC8qfyja-A"
      },
      "source": [
        "# raw_Gyro.rename(columns={'Pitch': 'Gyro_Pitch', 'Roll': 'Gyro_Roll' , 'Yaw': 'Gyro_Yaw'}, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wv3QEwHjhos"
      },
      "source": [
        "# Markers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENQQXITDjOL8"
      },
      "source": [
        "# concate all together \n",
        "# df = pd.concat( [raw_Acc , raw_True_Orientation , raw_Magnet , raw_Gyro ] , axis=1  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vINQePgOl8jS"
      },
      "source": [
        "# df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wULjZ2qpmLu9"
      },
      "source": [
        "# Removing Duplicate columns \n",
        "# df = df.loc[:,~df.columns.duplicated()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrkoQz3EmMpH"
      },
      "source": [
        "# df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4AUfbgq_mX6u"
      },
      "source": [
        "# # drop system time & Unnames: 5\n",
        "# df = df.drop(['Unnamed: 5' , 'System Time (ms)'], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bM9neVy2mh2A"
      },
      "source": [
        "# df = df.drop(len(df)-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEzxrp4sB2bu"
      },
      "source": [
        "# df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oeDHxiSVpIq-"
      },
      "source": [
        "------------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRLFRjWjpKGI"
      },
      "source": [
        "# df.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SncWOQgIpZwY"
      },
      "source": [
        "# df['Time']  =  pd.to_datetime(df['Event Time (ns)'], unit='ns')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGlr8oGrpgJ4"
      },
      "source": [
        "# df.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wODjQmKe8jX6"
      },
      "source": [
        "# df.set_index('Time' ,  inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXd_8p06qsL7"
      },
      "source": [
        "# df_resampled = df.resample('10000000NS').bfill()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcD28f77sVv5"
      },
      "source": [
        "# df_resampled"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Qo78eq9sPs3"
      },
      "source": [
        "# # Median Filter \n",
        "\n",
        "# x_median = signal.medfilt(df_resampled['X_Acc'])\n",
        "# y_median = signal.medfilt(df_resampled['Y_Acc'])\n",
        "# z_median = signal.medfilt(df_resampled['Z_Acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtKaJv7TtMD4"
      },
      "source": [
        "# # sample frequecny\n",
        "# fs = 100\n",
        "# fc = 20\n",
        "\n",
        "# w = fc/(fs/2)\n",
        "# b,a = signal.butter(3, w, 'low')\n",
        "\n",
        "# x_median_20hz = signal.filtfilt(b,a,x_median)\n",
        "# y_median_20hz = signal.filtfilt(b,a,y_median)\n",
        "# z_median_20hz = signal.filtfilt(b,a,z_median)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLG9lBeTtWDb"
      },
      "source": [
        "# Step 3 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "725CxPoutXV1"
      },
      "source": [
        "# # Low Pass Filter \n",
        "\n",
        "# # sample frequecny\n",
        "# fs = 100\n",
        "\n",
        "# #Cut off frequency\n",
        "# fc = 0.3\n",
        "\n",
        "# w = fc/(fs/2)\n",
        "# b,a = signal.butter(4, w, 'low')\n",
        "\n",
        "# x_median_20hz_gravity = signal.filtfilt(b,a,x_median_20hz)\n",
        "# y_median_20hz_gravity = signal.filtfilt(b,a,y_median_20hz)\n",
        "# z_median_20hz_gravity = signal.filtfilt(b,a,z_median_20hz)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bonzJm7etpP9"
      },
      "source": [
        "# x_squared = x_median_20hz_gravity**2\n",
        "# y_squared = y_median_20hz_gravity**2\n",
        "# z_squared = z_median_20hz_gravity**2\n",
        "\n",
        "# total_squared = x_squared + y_squared  + z_squared \n",
        "\n",
        "# # want the mean of this to keep gravity constant throughout the trial \n",
        "# value_total_acc = np.sqrt(np.mean(total_squared))\n",
        "\n",
        "# # calculating std \n",
        "# std_total =  np.std(np.sqrt(total_squared))\n",
        "\n",
        "# diff =  value_total_acc - 9.81 \n",
        "\n",
        "# print(f\"Mean force: {value_total_acc} ,  STD: {std_total} ,  Diff {diff}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hjq_yndh387x"
      },
      "source": [
        "---------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4OUxexD0Ah7"
      },
      "source": [
        "------------------------------------------------------------\n",
        "\n",
        "Trying to build this as going along "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31o7nmZDiM_-"
      },
      "source": [
        "# Preprocess Function "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsAQeNMamvgy"
      },
      "source": [
        "def preprocess_func(acc , true_ori , magnet , gyro , markers , ID , Run , fc = 0.3 , n_time_steps = 256 , step = 128 , plots = False ):\n",
        "\n",
        "  \"\"\" Function to do all the necessary preprocessoing steps. \n",
        "      Want to return 3 dataframes & 2 Arrays: \n",
        "      \n",
        "      DataFrames:\n",
        "\n",
        "      1 = original measurements resampled into evenly spaced\n",
        "      2 = Reorientated measurements resampled into evenly spaced\n",
        "      3 = Reorientated measurements broken into hand crafted feature segments \n",
        "\n",
        "      Arrays:\n",
        "\n",
        "      4 = Reorientated measurements broken into segments\n",
        "      5 = Labels for Reorientated measurements broken into segments\n",
        "\n",
        "      \n",
        "\n",
        "      \n",
        "      \n",
        "      First 5 parameters are the file names of measurements from excel data\n",
        "      fc - is the cut of frequency used to isolate gravity component can range from (0.1-0.5) from literature\n",
        "      n_time_steps, is the number of time steps for the sliding window, n_time_steps * (0.01) will give how many seconds is covered \n",
        "      n_time_steps = 256  -> 2.56s of the signal will be used as a segment \n",
        "      step is used to create an overlap of sliding window from literature review, 50% overlap was used. \n",
        "\n",
        "      Example n_time_steps = 256  -> step = 128   50% overlap \n",
        "\n",
        "      ID is 2 digit indentifier code , example TrialFPSV3502  ->35\n",
        "      Run is the trial number of the indiviual ,  example TrialFPSV3502 -> 2 \n",
        "        \n",
        "        \n",
        "      \"\"\"\n",
        "\n",
        "  #import warnings\n",
        "  #warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "  ############################################## Read in Data ######################################################################################\n",
        "\n",
        "  # Accleration\n",
        "  raw_Acc = pd.read_csv(acc ,  skiprows=0 ,  header=1 )\n",
        "  # Rename Cols not to cause any confusion \n",
        "  raw_Acc.rename(columns={'X Axis': 'X_Acc', 'Y Axis': 'Y_Acc' , 'Z Axis': 'Z_Acc'}, inplace=True)\n",
        "\n",
        "\n",
        "  # True Orientation \n",
        "  raw_True_Orientation = pd.read_csv( true_ori , skiprows=0 ,  header=1 )\n",
        "  # Rename Cols not to cause any confusion \n",
        "  raw_True_Orientation.rename(columns={'Azimuth': 'TrueOri_Azimuth', 'Pitch': 'TrueOri_Pitch' , 'Roll': 'TrueOri_Roll'}, inplace=True)\n",
        "\n",
        "\n",
        "  # Magnetometer\n",
        "  raw_Magnet = pd.read_csv( magnet , skiprows=0 ,  header=1 )\n",
        "  # Rename Cols not to cause any confusion \n",
        "  raw_Magnet.rename(columns={'X Axis': 'X_Magnet', 'Y Axis': 'Y_Magnet' , 'Z Axis': 'Z_Magnet'}, inplace=True)\n",
        "\n",
        "\n",
        "  # Gyro\n",
        "  raw_Gyro = pd.read_csv( gyro , skiprows=0 ,  header=1 )\n",
        "  # Rename Cols not to cause any confusion \n",
        "  raw_Gyro.rename(columns={'Pitch': 'Gyro_Pitch', 'Roll': 'Gyro_Roll' , 'Yaw': 'Gyro_Yaw'}, inplace=True)\n",
        "\n",
        "\n",
        "  # Markers\n",
        "  Markers = pd.read_csv( markers, skiprows=0 ,  header=1 )\n",
        "\n",
        "  ID = ID\n",
        "  Run = Run\n",
        "\n",
        "  ############################################# Concate dataframes together and remove na & duplicate / unnessary columns ############################\n",
        "\n",
        "  # concate all together \n",
        "  df = pd.concat( [raw_Acc , raw_True_Orientation , raw_Magnet , raw_Gyro ] , axis=1  )\n",
        "\n",
        "  # Removing Duplicate columns \n",
        "  df = df.loc[:,~df.columns.duplicated()]\n",
        "\n",
        "  # drop system time & Unnames: 5\n",
        "  df = df.drop(['Unnamed: 5' , 'System Time (ms)'], axis=1)\n",
        "\n",
        "  # drop last row as its always n.a\n",
        "  df = df.drop(len(df)-1)\n",
        "\n",
        "  # just a checker for na after original removing \n",
        "  if df.isna().sum().any() != 0:\n",
        "    \"Print n.a still exist in original dataframe, investigate!\"\n",
        "\n",
        "\n",
        "  ############################################ Resampling time ##################################################################\n",
        "\n",
        "  # convert dtype of Event Time(ns) to datetime to resample \n",
        "  df['Time']  =  pd.to_datetime(df['Event Time (ns)'], unit='ns')\n",
        "\n",
        "  # now set Time column as the index \n",
        "  df.set_index('Time' ,  inplace=True)\n",
        "\n",
        "  # resampling into bins and using backfill\n",
        "  df_resampled = df.resample('10000000NS').bfill()\n",
        "\n",
        "\n",
        "\n",
        "  ############################################  Signal Processing ##################################################################\n",
        "\n",
        "\n",
        "\n",
        "                                ################################### Acceleration #################################\n",
        "\n",
        "\n",
        "  # Time difference\n",
        "  # currently as it stands with above resampling bins , time difference is 0.01 of a second, which is  $10^{-2}$ of a second \n",
        "\n",
        "  # Frequency \n",
        "  # 1 occurance every 0.01 seconds    ->  F  = 1/0.01 = 100 hz \n",
        "\n",
        "\n",
        "  #Going to copy Human Activity Recognition Preprocessing steps: (https://www.elen.ucl.ac.be/Proceedings/esann/esannpdf/es2013-84.pdf)\n",
        "  # - Median filter\n",
        "  # - 3rd order low-pass Butterworth Filter with a 20 Hz cutoff Freq (This rate is sufficient for capturing humanbody motion since99%of its energy is contained below 15Hz) \n",
        "  # - The acceleration signal, which has gravitational and body motion components, was separated using another Butterworth low-pass filter into body acceleration and gravity.\n",
        "  # The gravitational force is assumed to have only low frequency components, therefore we found from the experiments that 0.3 Hz was an optimal\n",
        "  # corner frequency for a constant gravity signal\n",
        "\n",
        "\n",
        "  # Step 1: Median Filter \n",
        "\n",
        "  x_acc_median = signal.medfilt(df_resampled['X_Acc'])\n",
        "  y_acc_median = signal.medfilt(df_resampled['Y_Acc'])\n",
        "  z_acc_median = signal.medfilt(df_resampled['Z_Acc'])\n",
        "\n",
        "  # Step 2:  3rd order low-pass Butterworth Filter with a 20 Hz cutoff Freq (This rate is sufficient for capturing humanbody motion since 99% of its energy is contained below 15Hz) \n",
        "\n",
        "  # sample frequecny\n",
        "  fs = 100\n",
        "\n",
        "  #cut off frequency\n",
        "  fc_2 = 20\n",
        "\n",
        "  w = fc_2 /(fs/2)\n",
        "  b,a = signal.butter(3, w, 'low')\n",
        "\n",
        "  x_acc_median_20hz = signal.filtfilt(b,a,x_acc_median)\n",
        "  y_acc_median_20hz = signal.filtfilt(b,a,y_acc_median)\n",
        "  z_acc_median_20hz = signal.filtfilt(b,a,z_acc_median)\n",
        "\n",
        "\n",
        "\n",
        "  # Step 3 : The acceleration signal, which has gravitational and body motion components, was separated using another Butterworth low-pass filter into body acceleration and gravity.\n",
        "  # The gravitational force is assumed to have only low frequency components, therefore we found from the experiments that 0.3 Hz\n",
        "  # was an optimal corner frequency for a constant gravity signal (from literature: https://www.elen.ucl.ac.be/Proceedings/esann/esannpdf/es2013-84.pdf)\n",
        "\n",
        "  # Low Pass Filter \n",
        "\n",
        "  # sample frequecny\n",
        "  fs = 100\n",
        "\n",
        "  #Cut off frequency ( 0.3 )\n",
        "  fc = fc\n",
        "\n",
        "  w = fc/(fs/2)\n",
        "  b,a = signal.butter(4, w, 'low')\n",
        "\n",
        "  x_acc_median_20hz_gravity = signal.filtfilt(b,a,x_acc_median_20hz)\n",
        "  y_acc_median_20hz_gravity = signal.filtfilt(b,a,y_acc_median_20hz)\n",
        "  z_acc_median_20hz_gravity = signal.filtfilt(b,a,z_acc_median_20hz)\n",
        "\n",
        "  x_squared = x_acc_median_20hz_gravity**2\n",
        "  y_squared = y_acc_median_20hz_gravity**2\n",
        "  z_squared = z_acc_median_20hz_gravity**2\n",
        "\n",
        "  # summing the above components\n",
        "  total_squared = x_squared + y_squared  + z_squared \n",
        "\n",
        "  # want the mean of this to keep gravity constant throughout the trial \n",
        "  value_total_acc = np.sqrt(np.mean(total_squared))\n",
        "\n",
        "  # calculating std \n",
        "  std_total =  np.std(np.sqrt(total_squared))\n",
        "\n",
        "  # Calculating difference\n",
        "  diff =  value_total_acc - 9.81 \n",
        "\n",
        "  # print out statement to get an idea how its working \n",
        "  print(f\"Mean force: {value_total_acc} ,  STD: {std_total} ,  Diff {diff}\")\n",
        "\n",
        "\n",
        "\n",
        "  # From the paper https://arxiv.org/ftp/arxiv/papers/1708/1708.08989.pdf\n",
        "\n",
        "  # - their code was available on github and they substract gravity component from total to get movement \n",
        "  # https://github.com/guillaume-chevalier/HAR-stacked-residual-bidir-LSTMs/blob/master/data/signal_filtering.py \n",
        "\n",
        "  x_acc_median_20hz_movement = x_acc_median_20hz - x_acc_median_20hz_gravity\n",
        "  y_acc_median_20hz_movement = y_acc_median_20hz - y_acc_median_20hz_gravity\n",
        "  z_acc_median_20hz_movement = z_acc_median_20hz - z_acc_median_20hz_gravity\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        " ######################################## Matrix Rotations #############################################\n",
        "\n",
        "\n",
        " #define angles for transfromation matrix\n",
        "\n",
        "  def Phi(y,z, degrees = False):\n",
        "\n",
        "    \"Calculates Roll Angle. If Degrees is set to true, the angles measurement is in degress and will be converted to radians.\"\n",
        "\n",
        "    gy = y\n",
        "    gz = z\n",
        "    roll = gy / gz \n",
        "    if degrees == True:\n",
        "      # convert degrees to radian \n",
        "      roll = math.radians(roll)\n",
        "    return (math.atan(roll))\n",
        "\n",
        "\n",
        "  def Theta(x, y , z , degrees = False):\n",
        "    \"Calculate Pitch Angle\"\n",
        "    neg_gx = -x\n",
        "    gy_square = y**2 \n",
        "    gz_square = z**2\n",
        "    pitch = neg_gx / ( np.sqrt(gy_square + gz_square))\n",
        "    if degrees == True:\n",
        "      # convert degrees to radian \n",
        "      pitch = math.radians(pitch)\n",
        "\n",
        "    return (math.atan(pitch))\n",
        "\n",
        "\n",
        "  \n",
        "  def psi(x_mag , y_mag , z_mag , roll , pitch ):\n",
        "    \"Calculate Yaw Angle\"\n",
        "    x = x_mag \n",
        "    y = y_mag \n",
        "    z = z_mag\n",
        "\n",
        "    roll = roll \n",
        "    pitch = pitch \n",
        "\n",
        "    Mx = x * math.cos(roll) + z * math.sin(roll)  \n",
        "\n",
        "    My = x * math.sin(pitch) * math.sin(roll)  \\\n",
        "        + y * math.cos(pitch)               \\\n",
        "        - z * math.sin(pitch) * math.cos(roll)\n",
        " \n",
        "    yaw = (math.atan(My / Mx))\n",
        "\n",
        "    return yaw\n",
        "\n",
        "\n",
        "  #define the rotation matrix \n",
        "\n",
        "  def Rx(phi):\n",
        "      return np.matrix([[1,                  0,                       0], \n",
        "                        [0,               math.cos(phi),       -math.sin(phi)],\n",
        "                        [0,               math.sin(phi),        math.cos(phi)]])\n",
        "\n",
        "  def Ry(theta):\n",
        "      return np.matrix([[math.cos(theta),      0            , math.sin(theta)],\n",
        "                        [0                 ,   1                        ,0],\n",
        "                        [-math.sin(theta),     0,             math.cos(theta)]])\n",
        "\n",
        "  def Rz(psi):\n",
        "      return np.matrix([[math.cos(psi),     -math.sin(psi) ,            0],\n",
        "                        [math.sin(psi)   ,   math.cos(psi) ,            0],\n",
        "                        [0 ,                    0,                1]])\n",
        "\n",
        "\n",
        "\n",
        "  #define the opposite direction rotation matrix \n",
        "\n",
        "  def Rx_b(phi):\n",
        "      return np.matrix([[1,                  0,                              0], \n",
        "                        [0,               -math.cos(phi),        math.sin(phi)],\n",
        "                        [0,               -math.sin(phi),       -math.cos(phi)]])\n",
        "\n",
        "  def Ry_b(theta):\n",
        "      return np.matrix([[-math.cos(theta),      0            ,  -math.sin(theta)],\n",
        "                        [0                 ,    1                             ,0],\n",
        "                        [math.sin(theta),       0,             -math.cos(theta)]])\n",
        "\n",
        "  def Rz_b(psi):\n",
        "      return np.matrix([[-math.cos(psi),      math.sin(psi) ,            0],\n",
        "                        [-math.sin(psi)   ,  -math.cos(psi) ,            0],\n",
        "                        [0 ,                    0,                       1]])\n",
        "\n",
        "\n",
        "################################################################################################################################\n",
        "\n",
        "  # Now apply matrix rotation \n",
        "\n",
        "  # set up lists to hold new data points\n",
        "\n",
        "  # Gravity Acceleration\n",
        "  x_acc_rotated = [] \n",
        "  y_acc_rotated = [] \n",
        "  z_acc_rotated = [] \n",
        "\n",
        "  # Movement Acceleration\n",
        "  x_acc_movement_rotated = [] \n",
        "  y_acc_movement_rotated = [] \n",
        "  z_acc_movement_rotated = [] \n",
        "\n",
        "  # Magnetometer \n",
        "  x_magnet_rotated = [] \n",
        "  y_magnet_rotated = [] \n",
        "  z_magnet_rotated = [] \n",
        "\n",
        "  # Gyro \n",
        "  pitch_gyro_rotated = [] \n",
        "  roll_gyro_rotated = [] \n",
        "  yaw_gyro_rotated = [] \n",
        "\n",
        "  # True Orientation \n",
        "  azimuth_TrueOri_rotated = [] \n",
        "  roll_TrueOri_rotated = [] \n",
        "  pitch_TrueOri_rotated = [] \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # loop through the gravity componet \n",
        "  for i in range(len(x_acc_median_20hz_gravity)):\n",
        "\n",
        "    # Uses Acc\n",
        "    pitch = Theta( x_acc_median_20hz_gravity[i] , y_acc_median_20hz_gravity[i] ,  z_acc_median_20hz_gravity[i] )\n",
        "    roll  = Phi( y_acc_median_20hz_gravity[i] ,   z_acc_median_20hz_gravity[i]  )\n",
        "\n",
        "    # read in magnetometer data \n",
        "    x_mag = df_resampled['X_Magnet'][i]\n",
        "    y_mag = df_resampled['Y_Magnet'][i]\n",
        "    z_mag = df_resampled['Z_Magnet'][i]\n",
        "\n",
        "    # uses Mag \n",
        "    yaw  = psi( x_mag  , y_mag , z_mag  , roll = roll , pitch = pitch)\n",
        "\n",
        "\n",
        "    #Create a rotation matrix for each sensor to normalize the orientation of the phone in each test\n",
        "    R = Rz(yaw) * Ry(pitch) * Rx(roll)\n",
        "\n",
        "    #######################################################################################################################################################################################\n",
        "    \n",
        "\n",
        "    # put into array for multiplication \n",
        "    array_acc_for_multiplication = [ [x_acc_median_20hz_gravity[i]] , [y_acc_median_20hz_gravity[i]] ,  [z_acc_median_20hz_gravity[i]] ]\n",
        "\n",
        "    # Acceleration for body movement \n",
        "    array_acc_movement_for_multiplication = [ [x_acc_median_20hz_movement[i]] , [y_acc_median_20hz_movement[i]] ,  [z_acc_median_20hz_movement[i]] ]\n",
        "\n",
        "    # Magnometer \n",
        "    array_magnet_for_multiplication = [ [df_resampled['X_Magnet'][i]] , [df_resampled['Y_Magnet'][i]] ,  [df_resampled['Z_Magnet'][i]] ]\n",
        "\n",
        "    # Gyro \n",
        "    array_gyro_for_multiplication = [ [df_resampled['Gyro_Pitch'][i]] , [df_resampled['Gyro_Roll'][i]] ,  [df_resampled['Gyro_Yaw'][i]] ]\n",
        "\n",
        "    # True Orientation \n",
        "    array_TrueOri_for_multiplication = [ [df_resampled['TrueOri_Azimuth'][i]] , [df_resampled['TrueOri_Pitch'][i]] ,  [df_resampled['TrueOri_Roll'][i]] ]\n",
        "\n",
        "\n",
        "    ##############################################################################################################################################################\n",
        "\n",
        "\n",
        "    # rotated Gravity Acceleration values \n",
        "    rot_x , rot_y , rot_z = R * array_acc_for_multiplication\n",
        "\n",
        "    # rotated Movement Acceleration values \n",
        "    rot_x_acc_movement , rot_y_acc_movement , rot_z_acc_movement = R * array_acc_movement_for_multiplication\n",
        "\n",
        "    # rotated Magnometer values \n",
        "    rot_x_magnet , rot_y_magnet , rot_z_magnet = R * array_magnet_for_multiplication\n",
        "\n",
        "    # rotated Gryo values \n",
        "    rot_pitch_gryo , rot_roll_gryo , rot_yaw_gryo = R * array_gyro_for_multiplication\n",
        "\n",
        "    # rotated Movement Acceleration values \n",
        "    rot_azimuth_TrueOri , rot_pitch_TrueOri , rot_roll_TrueOri = R * array_TrueOri_for_multiplication\n",
        "\n",
        "\n",
        "    # check if phone may have flipped and needs to reverse or go \"backwards\" \n",
        "    if (abs(rot_x) > 0.01) or (abs(rot_y) > 0.01) or (rot_z < 0):\n",
        "\n",
        "        # it is correct way up, however the X and Y are off\n",
        "        if np.sign(rot_z) == 1 and (abs(rot_x) > 0.01) or (abs(rot_y) > 0.01):\n",
        "\n",
        "          #Create a rotation matrix for each sensor to normalize the orientation of the phone in each test\n",
        "          R_b = Rz_b(yaw) * Ry_b(pitch) * Rx_b(roll)\n",
        "\n",
        "\n",
        "        # just if need to invert the z-axis, as the X and Y are approx 0\n",
        "        if (np.sign(rot_z) == -1 and (abs(rot_x) <= 0.01) and (abs(rot_y) <= 0.01)):\n",
        "\n",
        "          # Create a rotation matrix for each sensor to normalize the orientation of the phone in each test\n",
        "          R_b = -Rz(yaw) * Ry(pitch) * Rx(roll)\n",
        "\n",
        "\n",
        "        # need to invert z-axis and go backwards in rotation as X and Y are not approx 0 \n",
        "        if (np.sign(rot_z) == -1 and (abs(rot_x) >= 0.01) or (abs(rot_y) >= 0.01)):\n",
        "\n",
        "          # Create a rotation matrix for each sensor to normalize the orientation of the phone in each test\n",
        "          R_b = -Rz_b(yaw) * Ry_b(pitch) * Rx_b(roll)\n",
        "\n",
        "     ################### New rotated values if hit \"if\" statement ################################################ \n",
        "\n",
        "        # rotated Acceleration due to gravity values\n",
        "        rot_x , rot_y , rot_z = R_b * array_acc_for_multiplication\n",
        "\n",
        "        # rotated Movement Acceleration values \n",
        "        rot_x_acc_movement , rot_y_acc_movement , rot_z_acc_movement = R_b * array_acc_movement_for_multiplication\n",
        "\n",
        "        # rotated Magnometer values \n",
        "        rot_x_magnet , rot_y_magnet , rot_z_magnet = R_b * array_magnet_for_multiplication\n",
        "\n",
        "        # rotated Gryo values \n",
        "        rot_pitch_gryo , rot_roll_gryo , rot_yaw_gryo = R_b * array_gyro_for_multiplication\n",
        "\n",
        "        # rotated Movement Acceleration values \n",
        "        rot_azimuth_TrueOri , rot_pitch_TrueOri , rot_roll_TrueOri = R_b * array_TrueOri_for_multiplication\n",
        "\n",
        "\n",
        "    # append rotated gravity acceleration\n",
        "    x_acc_rotated.append(rot_x)\n",
        "    y_acc_rotated.append(rot_y)\n",
        "    z_acc_rotated.append(rot_z)\n",
        "\n",
        "\n",
        "    # append rotated movement acceleration\n",
        "    x_acc_movement_rotated.append(rot_x_acc_movement)\n",
        "    y_acc_movement_rotated.append(rot_y_acc_movement)\n",
        "    z_acc_movement_rotated.append(rot_z_acc_movement)\n",
        "\n",
        "    # append rotated magnetometer\n",
        "    x_magnet_rotated.append(rot_x_magnet)\n",
        "    y_magnet_rotated.append(rot_y_magnet)\n",
        "    z_magnet_rotated.append(rot_z_magnet)\n",
        "\n",
        "    # append rotated gyro\n",
        "    pitch_gyro_rotated.append(rot_pitch_gryo)\n",
        "    roll_gyro_rotated.append(rot_roll_gryo)\n",
        "    yaw_gyro_rotated.append(rot_yaw_gryo) \n",
        "\n",
        "    # append rotated true orientation\n",
        "    azimuth_TrueOri_rotated.append(rot_azimuth_TrueOri)\n",
        "    pitch_TrueOri_rotated.append(rot_pitch_TrueOri)\n",
        "    roll_TrueOri_rotated.append(rot_roll_TrueOri)\n",
        "\n",
        "\n",
        "  # Convert these new values to an array - as currently matrix types \n",
        "\n",
        "  # Acceleration Gravity \n",
        "  arr_x_rotated = np.array(x_acc_rotated)\n",
        "  arr_y_rotated = np.array(y_acc_rotated)\n",
        "  arr_z_rotated = np.array(z_acc_rotated)\n",
        "\n",
        "  # Acceleration Movement\n",
        "  arr_x_movement_rotated = np.array(x_acc_movement_rotated)\n",
        "  arr_y_movement_rotated = np.array(y_acc_movement_rotated)\n",
        "  arr_z_movement_rotated = np.array(z_acc_movement_rotated)\n",
        "\n",
        "  # Magnetometer\n",
        "  arr_x_magnet_rotated = np.array(x_magnet_rotated)\n",
        "  arr_y_magnet_rotated = np.array(y_magnet_rotated)\n",
        "  arr_z_magnet_rotated = np.array(z_magnet_rotated)\n",
        "\n",
        "  # Gyro\n",
        "  arr_pitch_gyro_rotated = np.array(pitch_gyro_rotated)\n",
        "  arr_roll_gyro_rotated = np.array(roll_gyro_rotated)\n",
        "  arr_yaw_gyro_rotated = np.array(yaw_gyro_rotated)\n",
        "\n",
        "\n",
        "  # True Orientation \n",
        "  arr_azimuth_TrueOri_rotated = np.array(azimuth_TrueOri_rotated)\n",
        "  arr_pitch_TrueOri_rotated = np.array(pitch_TrueOri_rotated)\n",
        "  arr_roll_TrueOri_rotated = np.array(roll_TrueOri_rotated)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # Squeeze so can add to dataframe\n",
        "\n",
        "  # Acceleration Gravity \n",
        "  arr_x_rotated_squeezed = np.squeeze(arr_x_rotated)\n",
        "  arr_y_rotated_squeezed = np.squeeze(arr_y_rotated)\n",
        "  arr_z_rotated_squeezed = np.squeeze(arr_z_rotated)\n",
        "\n",
        "  # Acceleration Movement\n",
        "  arr_x_movement_rotated_squeezed = np.squeeze(arr_x_movement_rotated)\n",
        "  arr_y_movement_rotated_squeezed = np.squeeze(arr_y_movement_rotated)\n",
        "  arr_z_movement_rotated_squeezed = np.squeeze(arr_z_movement_rotated)\n",
        "\n",
        "\n",
        "  # Magnetometer\n",
        "  arr_x_magnet_rotated_squeezed = np.squeeze(arr_x_magnet_rotated)\n",
        "  arr_y_magnet_rotated_squeezed = np.squeeze(arr_y_magnet_rotated)\n",
        "  arr_z_magnet_rotated_squeezed = np.squeeze(arr_z_magnet_rotated)\n",
        "\n",
        "\n",
        "  # Gyro\n",
        "  arr_pitch_gyro_rotated_squeezed = np.squeeze(arr_pitch_gyro_rotated)\n",
        "  arr_roll_gyro_rotated_squeezed  = np.squeeze(arr_roll_gyro_rotated)\n",
        "  arr_yaw_gyro_rotated_squeezed   = np.squeeze(arr_yaw_gyro_rotated)\n",
        "\n",
        "\n",
        "\n",
        "  # True Orientation \n",
        "  arr_azimuth_TrueOri_rotated_squeezed = np.squeeze(arr_azimuth_TrueOri_rotated)\n",
        "  arr_pitch_TrueOri_rotated_squeezed   = np.squeeze(arr_pitch_TrueOri_rotated)\n",
        "  arr_roll_TrueOri_rotated_squeezed    = np.squeeze(arr_roll_TrueOri_rotated)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # create new dataframe to hold rotated measures, same index as other Dataframe \n",
        "  df_resampled_rotated = pd.DataFrame(index= df_resampled.index)\n",
        "\n",
        "  # add the rotated measurements \n",
        "  df_resampled_rotated['X_Acc_Grav_R'] = arr_x_rotated_squeezed\n",
        "  df_resampled_rotated['Y_Acc_Grav_R'] = arr_y_rotated_squeezed\n",
        "  df_resampled_rotated['Z_Acc_Grav_R'] = arr_z_rotated_squeezed \n",
        "\n",
        "\n",
        "  df_resampled_rotated['X_Acc_Move_R'] = arr_x_movement_rotated_squeezed\n",
        "  df_resampled_rotated['Y_Acc_Move_R'] = arr_y_movement_rotated_squeezed\n",
        "  df_resampled_rotated['Z_Acc_Move_R'] = arr_z_movement_rotated_squeezed\n",
        "\n",
        "\n",
        "  df_resampled_rotated['X_Magnet_R'] = arr_x_magnet_rotated_squeezed\n",
        "  df_resampled_rotated['Y_Magnet_R'] = arr_y_magnet_rotated_squeezed\n",
        "  df_resampled_rotated['Z_Magnet_R'] = arr_z_magnet_rotated_squeezed\n",
        "\n",
        "\n",
        "  df_resampled_rotated['Gyro_Pitch_R'] = arr_pitch_gyro_rotated_squeezed\n",
        "  df_resampled_rotated['Gyro_Roll_R']  = arr_roll_gyro_rotated_squeezed\n",
        "  df_resampled_rotated['Gyro_Yaw_R']   = arr_yaw_gyro_rotated_squeezed\n",
        "\n",
        "\n",
        "\n",
        "  df_resampled_rotated['TrueOri_Azimuth_R'] = arr_azimuth_TrueOri_rotated_squeezed\n",
        "  df_resampled_rotated['TrueOri_Pitch_R']   = arr_pitch_TrueOri_rotated_squeezed\n",
        "  df_resampled_rotated['TrueOri_Roll_R']    = arr_roll_TrueOri_rotated_squeezed\n",
        "\n",
        "  \n",
        "  ###################################### Markers ###########################################\n",
        "\n",
        "\n",
        "  # drop last line as n.a\n",
        "  marker = Markers.drop(len(Markers)-1)\n",
        "\n",
        "  # convert local time to a float\n",
        "  marker = marker.astype({'Local Time (ms)': float})\n",
        "\n",
        "\n",
        "  # Sort Values by Relative Time\n",
        "  marker.sort_values(by=['Relative Time (ms)'], inplace=True, ascending=True)\n",
        "\n",
        "  # Rename Elements to Walk_1 , Turn_1 etc. \n",
        "\n",
        "  # rename to walk 1 \n",
        "  marker.at[4, 'Label'] = 'Walk 1'\n",
        "\n",
        "  #rename to turn 1 \n",
        "  marker.at[5, 'Label'] = 'Turn 1'\n",
        "\n",
        "  # rename to walk 2\n",
        "  marker.at[6, 'Label'] = 'Walk 2'\n",
        "\n",
        "  #rename to turn 2\n",
        "  marker.at[7, 'Label'] = 'Turn 2'\n",
        "\n",
        "\n",
        "  # convert Relative time to ns \n",
        "  # ms  10^-3    ns 10^-9      ms -> ns  multiply by 10^6 \n",
        "\n",
        "  # add a new column\n",
        "  marker['Relative Time (ns)'] = marker['Relative Time (ms)'] * (10**6)\n",
        "\n",
        "\n",
        "  # add start time of acceleration data and relative time to get time taken \n",
        "\n",
        "  # now add onto it the event time from raw acceleration \n",
        "  marker['New_Time'] = marker['Relative Time (ns)'] + df['Event Time (ns)'][0]\n",
        "\n",
        "\n",
        "  # convert this to a datetime dtype \n",
        "  marker['New_Time']  =  pd.to_datetime(marker['New_Time'], unit='ns')\n",
        "\n",
        "\n",
        "\n",
        "  # Now taking interesting parts of the dataframe and resample \n",
        "  of_interest = marker[['New_Time', 'Label']]\n",
        "\n",
        "  # need to drop the first row as its duplicate in the terms of index\n",
        "  of_interest = of_interest.drop(0)\n",
        "\n",
        "  # setting time as index \n",
        "  of_interest.set_index('New_Time' ,  inplace=True)\n",
        "\n",
        "\n",
        "  # convert labels to vals  \n",
        "  of_interest[\"Cat_Label\"] = of_interest[\"Label\"].values\n",
        "  of_interest[\"Cat_Label\"] = of_interest[\"Cat_Label\"].astype('category')\n",
        "  of_interest[\"Cat_Label\"] = of_interest[\"Cat_Label\"].cat.codes\n",
        "\n",
        "  # resample so it agrees with IMU measurements \n",
        "  of_interest_resampled = of_interest.resample('10000000NS').bfill() \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  ######################################### Final DataFrame Without Segments (DataFrames 1 & 2 ) ###################################################################################\n",
        "\n",
        "  last_df = pd.concat([df_resampled, of_interest_resampled ] , axis = 1)\n",
        "\n",
        "  last_df_rot = pd.concat([df_resampled_rotated, of_interest_resampled ] , axis = 1)\n",
        "\n",
        "  # filter out n.a at the end \n",
        "  original_df_resampled = last_df.dropna()\n",
        "\n",
        "  # filter out n.a at the end \n",
        "  original_df_rotated_resampled = last_df_rot.dropna()\n",
        "\n",
        "\n",
        "\n",
        "  # Now remove Sync from Start Service Ack & Sync from Stop Service Ack \n",
        "  # as we dont actually need them, we will always have access to start time and finish time , we need to detect in between stages\n",
        "\n",
        "  # remove start sync (usually just one anyways) \n",
        "  original_df_resampled = original_df_resampled[original_df_resampled[\"Label\"] != \"Sync from Start Service Ack\"]\n",
        "  original_df_rotated_resampled = original_df_rotated_resampled[original_df_rotated_resampled[\"Label\"] != \"Sync from Start Service Ack\"]\n",
        "\n",
        "  # remove stop sync  \n",
        "  original_df_resampled = original_df_resampled[original_df_resampled[\"Label\"] != \"Sync from Stop Service Ack\"]\n",
        "  original_df_rotated_resampled = original_df_rotated_resampled[original_df_rotated_resampled[\"Label\"] != \"Sync from Stop Service Ack\"]\n",
        "\n",
        "\n",
        "  # another final check for any n.a \n",
        "\n",
        "  if original_df_resampled.isna().sum().any() != 0:\n",
        "    \"Print n.a still exist in original_df_resampled dataframe!\"\n",
        "\n",
        "\n",
        "  if original_df_rotated_resampled.isna().sum().any() != 0:\n",
        "    \"Print n.a still exist in original_df_rotated_resampled dataframe!\"\n",
        "\n",
        "\n",
        "\n",
        "######################################### Sliding Window  #################################################################################\n",
        "\n",
        "  # HAR Hand craft features - https://www.elen.ucl.ac.be/Proceedings/esann/esannpdf/es2013-84.pdf\n",
        "  # SMA - https://dsp.stackexchange.com/questions/18649/signal-magnitude-area/18659\n",
        "\n",
        "\n",
        "  # 2 custom functions for hand craft features \n",
        "\n",
        "  # Signal Magnititude Area \n",
        "  def sma(x , y , z):\n",
        "    sum = 0\n",
        "    for i in range(len(x)):\n",
        "      sum += np.abs(x[i]) + np.abs(y[i]) + np.abs(z[i])\n",
        "    return sum /len(x)\n",
        "\n",
        "\n",
        "  # Energy ( sum of squares divided by number of values)\n",
        "  def energy(x , y , z):\n",
        "    sum_square = 0\n",
        "    for i in range(len(x)):\n",
        "      sum_square += (x[i])**2 + (y[i])**2 + (z[i])**2\n",
        "    return sum_square /len(x)\n",
        "\n",
        "  # number of time steps & step size\n",
        "  N_TIME_STEPS = n_time_steps\n",
        "  # this is for reshaping array at end  - size 9 = 3 Acceleration , 3 Mangetometer , 3 Gyros \n",
        "  N_FEATURES = 9\n",
        "  step = step  \n",
        "\n",
        "  # hand-crafted features lists set up\n",
        "\n",
        "  #### change of sign in magnetometer ###\n",
        "  change_in_sign_x_magnet = [] \n",
        "  change_in_sign_y_magnet = [] \n",
        "  change_in_sign_z_magnet = [] \n",
        "\n",
        "\n",
        "  ########### FFT Acceleration movement ######\n",
        "\n",
        "  # energy bands\n",
        "  energybands_fft_acc_x_0 = []\n",
        "  energybands_fft_acc_x_10 = []\n",
        "  energybands_fft_acc_x_20 = []\n",
        "  energybands_fft_acc_x_30 = []\n",
        "  energybands_fft_acc_x_40 = []\n",
        "  energybands_fft_acc_x_50 = []\n",
        "\n",
        "  energybands_fft_acc_y_0 = []\n",
        "  energybands_fft_acc_y_10 = []\n",
        "  energybands_fft_acc_y_20 = []\n",
        "  energybands_fft_acc_y_30 = []\n",
        "  energybands_fft_acc_y_40 = []\n",
        "  energybands_fft_acc_y_50 = []\n",
        "\n",
        "  energybands_fft_acc_z_0 = []\n",
        "  energybands_fft_acc_z_10 = []\n",
        "  energybands_fft_acc_z_20 = []\n",
        "  energybands_fft_acc_z_30 = []\n",
        "  energybands_fft_acc_z_40 = []\n",
        "  energybands_fft_acc_z_50 = []\n",
        "\n",
        "\n",
        "  # most dominant frequency\n",
        "  maxfreq_fft_acc_x = []\n",
        "  maxfreq_fft_acc_y = []\n",
        "  maxfreq_fft_acc_z = []\n",
        "\n",
        "  # max power\n",
        "  maxpower_fft_acc_x = []\n",
        "  maxpower_fft_acc_y = []\n",
        "  maxpower_fft_acc_z = []\n",
        "\n",
        "  # mean weighted frequency\n",
        "  meanfreq_fft_acc_x = []\n",
        "  meanfreq_fft_acc_y = []\n",
        "  meanfreq_fft_acc_z = []\n",
        "\n",
        "  # skewness of frequency\n",
        "  skewfreq_fft_acc_x = []\n",
        "  skewfreq_fft_acc_y = []\n",
        "  skewfreq_fft_acc_z = []\n",
        "\n",
        "  # kurtosis of frequency\n",
        "  kurtfreq_fft_acc_x = []\n",
        "  kurtfreq_fft_acc_y = []\n",
        "  kurtfreq_fft_acc_z = []\n",
        "\n",
        "\n",
        "\n",
        "  ############ mean ###############\n",
        "\n",
        "  # Acclereation due to movement  \n",
        "  mean_x_acc_move = []\n",
        "  mean_y_acc_move = []\n",
        "  mean_z_acc_move = []\n",
        "\n",
        "  # Magnetometer\n",
        "  mean_x_magnet = []\n",
        "  mean_y_magnet = []\n",
        "  mean_z_magnet = []\n",
        "\n",
        "  # Gyro\n",
        "  mean_pitch_gyro = []\n",
        "  mean_roll_gyro  = []\n",
        "  mean_yaw_gyro   = []\n",
        "\n",
        "  ############ STD ###############\n",
        "\n",
        "  # Acceleration due to movement  \n",
        "  std_x_acc_move = []\n",
        "  std_y_acc_move = []\n",
        "  std_z_acc_move = []\n",
        "\n",
        "  # Magnetometer\n",
        "  std_x_magnet = []\n",
        "  std_y_magnet = []\n",
        "  std_z_magnet = []\n",
        "\n",
        "  # Gyro\n",
        "  std_pitch_gyro = []\n",
        "  std_roll_gyro  = []\n",
        "  std_yaw_gyro   = []\n",
        "\n",
        "  ############ median absolute deviation ###############\n",
        "\n",
        "  # Acceleration due to movement  \n",
        "  mad_x_acc_move = []\n",
        "  mad_y_acc_move = []\n",
        "  mad_z_acc_move = []\n",
        "\n",
        "  # Magnetometer\n",
        "  mad_x_magnet = []\n",
        "  mad_y_magnet = []\n",
        "  mad_z_magnet = []\n",
        "\n",
        "  # Gyro\n",
        "  mad_pitch_gyro = []\n",
        "  mad_roll_gyro  = []\n",
        "  mad_yaw_gyro   = []\n",
        "\n",
        "\n",
        "  ############ max value in segment/ array ###############\n",
        "\n",
        "  # Acceleration due to movement  \n",
        "  max_x_acc_move = []\n",
        "  max_y_acc_move = []\n",
        "  max_z_acc_move = []\n",
        "\n",
        "  # Magnetometer\n",
        "  max_x_magnet = []\n",
        "  max_y_magnet = []\n",
        "  max_z_magnet = []\n",
        "\n",
        "  # Gyro\n",
        "  max_pitch_gyro = []\n",
        "  max_roll_gyro  = []\n",
        "  max_yaw_gyro   = []\n",
        "\n",
        "  ############ min value in segment/ array ###############\n",
        "\n",
        "  # Acceleration due to movement \n",
        "  min_x_acc_move = []\n",
        "  min_y_acc_move = []\n",
        "  min_z_acc_move = []\n",
        "\n",
        "  # Magnetometer\n",
        "  min_x_magnet = []\n",
        "  min_y_magnet = []\n",
        "  min_z_magnet = []\n",
        "\n",
        "  # Gyro\n",
        "  min_pitch_gyro = []\n",
        "  min_roll_gyro  = []\n",
        "  min_yaw_gyro   = []\n",
        "\n",
        "\n",
        "  ############ SMA (signal magnitude area) ###############\n",
        "\n",
        "  # Acceleration due to movement \n",
        "  sma_acc_move = [] \n",
        "\n",
        "  # Magnetometer\n",
        "  sma_magnet = []\n",
        "\n",
        "  # Gyro\n",
        "  sma_gyro = []\n",
        "\n",
        "  ############ # Energy ( sum of squares divided by number of values) ###############\n",
        "\n",
        "  # Acceleration due to movement \n",
        "  energy_acc_move = [] \n",
        "\n",
        "  # Magnetometer\n",
        "  energy_magnet = []\n",
        "\n",
        "  # Gyro\n",
        "  energy_gyro = []\n",
        "\n",
        "\n",
        "  ############ Interquartile range   ###############\n",
        "\n",
        "\n",
        "  # Acceleration due to movement\n",
        "  iqr_x_acc_move = []\n",
        "  iqr_y_acc_move = []\n",
        "  iqr_z_acc_move = []\n",
        "\n",
        "  # Magnetometer\n",
        "  iqr_x_magnet = []\n",
        "  iqr_y_magnet = []\n",
        "  iqr_z_magnet = []\n",
        "\n",
        "  # Gyro\n",
        "  iqr_pitch_gyro = []\n",
        "  iqr_roll_gyro  = []\n",
        "  iqr_yaw_gyro   = []\n",
        "\n",
        "\n",
        "\n",
        "  ############  Signal Entropy    ###############\n",
        "\n",
        "\n",
        "  # Acceleration due to movement\n",
        "  entropy_x_acc_move = []\n",
        "  entropy_y_acc_move = []\n",
        "  entropy_z_acc_move = []\n",
        "\n",
        "  # Magnetometer\n",
        "  entropy_x_magnet = []\n",
        "  entropy_y_magnet = []\n",
        "  entropy_z_magnet = []\n",
        "\n",
        "  # Gyro\n",
        "  entropy_pitch_gyro = []\n",
        "  entropy_roll_gyro  = []\n",
        "  entropy_yaw_gyro   = []\n",
        "\n",
        "\n",
        "\n",
        "  ############  Correlation between 2 signals   ###############\n",
        "\n",
        "  # Acceleration due to movement\n",
        "  corr_xy_acc_move = []\n",
        "  corr_xz_acc_move = []\n",
        "  corr_yz_acc_move = []\n",
        "\n",
        "  # Magnetometer\n",
        "  corr_xy_magnet = []\n",
        "  corr_xz_magnet = []\n",
        "  corr_yz_magnet = []\n",
        "\n",
        "  # Gyro\n",
        "  corr_pitch_roll_gyro = []\n",
        "  corr_pitch_yaw_gyro  = []\n",
        "  corr_roll_yaw_gyro   = []\n",
        "\n",
        "\n",
        "  # list to hold segments and labels \n",
        "  segments_acc_move = []\n",
        "  segments_magnet   = []\n",
        "  segments_gyro     = []\n",
        "  labels_seg = []\n",
        "\n",
        "\n",
        "\n",
        "  # Sliding window \n",
        "  for i in range(0, len(original_df_rotated_resampled) , step):\n",
        "\n",
        "    ############ Signals Only ####################\n",
        "\n",
        "    # Acceleration Movement Segments\n",
        "    xs_acc_move = original_df_rotated_resampled['X_Acc_Move_R'].values[i: i + N_TIME_STEPS]\n",
        "    ys_acc_move = original_df_rotated_resampled['Y_Acc_Move_R'].values[i: i + N_TIME_STEPS]\n",
        "    zs_acc_move = original_df_rotated_resampled['Z_Acc_Move_R'].values[i: i + N_TIME_STEPS]\n",
        "    \n",
        "\n",
        "\n",
        "    # Magnetometer Segments\n",
        "    xs_magnet = original_df_rotated_resampled['X_Magnet_R'].values[i: i + N_TIME_STEPS]\n",
        "    ys_magnet = original_df_rotated_resampled['Y_Magnet_R'].values[i: i + N_TIME_STEPS]\n",
        "    zs_magnet = original_df_rotated_resampled['Z_Magnet_R'].values[i: i + N_TIME_STEPS]\n",
        "\n",
        "\n",
        "\n",
        "    # Gyro Segments\n",
        "    pitch_s_gyro = original_df_rotated_resampled['Gyro_Pitch_R'].values[i: i + N_TIME_STEPS]\n",
        "    roll_s_gyro  = original_df_rotated_resampled['Gyro_Roll_R'].values[i: i + N_TIME_STEPS]\n",
        "    yaw_s_gyro   = original_df_rotated_resampled['Gyro_Yaw_R'].values[i: i + N_TIME_STEPS]\n",
        "\n",
        "\n",
        "\n",
        "    # if statement to ensure we cover all the signal , will pad with zeros to the right if needed, while ensure each segment\n",
        "    # will be of length N_TIME_STEPS\n",
        "    # The below statement is querying if the segment will be bigger than the values in the dataframe\n",
        "\n",
        "    if  (i + step >= len(original_df_rotated_resampled)) or (i + N_TIME_STEPS >= len(original_df_rotated_resampled) ):\n",
        "\n",
        "\n",
        "      ########################## Acceleration  #####################\n",
        "\n",
        "      # Acceleration - set up xs , ys ,zs of zeros of N_TIME_STEPS to keep all segments same length\n",
        "      xs_acc_move = np.zeros(N_TIME_STEPS)\n",
        "      ys_acc_move = np.zeros(N_TIME_STEPS)\n",
        "      zs_acc_move = np.zeros(N_TIME_STEPS)\n",
        "\n",
        "      # Now take the remaining values of the segment , this will be less than N_TIME_STEPS\n",
        "      x_acc_move = original_df_rotated_resampled['X_Acc_Move_R'].values[i::]\n",
        "      y_acc_move = original_df_rotated_resampled['Y_Acc_Move_R'].values[i::]\n",
        "      z_acc_move = original_df_rotated_resampled['Z_Acc_Move_R'].values[i::]\n",
        "\n",
        "      # assign these values from above step into the xs, ys, zs  zeros , this will give a segment of size N_TIME_STEPS, with padding of zeros to the right \n",
        "      xs_acc_move[:len(x_acc_move)] = x_acc_move\n",
        "      ys_acc_move[:len(y_acc_move)] = y_acc_move\n",
        "      zs_acc_move[:len(z_acc_move)] = z_acc_move\n",
        "\n",
        "\n",
        "\n",
        "      ########################## Magnetometer  #####################\n",
        "\n",
        "      xs_magnet = np.zeros(N_TIME_STEPS)\n",
        "      ys_magnet = np.zeros(N_TIME_STEPS)\n",
        "      zs_magnet = np.zeros(N_TIME_STEPS)\n",
        "\n",
        "      x_magnet = original_df_rotated_resampled['X_Magnet_R'].values[i::]\n",
        "      y_magnet = original_df_rotated_resampled['Y_Magnet_R'].values[i::]\n",
        "      z_magnet = original_df_rotated_resampled['Z_Magnet_R'].values[i::]\n",
        "\n",
        "\n",
        "      xs_magnet[:len(x_magnet)] = x_magnet\n",
        "      ys_magnet[:len(y_magnet)] = y_magnet\n",
        "      zs_magnet[:len(z_magnet)] = z_magnet\n",
        "\n",
        "\n",
        "      ########################## Gyro  #####################\n",
        "\n",
        "\n",
        "      pitch_s_gyro = np.zeros(N_TIME_STEPS)\n",
        "      roll_s_gyro  = np.zeros(N_TIME_STEPS)\n",
        "      yaw_s_gyro   = np.zeros(N_TIME_STEPS)\n",
        "\n",
        "\n",
        "      pitch_gyro = original_df_rotated_resampled['Gyro_Pitch_R'].values[i::]\n",
        "      roll_gyro  = original_df_rotated_resampled['Gyro_Roll_R'].values[i::]\n",
        "      yaw_gyro   = original_df_rotated_resampled['Gyro_Yaw_R'].values[i::]\n",
        "\n",
        "\n",
        "      pitch_s_gyro[:len(pitch_gyro)] = pitch_gyro\n",
        "      roll_s_gyro[:len(roll_gyro)]   = roll_gyro\n",
        "      yaw_s_gyro[:len(yaw_gyro)]     = yaw_gyro\n",
        "\n",
        "\n",
        "      # Now append to segments lists\n",
        "\n",
        "      segments_acc_move.append([xs_acc_move, ys_acc_move, zs_acc_move])\n",
        "      segments_magnet.append([xs_magnet , ys_magnet , zs_magnet  ])\n",
        "      segments_gyro.append([pitch_s_gyro , roll_s_gyro , yaw_s_gyro ])\n",
        "\n",
        "      # Same applies to label, take mode of remaining\n",
        "      labels_s = stats.mode(original_df_rotated_resampled['Label'][i::])[0][0]\n",
        "      labels_seg.append(labels_s)\n",
        "\n",
        "\n",
        "\n",
        "    else:\n",
        "\n",
        "\n",
        "      # appending \n",
        "      segments_acc_move.append([xs_acc_move, ys_acc_move, zs_acc_move])\n",
        "      segments_magnet.append([xs_magnet, ys_magnet, zs_magnet])\n",
        "      segments_gyro.append([pitch_s_gyro, roll_s_gyro, yaw_s_gyro])\n",
        "\n",
        "\n",
        "      labels_s = stats.mode(original_df_rotated_resampled['Label'][i: i + N_TIME_STEPS])[0][0]\n",
        "      labels_seg.append(labels_s)\n",
        "\n",
        "\n",
        "    # ################# \"hand crafted\" features #################################\n",
        "\n",
        "\n",
        "          ############################ Calculate FFT on Acceleration movement #####################################\n",
        "    \n",
        "    # Number of samples in signal\n",
        "    N_sample = len(xs_acc_move)\n",
        "\n",
        "    # Sampling rate is 100Hz\n",
        "    SAMPLE_RATE = 100\n",
        "\n",
        "    # Detrending data (advice from stack overflow to overcome 0 Hz main frequency)\n",
        "\n",
        "    detrend_x = xs_acc_move - np.mean(xs_acc_move)\n",
        "    detrend_y = ys_acc_move - np.mean(ys_acc_move)\n",
        "    detrend_z = zs_acc_move - np.mean(zs_acc_move)\n",
        "\n",
        "\n",
        "      ############ FFT X-Axis ###############\n",
        "\n",
        "    # Applying FFT for X-axis data\n",
        "    yf_x = rfft(detrend_x)\n",
        "    xf_x = rfftfreq(N_sample, 1 / SAMPLE_RATE)\n",
        "\n",
        "\n",
        "    # most dominant frequency\n",
        "    max_freq_x = xf_x[np.argmax(np.abs(yf_x))]\n",
        "\n",
        "    # max power\n",
        "    max_power_x = np.max(np.abs(yf_x))\n",
        "\n",
        "    # mean weighted frequency\n",
        "    mean_freq_x = ((np.abs(yf_x).dot(xf_x))/ len(xf_x) )\n",
        "\n",
        "\n",
        "    # skewness - checks if its normally distributed usually.  value greater than zero means that\n",
        "    # there is more weight in the right tail of the distribution and vice versa\n",
        "    skew_freq_x = skew(np.abs(yf_x))\n",
        "\n",
        "    #  It is a measure of the tailedness i.e. descriptor of shape of probability distribution of a real-valued random variable.\n",
        "    # In simple terms, one can say it is a measure of how heavy tail is compared to a normal distribution.\n",
        "    kurt_freq_x = kurtosis(np.abs(yf_x))\n",
        "\n",
        "\n",
        "\n",
        "      ############ FFT Y-Axis ###############\n",
        "\n",
        "    # Applying FFT for Y-axis data\n",
        "    yf_y = rfft(detrend_y)\n",
        "    xf_y = rfftfreq(N_sample, 1 / SAMPLE_RATE)\n",
        "\n",
        "\n",
        "    # most dominant frequency\n",
        "    max_freq_y = xf_y[np.argmax(np.abs(yf_y))]\n",
        "\n",
        "    # max power\n",
        "    max_power_y = np.max(np.abs(yf_y))\n",
        "\n",
        "    # mean weighted frequency\n",
        "    mean_freq_y = ((np.abs(yf_y).dot(xf_y))/ len(xf_y) )\n",
        "\n",
        "\n",
        "    # skewness - checks if its normally distributed usually.  value greater than zero means that\n",
        "    # there is more weight in the right tail of the distribution and vice versa\n",
        "    skew_freq_y = skew(np.abs(yf_y))\n",
        "\n",
        "    #  It is a measure of the tailedness i.e. descriptor of shape of probability distribution of a real-valued random variable.\n",
        "    # In simple terms, one can say it is a measure of how heavy tail is compared to a normal distribution.\n",
        "    kurt_freq_y = kurtosis(np.abs(yf_y))\n",
        "\n",
        "\n",
        "\n",
        "      ############ FFT Z-Axis ###############\n",
        "\n",
        "    # Applying FFT for Z-axis data\n",
        "    yf_z = rfft(detrend_y)\n",
        "    xf_z = rfftfreq(N_sample, 1 / SAMPLE_RATE)\n",
        "\n",
        "\n",
        "    # most dominant frequency\n",
        "    max_freq_z = xf_z[np.argmax(np.abs(yf_z))]\n",
        "\n",
        "    # max power\n",
        "    max_power_z = np.max(np.abs(yf_z))\n",
        "\n",
        "    # mean weighted frequency\n",
        "    mean_freq_z = ((np.abs(yf_z).dot(xf_z))/ len(xf_z) )\n",
        "\n",
        "\n",
        "    # skewness - checks if its normally distributed usually.  value greater than zero means that\n",
        "    # there is more weight in the right tail of the distribution and vice versa\n",
        "    skew_freq_z = skew(np.abs(yf_z))\n",
        "\n",
        "    #  It is a measure of the tailedness i.e. descriptor of shape of probability distribution of a real-valued random variable.\n",
        "    # In simple terms, one can say it is a measure of how heavy tail is compared to a normal distribution.\n",
        "    kurt_freq_z = kurtosis(np.abs(yf_z))\n",
        "\n",
        "\n",
        "\n",
        "    # Appending FFT \n",
        "\n",
        "    # energy bands\n",
        "\n",
        "    ###### X Axis ########\n",
        "    # 0 HZ \n",
        "    energybands_fft_acc_x_0.append(abs(yf_x[0]))\n",
        "    # 10 Hz\n",
        "    energybands_fft_acc_x_10.append(abs(yf_x[1]))\n",
        "    # 20 Hz\n",
        "    energybands_fft_acc_x_20.append(abs(yf_x[2]))\n",
        "    # 30 Hz\n",
        "    energybands_fft_acc_x_30.append(abs(yf_x[3]))\n",
        "    # 40 Hz\n",
        "    energybands_fft_acc_x_40.append(abs(yf_x[4]))\n",
        "    # 50 Hz\n",
        "    energybands_fft_acc_x_50.append(abs(yf_x[5]))\n",
        "\n",
        "\n",
        "    ###### Y Axis ########\n",
        "    # 0 HZ \n",
        "    energybands_fft_acc_y_0.append(abs(yf_y[0]))\n",
        "    # 10 Hz\n",
        "    energybands_fft_acc_y_10.append(abs(yf_y[1]))\n",
        "    # 20 Hz\n",
        "    energybands_fft_acc_y_20.append(abs(yf_y[2]))\n",
        "    # 30 Hz\n",
        "    energybands_fft_acc_y_30.append(abs(yf_y[3]))\n",
        "    # 40 Hz\n",
        "    energybands_fft_acc_y_40.append(abs(yf_y[4]))\n",
        "    # 50 Hz\n",
        "    energybands_fft_acc_y_50.append(abs(yf_y[5]))\n",
        "\n",
        "\n",
        "    ###### Z Axis ########\n",
        "    # 0 HZ \n",
        "    energybands_fft_acc_z_0.append(abs(yf_z[0]))\n",
        "    # 10 Hz\n",
        "    energybands_fft_acc_z_10.append(abs(yf_z[1]))\n",
        "    # 20 Hz\n",
        "    energybands_fft_acc_z_20.append(abs(yf_z[2]))\n",
        "    # 30 Hz\n",
        "    energybands_fft_acc_z_30.append(abs(yf_z[3]))\n",
        "    # 40 Hz\n",
        "    energybands_fft_acc_z_40.append(abs(yf_z[4]))\n",
        "    # 50 Hz\n",
        "    energybands_fft_acc_z_50.append(abs(yf_z[5]))\n",
        "\n",
        "\n",
        "\n",
        "    # most dominant frequency\n",
        "    maxfreq_fft_acc_x.append(max_freq_x)\n",
        "    maxfreq_fft_acc_y.append(max_freq_y)\n",
        "    maxfreq_fft_acc_z.append(max_freq_z)\n",
        "\n",
        "    # max power\n",
        "    maxpower_fft_acc_x.append(max_power_x)\n",
        "    maxpower_fft_acc_y.append(max_power_y)\n",
        "    maxpower_fft_acc_z.append(max_power_z)\n",
        "\n",
        "    # mean weighted frequency\n",
        "    meanfreq_fft_acc_x.append(mean_freq_x)\n",
        "    meanfreq_fft_acc_y.append(mean_freq_y)\n",
        "    meanfreq_fft_acc_z.append(mean_freq_z)\n",
        "\n",
        "    # skewness of frequency\n",
        "    skewfreq_fft_acc_x.append(skew_freq_x)\n",
        "    skewfreq_fft_acc_y.append(skew_freq_y)\n",
        "    skewfreq_fft_acc_z.append(skew_freq_z)\n",
        "\n",
        "    # kurtosis of frequency\n",
        "    kurtfreq_fft_acc_x.append(kurt_freq_x)\n",
        "    kurtfreq_fft_acc_y.append(kurt_freq_y)\n",
        "    kurtfreq_fft_acc_z.append(kurt_freq_z)\n",
        "\n",
        "\n",
        "\n",
        "                ################################# X Axis Magnet #############################################\n",
        "\n",
        "    # iterate through the values of the segment\n",
        "\n",
        "    # set default to 0\n",
        "    sign_change_x = 0\n",
        "\n",
        "    for i in xs_magnet:\n",
        "\n",
        "      # determine sign manually just so that there is  no confusions around 0 if it occurs\n",
        "      # This is the starting sign value of the segment, if positive start sign = 1 \n",
        "      if xs_magnet[0] >= 0:\n",
        "        start_sign_x = 1\n",
        "      \n",
        "      # else its negative = 0 \n",
        "      else:\n",
        "        start_sign_x = 0\n",
        "\n",
        "      # This is the current sign value in the segment, if positive start sign = 1 \n",
        "      if i >= 0:\n",
        "        current_sign_x = 1\n",
        "\n",
        "      # else its negative = 0 \n",
        "      else:\n",
        "        current_sign_x = 0\n",
        "\n",
        "\n",
        "      # if start sign and current sign differ, must be a sign change , so set sign change = 1 to represent a change in sign \n",
        "      if start_sign_x != current_sign_x:\n",
        "\n",
        "        # means there was a change\n",
        "        sign_change_x = 1\n",
        "\n",
        "\n",
        "    change_in_sign_x_magnet.append(sign_change_x)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "          ################################# Y Axis Magnet #############################################\n",
        "\n",
        "    # set default to 0\n",
        "    sign_change_y = 0\n",
        "\n",
        "    # iterate through the values of the segment\n",
        "    for i in ys_magnet:\n",
        "\n",
        "      # determine sign manually just so that there is  no confusions around 0 if it occurs\n",
        "      # This is the starting sign value of the segment, if positive start sign = 1 \n",
        "      if ys_magnet[0] >= 0:\n",
        "        start_sign_y = 1\n",
        "      \n",
        "      # else its negative = 0 \n",
        "      else:\n",
        "        start_sign_y = 0\n",
        "\n",
        "      # This is the current sign value in the segment, if positive start sign = 1 \n",
        "      if i >= 0:\n",
        "        current_sign_y = 1\n",
        "\n",
        "      # else its negative = 0 \n",
        "      else:\n",
        "        current_sign_y = 0\n",
        "\n",
        "\n",
        "      # if start sign and current sign differ, must be a sign change , so set sign change = 1 to represent a change in sign \n",
        "      if start_sign_y != current_sign_y:\n",
        "\n",
        "        # means there was a change\n",
        "        sign_change_y = 1\n",
        "\n",
        "\n",
        "    change_in_sign_y_magnet.append(sign_change_y)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "          ################################# Z Axis Magnet #############################################\n",
        "\n",
        "    # set default to 0\n",
        "    sign_change_z = 0\n",
        "\n",
        "    # iterate through the values of the segment\n",
        "    for i in zs_magnet:\n",
        "\n",
        "      # determine sign manually just so that there is  no confusions around 0 if it occurs\n",
        "      # This is the starting sign value of the segment, if positive start sign = 1 \n",
        "      if zs_magnet[0] >= 0:\n",
        "        start_sign_z = 1\n",
        "      \n",
        "      # else its negative = 0 \n",
        "      else:\n",
        "        start_sign_z = 0\n",
        "\n",
        "      # This is the current sign value in the segment, if positive start sign = 1 \n",
        "      if i >= 0:\n",
        "        current_sign_z = 1\n",
        "\n",
        "      # else its negative = 0 \n",
        "      else:\n",
        "        current_sign_z = 0\n",
        "\n",
        "\n",
        "      # if start sign and current sign differ, must be a sign change , so set sign change = 1 to represent a change in sign \n",
        "      if start_sign_z != current_sign_z:\n",
        "\n",
        "        # means there was a change\n",
        "        sign_change_z = 1\n",
        "\n",
        "    change_in_sign_z_magnet.append(sign_change_z)\n",
        "\n",
        "\n",
        "        \n",
        "\n",
        "                    #################################### Mean ##############################################\n",
        "\n",
        "\n",
        "\n",
        "            ######### Acceleration ###################\n",
        "\n",
        "    # Calculate mean of Acceleration segment\n",
        "    x_acc_move_mean_segment = np.mean(xs_acc_move)\n",
        "    y_acc_move_mean_segment = np.mean(ys_acc_move)\n",
        "    z_acc_move_mean_segment = np.mean(zs_acc_move)\n",
        "\n",
        "    # Append mean of Acceleration segment\n",
        "    mean_x_acc_move.append(x_acc_move_mean_segment)\n",
        "    mean_y_acc_move.append(y_acc_move_mean_segment)\n",
        "    mean_z_acc_move.append(z_acc_move_mean_segment)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            ########### Magnetometer ###################\n",
        "\n",
        "    # Calculate mean of Magnetometer segment\n",
        "    x_magnet_mean_segment = np.mean(xs_magnet)\n",
        "    y_magnet_mean_segment = np.mean(ys_magnet)\n",
        "    z_magnet_mean_segment = np.mean(zs_magnet)\n",
        "\n",
        "    # Append mean of Magnetometer segment\n",
        "    mean_x_magnet.append(x_magnet_mean_segment)\n",
        "    mean_y_magnet.append(y_magnet_mean_segment)\n",
        "    mean_z_magnet.append(z_magnet_mean_segment)\n",
        "\n",
        "\n",
        "\n",
        "            ########### Gyro ###################\n",
        "\n",
        "    # Calculate mean of Gyro segment\n",
        "    pitch_gyro_mean_segment = np.mean(pitch_s_gyro)\n",
        "    roll_gyro_mean_segment  = np.mean(roll_s_gyro)\n",
        "    yaw_gyro_mean_segment   = np.mean(yaw_s_gyro)\n",
        "\n",
        "    # Append mean of Gyro segment\n",
        "    mean_pitch_gyro.append(pitch_gyro_mean_segment)\n",
        "    mean_roll_gyro.append(roll_gyro_mean_segment)\n",
        "    mean_yaw_gyro.append(yaw_gyro_mean_segment)\n",
        "\n",
        "\n",
        "\n",
        "                    #################################### STD  ##############################################\n",
        "  \n",
        "\n",
        "                ########### Acceleration ###################\n",
        "\n",
        "    # Calculate std of Acceleration segment\n",
        "    x_acc_move_std_segment = np.std(xs_acc_move)\n",
        "    y_acc_move_std_segment = np.std(ys_acc_move)\n",
        "    z_acc_move_std_segment = np.std(zs_acc_move)\n",
        "\n",
        "    # Append std of Acceleration segment\n",
        "    std_x_acc_move.append(x_acc_move_std_segment)\n",
        "    std_y_acc_move.append(y_acc_move_std_segment)\n",
        "    std_z_acc_move.append(z_acc_move_std_segment)\n",
        "\n",
        "\n",
        "                ########### Magnetometer ###################\n",
        "\n",
        "    # Calculate std of Magnetometer segment\n",
        "    x_magnet_std_segment = np.std(xs_magnet)\n",
        "    y_magnet_std_segment = np.std(ys_magnet)\n",
        "    z_magnet_std_segment = np.std(zs_magnet)\n",
        "\n",
        "    # Append std of Magnetometer segment\n",
        "    std_x_magnet.append(x_magnet_std_segment)\n",
        "    std_y_magnet.append(y_magnet_std_segment)\n",
        "    std_z_magnet.append(z_magnet_std_segment)\n",
        "\n",
        "\n",
        "\n",
        "            ########### Gyro ###################\n",
        "\n",
        "    # Calculate std of Gyro segment\n",
        "    pitch_gyro_std_segment = np.std(pitch_s_gyro)\n",
        "    roll_gyro_std_segment  = np.std(roll_s_gyro)\n",
        "    yaw_gyro_std_segment   = np.std(yaw_s_gyro)\n",
        "\n",
        "    # Append std of Gyro segment\n",
        "    std_pitch_gyro.append(pitch_gyro_std_segment)\n",
        "    std_roll_gyro.append(roll_gyro_std_segment)\n",
        "    std_yaw_gyro.append(yaw_gyro_std_segment)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "                    #################################### median absolute deviation ##############################################\n",
        "\n",
        "\n",
        "\n",
        "                ########### Acceleration ###################\n",
        "\n",
        "    # Calculate median absolute deviation of Acceleration segment\n",
        "    x_acc_move_mad_segment = stats.median_absolute_deviation(xs_acc_move)\n",
        "    y_acc_move_mad_segment = stats.median_absolute_deviation(ys_acc_move)\n",
        "    z_acc_move_mad_segment = stats.median_absolute_deviation(zs_acc_move)\n",
        "\n",
        "    # Append median absolute deviation of Acceleration segment\n",
        "    mad_x_acc_move.append(x_acc_move_mad_segment)\n",
        "    mad_y_acc_move.append(y_acc_move_mad_segment)\n",
        "    mad_z_acc_move.append(z_acc_move_mad_segment)\n",
        "\n",
        "\n",
        "\n",
        "                ########### Magnetometer ###################\n",
        "\n",
        "    # Calculate median absolute deviation of Magnetometer segment\n",
        "    x_magnet_mad_segment = stats.median_absolute_deviation(xs_magnet)\n",
        "    y_magnet_mad_segment = stats.median_absolute_deviation(ys_magnet)\n",
        "    z_magnet_mad_segment = stats.median_absolute_deviation(zs_magnet)\n",
        "\n",
        "    # Append median absolute deviation of Magnetometer segment\n",
        "    mad_x_magnet.append(x_magnet_mad_segment)\n",
        "    mad_y_magnet.append(y_magnet_mad_segment)\n",
        "    mad_z_magnet.append(z_magnet_mad_segment)\n",
        "\n",
        "\n",
        "\n",
        "            ########### Gyro ###################\n",
        "\n",
        "    # Calculate median absolute deviation of Gyro segment\n",
        "    pitch_gyro_mad_segment = stats.median_absolute_deviation(pitch_s_gyro)\n",
        "    roll_gyro_mad_segment  = stats.median_absolute_deviation(roll_s_gyro)\n",
        "    yaw_gyro_mad_segment   = stats.median_absolute_deviation(yaw_s_gyro)\n",
        "\n",
        "    # Append median absolute deviation of Gyro segment\n",
        "    mad_pitch_gyro.append(pitch_gyro_mad_segment)\n",
        "    mad_roll_gyro.append(roll_gyro_mad_segment)\n",
        "    mad_yaw_gyro.append(yaw_gyro_mad_segment)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "                    #################################### max value in segment/array  ##############################################\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "                ########### Acceleration ###################\n",
        "\n",
        "    # Calculate max of Acceleration segment\n",
        "    x_acc_move_max_segment = np.max(xs_acc_move)\n",
        "    y_acc_move_max_segment = np.max(ys_acc_move)\n",
        "    z_acc_move_max_segment = np.max(zs_acc_move)\n",
        "\n",
        "    # Append max of Acceleration segment\n",
        "    max_x_acc_move.append(x_acc_move_max_segment)\n",
        "    max_y_acc_move.append(y_acc_move_max_segment)\n",
        "    max_z_acc_move.append(z_acc_move_max_segment)\n",
        "\n",
        "\n",
        "                ########### Magnetometer ###################\n",
        "\n",
        "    # Calculate max of Magnetometer segment\n",
        "    x_magnet_max_segment = np.max(xs_magnet)\n",
        "    y_magnet_max_segment = np.max(ys_magnet)\n",
        "    z_magnet_max_segment = np.max(zs_magnet)\n",
        "\n",
        "    # Append max of Magnetometer segment\n",
        "    max_x_magnet.append(x_magnet_max_segment)\n",
        "    max_y_magnet.append(y_magnet_max_segment)\n",
        "    max_z_magnet.append(z_magnet_max_segment)\n",
        "\n",
        "\n",
        "\n",
        "                ########### Gyro ###################\n",
        "\n",
        "    # Calculate max of Gyro segment\n",
        "    pitch_gyro_max_segment = np.max(pitch_s_gyro)\n",
        "    roll_gyro_max_segment  = np.max(roll_s_gyro)\n",
        "    yaw_gyro_max_segment   = np.max(yaw_s_gyro)\n",
        "\n",
        "    # Append max of Gyro segment\n",
        "    max_pitch_gyro.append(pitch_gyro_max_segment)\n",
        "    max_roll_gyro.append(roll_gyro_max_segment)\n",
        "    max_yaw_gyro.append(yaw_gyro_max_segment)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "                    #################################### min value in segment/array  ##############################################\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "                ########### Acceleration ###################\n",
        "\n",
        "    # Calculate min of Acceleration segment\n",
        "    x_acc_move_min_segment = np.min(xs_acc_move)\n",
        "    y_acc_move_min_segment = np.min(ys_acc_move)\n",
        "    z_acc_move_min_segment = np.min(zs_acc_move)\n",
        "\n",
        "    # Append min of Acceleration segment\n",
        "    min_x_acc_move.append(x_acc_move_min_segment)\n",
        "    min_y_acc_move.append(y_acc_move_min_segment)\n",
        "    min_z_acc_move.append(z_acc_move_min_segment)\n",
        "\n",
        "\n",
        "\n",
        "                ########### Magnetometer ###################\n",
        "\n",
        "    # Calculate min of Magnetometer segment\n",
        "    x_magnet_min_segment = np.min(xs_magnet)\n",
        "    y_magnet_min_segment = np.min(ys_magnet)\n",
        "    z_magnet_min_segment = np.min(zs_magnet)\n",
        "\n",
        "    # Append min of Magnetometer segment\n",
        "    min_x_magnet.append(x_magnet_min_segment)\n",
        "    min_y_magnet.append(y_magnet_min_segment)\n",
        "    min_z_magnet.append(z_magnet_min_segment)\n",
        "\n",
        "\n",
        "\n",
        "                    ########### Gyro ###################\n",
        "\n",
        "    # Calculate min of Gyro segment\n",
        "    pitch_gyro_min_segment = np.min(pitch_s_gyro)\n",
        "    roll_gyro_min_segment  = np.min(roll_s_gyro)\n",
        "    yaw_gyro_min_segment   = np.min(yaw_s_gyro)\n",
        "\n",
        "    # Append min of Gyro segment\n",
        "    min_pitch_gyro.append(pitch_gyro_min_segment)\n",
        "    min_roll_gyro.append(roll_gyro_min_segment)\n",
        "    min_yaw_gyro.append(yaw_gyro_min_segment)\n",
        "\n",
        "\n",
        "\n",
        "                    ####################################  SMA (signal magnitude area) ##############################################\n",
        "\n",
        "\n",
        "                ########### Acceleration ###################\n",
        "\n",
        "    # Calculate SMA of Acceleration segment\n",
        "    sma_acc_segment = sma(xs_acc_move , ys_acc_move, zs_acc_move)\n",
        "\n",
        "    # Append SMA of Acceleration segment\n",
        "    sma_acc_move.append(sma_acc_segment)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "                ########### Magnetometer ###################\n",
        "\n",
        "    # Calculate SMA of Magnetometer segment\n",
        "    sma_magnet_segment = sma(xs_magnet, ys_magnet , zs_magnet)\n",
        "\n",
        "\n",
        "    # Append SMA  of Magnetometer segment\n",
        "    sma_magnet.append(sma_magnet_segment)\n",
        "\n",
        "\n",
        "\n",
        "                    ########### Gyro ###################\n",
        "\n",
        "    # Calculate SMA  of Gyro segment\n",
        "    sma_gyro_segment = sma(pitch_s_gyro, roll_s_gyro , yaw_s_gyro)\n",
        "\n",
        "\n",
        "    # Append SMA  of Gyro segment\n",
        "    sma_gyro.append(sma_gyro_segment)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "                    ####################################  Energy (sum of squares divided by number of values) ##############################################\n",
        "\n",
        "\n",
        "\n",
        "                ########### Acceleration ###################\n",
        "\n",
        "    # Calculate energy of Acceleration segment\n",
        "    energy_acc_segment = energy(xs_acc_move , ys_acc_move, zs_acc_move)\n",
        "\n",
        "    # Append energy of Acceleration segment\n",
        "    energy_acc_move.append(energy_acc_segment)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "                    ########### Magnetometer ###################\n",
        "\n",
        "    # Calculate energy of Magnetometer segment\n",
        "    energy_magnet_segment = energy(xs_magnet, ys_magnet , zs_magnet)\n",
        "\n",
        "\n",
        "    # Append energy  of Magnetometer segment\n",
        "    energy_magnet.append(energy_magnet_segment)\n",
        "\n",
        "\n",
        "\n",
        "                    ########### Gyro ###################\n",
        "\n",
        "    # Calculate energy of Gyro segment\n",
        "    energy_gyro_segment = energy(pitch_s_gyro, roll_s_gyro , yaw_s_gyro)\n",
        "\n",
        "\n",
        "    # Append energy of Gyro segment\n",
        "    energy_gyro.append(energy_gyro_segment)\n",
        "\n",
        "\n",
        "\n",
        "                    ####################################  IQR  ##############################################\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "                ########### Acceleration ###################\n",
        "\n",
        "    # Calculate IQR of Acceleration segment\n",
        "    x_acc_move_iqr_segment = stats.iqr(xs_acc_move)\n",
        "    y_acc_move_iqr_segment = stats.iqr(ys_acc_move)\n",
        "    z_acc_move_iqr_segment = stats.iqr(zs_acc_move)\n",
        "\n",
        "    # Append IQR of Acceleration segment\n",
        "    iqr_x_acc_move.append(x_acc_move_iqr_segment)\n",
        "    iqr_y_acc_move.append(y_acc_move_iqr_segment)\n",
        "    iqr_z_acc_move.append(z_acc_move_iqr_segment)\n",
        "\n",
        "\n",
        "\n",
        "                ########### Magnetometer ###################\n",
        "\n",
        "    # Calculate IQR of Magnetometer segment\n",
        "    x_magnet_iqr_segment = stats.iqr(xs_magnet)\n",
        "    y_magnet_iqr_segment = stats.iqr(ys_magnet)\n",
        "    z_magnet_iqr_segment = stats.iqr(zs_magnet)\n",
        "\n",
        "    # Append IQR of Magnetometer segment\n",
        "    iqr_x_magnet.append(x_magnet_iqr_segment)\n",
        "    iqr_y_magnet.append(y_magnet_iqr_segment)\n",
        "    iqr_z_magnet.append(z_magnet_iqr_segment)\n",
        "\n",
        "\n",
        "                ########### Gyro ###################\n",
        "\n",
        "    # Calculate IQR of Gyro segment\n",
        "    pitch_gyro_iqr_segment = stats.iqr(pitch_s_gyro)\n",
        "    roll_gyro_iqr_segment  = stats.iqr(roll_s_gyro)\n",
        "    yaw_gyro_iqr_segment   = stats.iqr(yaw_s_gyro)\n",
        "\n",
        "    # Append IQR  of Gyro segment\n",
        "    iqr_pitch_gyro.append(pitch_gyro_iqr_segment)\n",
        "    iqr_roll_gyro.append(roll_gyro_iqr_segment)\n",
        "    iqr_yaw_gyro.append(yaw_gyro_iqr_segment)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "                    ####################################  Signal Entropy    ##############################################\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "                ########### Acceleration ###################\n",
        "\n",
        "    # Calculate Signal Entropy  of Acceleration segment\n",
        "    x_acc_move_entropy_segment = stats.entropy(xs_acc_move)\n",
        "    y_acc_move_entropy_segment = stats.entropy(ys_acc_move)\n",
        "    z_acc_move_entropy_segment = stats.entropy(zs_acc_move)\n",
        "\n",
        "    # Append Signal Entropy  of Acceleration segment\n",
        "    entropy_x_acc_move.append(x_acc_move_entropy_segment)\n",
        "    entropy_y_acc_move.append(y_acc_move_entropy_segment)\n",
        "    entropy_z_acc_move.append(z_acc_move_entropy_segment)\n",
        "\n",
        "\n",
        "\n",
        "                    ########### Magnetometer ###################\n",
        "\n",
        "    # Calculate entropy of Magnetometer segment\n",
        "    x_magnet_entropy_segment = stats.entropy(xs_magnet)\n",
        "    y_magnet_entropy_segment = stats.entropy(ys_magnet)\n",
        "    z_magnet_entropy_segment = stats.entropy(zs_magnet)\n",
        "\n",
        "    # Append entropy of Magnetometer segment\n",
        "    entropy_x_magnet.append(x_magnet_entropy_segment)\n",
        "    entropy_y_magnet.append(y_magnet_entropy_segment)\n",
        "    entropy_z_magnet.append(z_magnet_entropy_segment)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "                    ########### Gyro ###################\n",
        "\n",
        "    # Calculate entropy of Gyro segment\n",
        "    pitch_gyro_entropy_segment = stats.entropy(pitch_s_gyro)\n",
        "    roll_gyro_entropy_segment  = stats.entropy(roll_s_gyro)\n",
        "    yaw_gyro_entropy_segment   = stats.entropy(yaw_s_gyro)\n",
        "\n",
        "    # Append entropy  of Gyro segment\n",
        "    entropy_pitch_gyro.append(pitch_gyro_entropy_segment)\n",
        "    entropy_roll_gyro.append(roll_gyro_entropy_segment)\n",
        "    entropy_yaw_gyro.append(yaw_gyro_entropy_segment)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "                    #################################### Correlation between 2 signals   ##############################################\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "                ########### Acceleration ###################\n",
        "\n",
        "    # Calculate Correlation between 2 signals of Acceleration segment\n",
        "    xy_acc_move_corr_segment = np.corrcoef(xs_acc_move,ys_acc_move)\n",
        "    xz_acc_move_corr_segment = np.corrcoef(xs_acc_move,zs_acc_move)\n",
        "    yz_acc_move_corr_segment = np.corrcoef(ys_acc_move,zs_acc_move)\n",
        "\n",
        "    # since this is a matrix with 1 on diagonals and off diagonal are equal\n",
        "    # just access one of the off diagonal elements \n",
        "    corr_xy_acc_move.append(xy_acc_move_corr_segment[0][1])\n",
        "    corr_xz_acc_move.append(xz_acc_move_corr_segment[0][1])\n",
        "    corr_yz_acc_move.append(yz_acc_move_corr_segment[0][1])\n",
        "\n",
        "\n",
        "\n",
        "                ########### Magnetometer ###################\n",
        "\n",
        "    # Calculate Correlation between 2 signals of Magnetometer segment\n",
        "    xy_magnet_corr_segment = np.corrcoef(xs_magnet, ys_magnet)\n",
        "    xz_magnet_corr_segment = np.corrcoef(xs_magnet, zs_magnet)\n",
        "    yz_magnet_corr_segment = np.corrcoef(ys_magnet ,zs_magnet)\n",
        "\n",
        "    # Append Correlation between 2 signals of Magnetometer segment\n",
        "    corr_xy_magnet.append(xy_magnet_corr_segment[0][1])\n",
        "    corr_xz_magnet.append(xz_magnet_corr_segment[0][1])\n",
        "    corr_yz_magnet.append(yz_magnet_corr_segment[0][1])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "                ########### Gyro ###################\n",
        "\n",
        "    # Calculate entropy of Gyro segment\n",
        "    pitch_roll_gyro_corr_segment = np.corrcoef(pitch_s_gyro, roll_s_gyro)\n",
        "    pitch_yaw_gyro_corr_segment  = np.corrcoef(pitch_s_gyro, yaw_s_gyro)\n",
        "    roll_yaw_gyro_corr_segment   = np.corrcoef(roll_s_gyro, yaw_s_gyro)\n",
        "\n",
        "    # Append entropy  of Gyro segment\n",
        "    corr_pitch_roll_gyro.append(pitch_roll_gyro_corr_segment[0][1])\n",
        "    corr_pitch_yaw_gyro.append(pitch_yaw_gyro_corr_segment[0][1])\n",
        "    corr_roll_yaw_gyro.append(roll_yaw_gyro_corr_segment[0][1])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "################################################################## End of Hand Craft Features ##################################################################################################\n",
        "  \n",
        "\n",
        "  # Set Up dataframe for handcraft features \n",
        "  handcraft_features_segment_df = pd.DataFrame()\n",
        "\n",
        "  # Assign values\n",
        "\n",
        "\n",
        "  ##################  Mean  ###################### \n",
        "  handcraft_features_segment_df['X_Mean_Acc_Move'] = mean_x_acc_move\n",
        "  handcraft_features_segment_df['Y_Mean_Acc_Move'] = mean_y_acc_move\n",
        "  handcraft_features_segment_df['Z_Mean_Acc_Move'] = mean_z_acc_move\n",
        "\n",
        "  handcraft_features_segment_df['X_Mean_Magnet'] = mean_x_magnet\n",
        "  handcraft_features_segment_df['Y_Mean_Magnet'] = mean_y_magnet\n",
        "  handcraft_features_segment_df['Z_Mean_Magnet'] = mean_z_magnet\n",
        "\n",
        "  handcraft_features_segment_df['Pitch_Mean_Gyro'] = mean_pitch_gyro\n",
        "  handcraft_features_segment_df['Roll_Mean_Gyro']  = mean_roll_gyro\n",
        "  handcraft_features_segment_df['Yaw_Mean_Gyro']   = mean_yaw_gyro\n",
        "\n",
        "\n",
        "  ################### FFT Energy Bands #########################\n",
        "  handcraft_features_segment_df['X_Acc_Move_FFT_EnergyBands_0Hz'] =  energybands_fft_acc_x_0\n",
        "  handcraft_features_segment_df['Y_Acc_Move_FFT_EnergyBands_0Hz'] =  energybands_fft_acc_y_0\n",
        "  handcraft_features_segment_df['Z_Acc_Move_FFT_EnergyBands_0Hz'] =  energybands_fft_acc_z_0\n",
        "\n",
        "\n",
        "  handcraft_features_segment_df['X_Acc_Move_FFT_EnergyBands_10Hz'] =  energybands_fft_acc_x_10\n",
        "  handcraft_features_segment_df['Y_Acc_Move_FFT_EnergyBands_10Hz'] =  energybands_fft_acc_y_10\n",
        "  handcraft_features_segment_df['Z_Acc_Move_FFT_EnergyBands_10Hz'] =  energybands_fft_acc_z_10\n",
        "\n",
        "\n",
        "  handcraft_features_segment_df['X_Acc_Move_FFT_EnergyBands_20Hz'] =  energybands_fft_acc_x_20\n",
        "  handcraft_features_segment_df['Y_Acc_Move_FFT_EnergyBands_20Hz'] =  energybands_fft_acc_y_20\n",
        "  handcraft_features_segment_df['Z_Acc_Move_FFT_EnergyBands_20Hz'] =  energybands_fft_acc_z_20\n",
        "\n",
        "\n",
        "  handcraft_features_segment_df['X_Acc_Move_FFT_EnergyBands_30Hz'] =  energybands_fft_acc_x_30\n",
        "  handcraft_features_segment_df['Y_Acc_Move_FFT_EnergyBands_30Hz'] =  energybands_fft_acc_y_30\n",
        "  handcraft_features_segment_df['Z_Acc_Move_FFT_EnergyBands_30Hz'] =  energybands_fft_acc_z_30\n",
        "\n",
        "\n",
        "  handcraft_features_segment_df['X_Acc_Move_FFT_EnergyBands_40Hz'] =  energybands_fft_acc_x_40\n",
        "  handcraft_features_segment_df['Y_Acc_Move_FFT_EnergyBands_40Hz'] =  energybands_fft_acc_y_40\n",
        "  handcraft_features_segment_df['Z_Acc_Move_FFT_EnergyBands_40Hz'] =  energybands_fft_acc_z_40\n",
        "\n",
        "\n",
        "  handcraft_features_segment_df['X_Acc_Move_FFT_EnergyBands_50Hz'] =  energybands_fft_acc_x_50\n",
        "  handcraft_features_segment_df['Y_Acc_Move_FFT_EnergyBands_50Hz'] =  energybands_fft_acc_y_50\n",
        "  handcraft_features_segment_df['Z_Acc_Move_FFT_EnergyBands_50Hz'] =  energybands_fft_acc_z_50\n",
        "\n",
        "\n",
        "  ################### FFT Dominant Frequency #########################\n",
        "  handcraft_features_segment_df['X_Acc_Move_FFT_DominantFrequency'] =  maxfreq_fft_acc_x\n",
        "  handcraft_features_segment_df['Y_Acc_Move_FFT_DominantFrequency'] =  maxfreq_fft_acc_y\n",
        "  handcraft_features_segment_df['Z_Acc_Move_FFT_DominantFrequency'] =  maxfreq_fft_acc_z\n",
        "\n",
        "\n",
        "  ################### FFT Max Power #########################\n",
        "  handcraft_features_segment_df['X_Acc_Move_FFT_MaxPower'] = maxpower_fft_acc_x\n",
        "  handcraft_features_segment_df['Y_Acc_Move_FFT_MaxPower'] = maxpower_fft_acc_y\n",
        "  handcraft_features_segment_df['Z_Acc_Move_FFT_MaxPower'] = maxpower_fft_acc_z\n",
        "\n",
        "  ################### FFT Mean Weighted Frequency #########################\n",
        "  handcraft_features_segment_df['X_Acc_Move_FFT_MeanWeightedFrequency'] = meanfreq_fft_acc_x\n",
        "  handcraft_features_segment_df['Y_Acc_Move_FFT_MeanWeightedFrequency'] = meanfreq_fft_acc_y\n",
        "  handcraft_features_segment_df['Z_Acc_Move_FFT_MeanWeightedFrequency'] = meanfreq_fft_acc_z\n",
        "\n",
        "\n",
        "  ################### FFT Skewness Frequency #########################\n",
        "  handcraft_features_segment_df['X_Acc_Move_FFT_SkewnessFrequency'] = meanfreq_fft_acc_x\n",
        "  handcraft_features_segment_df['Y_Acc_Move_FFT_SkewnessFrequency'] = meanfreq_fft_acc_y\n",
        "  handcraft_features_segment_df['Z_Acc_Move_FFT_SkewnessFrequency'] = meanfreq_fft_acc_z\n",
        "\n",
        "\n",
        "  ################### FFT Kurtosis Frequency #########################\n",
        "  handcraft_features_segment_df['X_Acc_Move_FFT_KurtosisFrequency'] =  kurtfreq_fft_acc_x\n",
        "  handcraft_features_segment_df['Y_Acc_Move_FFT_KurtosisFrequency'] =  kurtfreq_fft_acc_y\n",
        "  handcraft_features_segment_df['Z_Acc_Move_FFT_KurtosisFrequency'] =  kurtfreq_fft_acc_z\n",
        "\n",
        "\n",
        "\n",
        "  ################## Change of Signs of Magnetometer  ###################### \n",
        "  handcraft_features_segment_df['X_Magnet_ChangeOfSign'] = change_in_sign_x_magnet\n",
        "  handcraft_features_segment_df['Y_Magnet_ChangeOfSign'] = change_in_sign_y_magnet\n",
        "  handcraft_features_segment_df['Z_Magnet_ChangeOfSign'] = change_in_sign_z_magnet\n",
        "\n",
        "\n",
        "\n",
        "  ##################  STD  ###################### \n",
        "  handcraft_features_segment_df['X_std_Acc_Move'] = std_x_acc_move\n",
        "  handcraft_features_segment_df['Y_std_Acc_Move'] = std_y_acc_move\n",
        "  handcraft_features_segment_df['Z_std_Acc_Move'] = std_z_acc_move\n",
        "\n",
        "  handcraft_features_segment_df['X_std_Magnet'] = std_x_magnet\n",
        "  handcraft_features_segment_df['Y_std_Magnet'] = std_y_magnet\n",
        "  handcraft_features_segment_df['Z_std_Magnet'] = std_z_magnet\n",
        "\n",
        "  handcraft_features_segment_df['Pitch_std_Gyro'] = std_pitch_gyro\n",
        "  handcraft_features_segment_df['Roll_std_Gyro']  = std_roll_gyro\n",
        "  handcraft_features_segment_df['Yaw_std_Gyro']   = std_yaw_gyro\n",
        "\n",
        "\n",
        "\n",
        "  ##################  Median Absolute Deviation ###################### \n",
        "  handcraft_features_segment_df['X_mad_Acc_Move'] = mad_x_acc_move\n",
        "  handcraft_features_segment_df['Y_mad_Acc_Move'] = mad_y_acc_move\n",
        "  handcraft_features_segment_df['Z_mad_Acc_Move'] = mad_z_acc_move\n",
        "\n",
        "  handcraft_features_segment_df['X_mad_Magnet'] = mad_x_magnet\n",
        "  handcraft_features_segment_df['Y_mad_Magnet'] = mad_y_magnet\n",
        "  handcraft_features_segment_df['Z_mad_Magnet'] = mad_z_magnet\n",
        "\n",
        "  handcraft_features_segment_df['Pitch_mad_Gyro'] = mad_pitch_gyro\n",
        "  handcraft_features_segment_df['Roll_mad_Gyro']  = mad_roll_gyro\n",
        "  handcraft_features_segment_df['Yaw_mad_Gyro']   = mad_yaw_gyro\n",
        "\n",
        "\n",
        "\n",
        "  # ##################  Max value  ###################### \n",
        "  handcraft_features_segment_df['X_max_Acc_Move'] = max_x_acc_move\n",
        "  handcraft_features_segment_df['Y_max_Acc_Move'] = max_y_acc_move\n",
        "  handcraft_features_segment_df['Z_max_Acc_Move'] = max_z_acc_move\n",
        "\n",
        "  handcraft_features_segment_df['X_max_Magnet'] = max_x_magnet\n",
        "  handcraft_features_segment_df['Y_max_Magnet'] = max_y_magnet\n",
        "  handcraft_features_segment_df['Z_max_Magnet'] = max_z_magnet\n",
        "\n",
        "  handcraft_features_segment_df['Pitch_max_Gyro'] = max_pitch_gyro\n",
        "  handcraft_features_segment_df['Roll_max_Gyro']  = max_roll_gyro\n",
        "  handcraft_features_segment_df['Yaw_max_Gyro']   = max_yaw_gyro\n",
        "\n",
        "\n",
        "\n",
        "  ##################  Min value  ###################### \n",
        "  handcraft_features_segment_df['X_min_Acc_Move'] = min_x_acc_move\n",
        "  handcraft_features_segment_df['Y_min_Acc_Move'] = min_y_acc_move\n",
        "  handcraft_features_segment_df['Z_min_Acc_Move'] = min_z_acc_move\n",
        "\n",
        "  handcraft_features_segment_df['X_min_Magnet'] = min_x_magnet\n",
        "  handcraft_features_segment_df['Y_min_Magnet'] = min_y_magnet\n",
        "  handcraft_features_segment_df['Z_min_Magnet'] = min_z_magnet\n",
        "\n",
        "  handcraft_features_segment_df['Pitch_min_Gyro'] = min_pitch_gyro\n",
        "  handcraft_features_segment_df['Roll_min_Gyro']  = min_roll_gyro\n",
        "  handcraft_features_segment_df['Yaw_min_Gyro']   = min_yaw_gyro\n",
        "\n",
        "\n",
        "\n",
        "  ##################  Signal Magnitude area (SMA)  ###################### \n",
        "  handcraft_features_segment_df['SMA_Acc_Move'] = sma_acc_move\n",
        "  handcraft_features_segment_df['SMA_Magnet'] = sma_magnet\n",
        "  handcraft_features_segment_df['SMA_Gyro'] = sma_gyro\n",
        "\n",
        "\n",
        "  ##################  Energy  ###################### \n",
        "  handcraft_features_segment_df['Energy_Acc_Move'] = energy_acc_move\n",
        "  handcraft_features_segment_df['Energy_Magnet']   = energy_magnet\n",
        "  handcraft_features_segment_df['Energy_Gyro']     = energy_gyro\n",
        "\n",
        "\n",
        "\n",
        "  ##################  IQR  ###################### \n",
        "  handcraft_features_segment_df['X_iqr_Acc_Move'] = iqr_x_acc_move\n",
        "  handcraft_features_segment_df['Y_iqr_Acc_Move'] = iqr_y_acc_move\n",
        "  handcraft_features_segment_df['Z_iqr_Acc_Move'] = iqr_z_acc_move\n",
        "\n",
        "  handcraft_features_segment_df['X_iqr_Magnet'] = iqr_x_magnet\n",
        "  handcraft_features_segment_df['Y_iqr_Magnet'] = iqr_y_magnet\n",
        "  handcraft_features_segment_df['Z_iqr_Magnet'] = iqr_z_magnet\n",
        "\n",
        "  handcraft_features_segment_df['Pitch_iqr_Gyro'] = iqr_pitch_gyro\n",
        "  handcraft_features_segment_df['Roll_iqr_Gyro']  = iqr_roll_gyro\n",
        "  handcraft_features_segment_df['Yaw_iqr_Gyro']   = iqr_yaw_gyro\n",
        "\n",
        "\n",
        "  ### seems to return inf for quite a lot of entries ###\n",
        "\n",
        "  ##################  Signal Entropy  ###################### \n",
        "  #handcraft_features_segment_df['X_entropy_Acc_Move'] = entropy_x_acc_move\n",
        "  #handcraft_features_segment_df['Y_entropy_Acc_Move'] = entropy_y_acc_move\n",
        "  #handcraft_features_segment_df['Z_entropy_Acc_Move'] = entropy_z_acc_move\n",
        "\n",
        "  #handcraft_features_segment_df['X_entropy_Magnet'] = entropy_x_magnet\n",
        "  #handcraft_features_segment_df['Y_entropy_Magnet'] = entropy_y_magnet\n",
        "  #handcraft_features_segment_df['Z_entropy_Magnet'] = entropy_z_magnet\n",
        "\n",
        "  \n",
        "\n",
        "  #handcraft_features_segment_df['Pitch_entropy_Gyro'] = entropy_pitch_gyro\n",
        "  #handcraft_features_segment_df['Roll_entropy_Gyro']  = entropy_roll_gyro\n",
        "  #handcraft_features_segment_df['Yaw_entropy_Gyro']   = entropy_yaw_gyro\n",
        "\n",
        "\n",
        "\n",
        "  ##################  Correlation ###################### \n",
        "  handcraft_features_segment_df['XY_corr_Acc_Move'] = corr_xy_acc_move\n",
        "  handcraft_features_segment_df['XZ_corr_Acc_Move'] = corr_xz_acc_move\n",
        "  handcraft_features_segment_df['YZ_corr_Acc_Move'] = corr_yz_acc_move\n",
        "\n",
        "  handcraft_features_segment_df['XY_corr_Magnet'] = corr_xy_magnet\n",
        "  handcraft_features_segment_df['XZ_corr_Magnet'] = corr_xz_magnet\n",
        "  handcraft_features_segment_df['YZ_corr_Magnet'] = corr_yz_magnet\n",
        "\n",
        "  handcraft_features_segment_df['Pitch_Roll_corr_Gyro'] = corr_pitch_roll_gyro\n",
        "  handcraft_features_segment_df['Pitch_Yaw_corr_Gyro']  = corr_pitch_yaw_gyro\n",
        "  handcraft_features_segment_df['Roll_Yaw_corr_Gyro']   = corr_roll_yaw_gyro\n",
        "\n",
        "\n",
        "  # Labels of each segment finally! \n",
        "  handcraft_features_segment_df['Label_segment']   = labels_seg\n",
        "\n",
        " \n",
        "  \n",
        "######################################## Normal Signal Segments Processing ############################################\n",
        "\n",
        "\n",
        "  # joining all signals together , so can use for shape \n",
        "  #segment_all = np.concatenate((segments_acc_move, segments_magnet , segments_gyro ))\n",
        "\n",
        "  # reshape all segments \n",
        "  #reshaped_segments = np.asarray(segment_all, dtype= np.float32).reshape(-1, N_TIME_STEPS, N_FEATURES)\n",
        "\n",
        "  # set up an array of size  n_time_steps rows and 9 cols X , Y , Z  for accelerometer , magnetometer, gyro \n",
        "  # and then there will be the number of segments of sliding rows (range(np.array(segments_acc_move).shape[0]))\n",
        "\n",
        "  array_setup_checker =  [  [ [ None for y in range( 9 ) ] for x in range( N_TIME_STEPS ) ] for z in range(np.array(segments_acc_move).shape[0]) ]\n",
        "\n",
        "\n",
        "  # now going to add in the values from arrays\n",
        "\n",
        "  # start for each window  \n",
        "  for window in range(np.array(array_setup_checker).shape[0]):\n",
        "\n",
        "    # then each segement\n",
        "    for i in range(np.array(array_setup_checker).shape[1]):\n",
        "\n",
        "      ################## Acceleration #####################################\n",
        "\n",
        "      # X-Axis Movement Acceleration\n",
        "      array_setup_checker[window][i][0] = segments_acc_move[window][0][i]\n",
        "      # Y-Axis Movement Acceleration\n",
        "      array_setup_checker[window][i][1] = segments_acc_move[window][1][i]\n",
        "      # Z-Axis Movement Acceleration\n",
        "      array_setup_checker[window][i][2] = segments_acc_move[window][2][i]\n",
        "\n",
        "\n",
        "      ################## Magnetometer #####################################\n",
        "\n",
        "      # X-Axis Movement Acceleration\n",
        "      array_setup_checker[window][i][3] = segments_magnet[window][0][i]\n",
        "      # Y-Axis Movement Acceleration\n",
        "      array_setup_checker[window][i][4] = segments_magnet[window][1][i]\n",
        "      # Z-Axis Movement Acceleration\n",
        "      array_setup_checker[window][i][5] = segments_magnet[window][2][i]\n",
        "\n",
        "\n",
        "\n",
        "      ################## Gyro #####################################\n",
        "\n",
        "      # X-Axis Movement Acceleration\n",
        "      array_setup_checker[window][i][6] = segments_gyro[window][0][i]\n",
        "      # Y-Axis Movement Acceleration\n",
        "      array_setup_checker[window][i][7] = segments_gyro[window][1][i]\n",
        "      # Z-Axis Movement Acceleration\n",
        "      array_setup_checker[window][i][8] = segments_gyro[window][2][i]\n",
        "\n",
        "\n",
        "  reshaped_segments = array_setup_checker\n",
        "\n",
        "\n",
        "############################################ Add ID & Run number to dataframes #######################################\n",
        "\n",
        "\n",
        "\n",
        "  # add ID and Run number to dataframes, incase want to identify particular \n",
        "  original_df_resampled['Participant_ID']            = ID\n",
        "  original_df_rotated_resampled['Participant_ID']    = ID\n",
        "  handcraft_features_segment_df['Participant_ID']    = ID\n",
        "\n",
        "  original_df_resampled['Participant_Run']            = Run\n",
        "  original_df_rotated_resampled['Participant_Run']    = Run\n",
        "  handcraft_features_segment_df['Participant_Run']    = Run\n",
        "\n",
        "\n",
        "\n",
        "######################### Checks if any NA exist in dataframes and also plot gravity components to test re-oritenation ####################################\n",
        "\n",
        "\n",
        "  if handcraft_features_segment_df.isna().sum().any() != 0:\n",
        "    \"Print n.a still exist in  handcraft_features_segment_df!\"\n",
        "\n",
        "  if plots == True:\n",
        "\n",
        "    # one plot of Z gravity component\n",
        "    plt.plot( df_resampled_rotated['Z_Acc_Grav_R'] )\n",
        "    plt.xlabel(\"Time\")\n",
        "    plt.ylabel(\"Gravity Acceleration Z-Axis\")\n",
        "    plt.title(\"Gravity Component of Acceleration of Z-Axis\")\n",
        "    plt.show()\n",
        "\n",
        "    print(\"\\n\")\n",
        "\n",
        "    # plot of gravity components as a check to how well its re-orientated \n",
        "    fig, axs = plt.subplots(3 , constrained_layout=True , figsize=(7,7))\n",
        "    fig.suptitle('-----------------------------------------------Acceleration Due to Gravity Components - Re-orientated--------------------------------------------------------------------')\n",
        "\n",
        "    axs[0].title.set_text(\"X-Axis\")\n",
        "    axs[0].plot(df_resampled_rotated['X_Acc_Grav_R'])\n",
        "\n",
        "    axs[1].title.set_text(\"Y-Axis\")\n",
        "    axs[1].plot( df_resampled_rotated['Y_Acc_Grav_R'])\n",
        "\n",
        "    axs[2].title.set_text(\"Z-Axis\")\n",
        "    axs[2].plot( df_resampled_rotated['Z_Acc_Grav_R'])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  ######################## fin ##################\n",
        "\n",
        "  # first return (original_df_resampled) is not rotated, but the rest are\n",
        "\n",
        "\n",
        "  return original_df_resampled , original_df_rotated_resampled , handcraft_features_segment_df , reshaped_segments , labels_seg\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5YnzWau-Sdi"
      },
      "source": [
        "# Test Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODKLZbi8-R9z"
      },
      "source": [
        "# # # Accleration\n",
        "# accel = \"08-04-2015 04.08.05.518 - Right Coat Pocket - TrialFPSV3502 - Raw Acceleration.csv\" \n",
        "                        \n",
        "\n",
        "# # True Orientation \n",
        "# tog = \"08-04-2015 04.08.05.482 - Right Coat Pocket - TrialFPSV3502 - True Orientation Data.csv\" \n",
        "                       \n",
        "\n",
        "# # Magnetometer\n",
        "# maget = \"08-04-2015 04.08.05.545 - Right Coat Pocket - TrialFPSV3502 - Raw Magnetometer.csv\"\n",
        "\n",
        "# # Gyro\n",
        "# gyro = \"08-04-2015 04.08.05.572 - Right Coat Pocket - TrialFPSV3502 - Raw Gyro.csv\" \n",
        "                        \n",
        "\n",
        "# # Markers\n",
        "# markers = '08-04-2015 13.06.09.853 - TrialFPSV3502 - Markers.csv'\n",
        "                       \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlKYG0Sc0oyd"
      },
      "source": [
        "# a= [2,2,2,3]\n",
        "\n",
        "# #b = [1,2,3,4]\n",
        "\n",
        "# b = np.mean(a)\n",
        "\n",
        "# c = b-a\n",
        "\n",
        "# print(c)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K82KoTwWTGFh"
      },
      "source": [
        "#print(type(tog))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKZaSoH-nAM9"
      },
      "source": [
        "# preprocess function , step 50 datapoints (0.5 seconds) with 50% overlap (0.25 seconds)\n",
        "#original_df_resampled , original_df_rotated_resampled , handcraft_features_segment_df , reshaped_segments , labels_seg = preprocess_func(accel , tog, maget , gyro , markers , ID=88, Run = 2, fc= 0.3 , n_time_steps= 10 , step = 5 )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUnURodGSa5W"
      },
      "source": [
        "--------------------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3u969XR4s89i"
      },
      "source": [
        "#handcraft_features_segment_df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dmqb9LGBsUpH"
      },
      "source": [
        "#handcraft_features_segment_df['Y_Magnet_ChangeOfSign'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDTvADD_zNJg"
      },
      "source": [
        "--------------\n",
        "\n",
        "**DataFrame 1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmnG-Vs-AbLA"
      },
      "source": [
        "# original_df_resampled"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25mqfP1zzU21"
      },
      "source": [
        "------------------------------\n",
        "**DataFrame 2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfSXcCKhtvE2"
      },
      "source": [
        "# original_df_rotated_resampled"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qIlIQNP924p"
      },
      "source": [
        "# plt.plot( original_df_rotated_resampled.index , original_df_rotated_resampled['X_Acc_Move_R'] )\n",
        "# plt.plot(original_df_rotated_resampled['Label'])\n",
        "# plt.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mh3Nq98799hL"
      },
      "source": [
        "# plt.plot( original_df_rotated_resampled.index , original_df_rotated_resampled['X_Acc_Grav_R'] )\n",
        "# plt.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uI8J9GgozhI_"
      },
      "source": [
        "------------------------------------------\n",
        "**DataFrame 3**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_1ZzBNSzElV"
      },
      "source": [
        "# hand_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AspjH1fjzmsU"
      },
      "source": [
        "# hand_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7DNnoq47Pw9"
      },
      "source": [
        "----------------------------------\n",
        "Array 1 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XN2_vnJw7ONg"
      },
      "source": [
        "# # 15 segments for sliding window (to ensure all signal covered) , 256 points per segment , 9 features = X Acc Y Acc Z Acc , X Magnet Y Magnet Z Magnet , Gyro Pitch Gyro Roll Gyro Yaw \n",
        "# signals_seg.shape\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wsETIp98Xwr"
      },
      "source": [
        "--------------------\n",
        "Array 2 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NjC1Li0w71Ct"
      },
      "source": [
        "# labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tRZiSAbrFG6"
      },
      "source": [
        "------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMHEVaStKvme"
      },
      "source": [
        "-"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PoEq6MHIKwEB"
      },
      "source": [
        "-"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ot7GmLZKxNg"
      },
      "source": [
        "-"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Hy1dyL-KsTo"
      },
      "source": [
        "------------------------------------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9q27kVo1Kx4f"
      },
      "source": [
        "# Loop through preprocess for all of Participant runs "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAU8Z8I4MLgJ"
      },
      "source": [
        "# array_setup = list(array_setup)\n",
        "\n",
        "# #print(array_setup[0][1])\n",
        "\n",
        "# for i in array_setup[0][0].split(\" \"):\n",
        "\n",
        "#   if \"TrialFPSV\" in i:\n",
        "#     id = i[9:11]\n",
        "#     run = i[-1]\n",
        "\n",
        "# ID  = id\n",
        "# Run = run\n",
        "\n",
        "# print(ID, Run)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIkieUB8gEvr"
      },
      "source": [
        "print(len(big_array))\n",
        "\n",
        "print(len(big_array[0][0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s413UvaSfvLT"
      },
      "source": [
        "for i in range(len(big_array)):\n",
        "\n",
        "  #print(big_array[1][0][i])\n",
        "\n",
        "  print(big_array[0][0][i].split(\"-\"))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qx5tLthffx_O"
      },
      "source": [
        "--------------------------------\n",
        "\n",
        "Sliding Window 10-5 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9FeMWCsK257"
      },
      "source": [
        "for ID_run in range(len(big_array)):\n",
        "\n",
        "  print(f'\\n-----------------------------------------------------------------------  ID Run: {ID_run} -------------------------------------------------------------------\\n')\n",
        "\n",
        "  # will be iterating over 8 runs , 2-9 (inclusive so its 8)\n",
        "  # 5 outputs from preprocess:\n",
        "  # original_df_resampled , original_df_rotated_resampled , handcraft_features_segment_df , reshaped_segments , labels_seg\n",
        "\n",
        "  # lists to hold all 8 dataframes/arrays  , also resets in each loop\n",
        "  original_df_resampled_list = []\n",
        "  original_df_rotated_resampled_list = []\n",
        "  handcraft_features_segment_df_list = []\n",
        "  reshaped_segments_list = []\n",
        "  labels_seg_list = []\n",
        "\n",
        "  #################################################### Define Sliding Window Here! ################################################################\n",
        "\n",
        "  # define sliding window size \n",
        "  sliding_window_size = 100\n",
        "  overlap_window_size = 50\n",
        "\n",
        "\n",
        "\n",
        "  for i in range(len(big_array[0][0])):\n",
        "\n",
        "    print(f'\\n---------------------  ID Run: {ID_run}  -  Run{i} --------------------------------\\n')\n",
        "\n",
        "    ######################### set up cvs files names from array ##########################\n",
        "\n",
        "    # acceleration \n",
        "    acc = big_array[ID_run][0][i]\n",
        "\n",
        "    # true orientation\n",
        "    true_ori = big_array[ID_run][1][i]\n",
        "\n",
        "    # magnetometer\n",
        "    magnet = big_array[ID_run][2][i]\n",
        "\n",
        "    # gyro \n",
        "    gyro = big_array[ID_run][3][i]\n",
        "\n",
        "    # markers\n",
        "    markers = big_array[ID_run][4][i]\n",
        "\n",
        "\n",
        "    ########################### get participant ID and run  #################################\n",
        "\n",
        "    for m in big_array[ID_run][0][i].split(\" \"):\n",
        "\n",
        "      if \"TrialFPSV\" in m:\n",
        "        id = m[9:11]\n",
        "        run = m[-1]\n",
        "\n",
        "    ID  = id\n",
        "    Run = run \n",
        "\n",
        "    # get type of run , RCP , LCP etc\n",
        "    for n in big_array[ID_run][0]:\n",
        "\n",
        "      # split on dash as its easier to identify placement from this\n",
        "      splits_for_placement = n.split(\"-\")\n",
        "\n",
        "      if splits_for_placement[3] == ' Left Coat Pocket ':\n",
        "\n",
        "        placement = \"LCP\"\n",
        "\n",
        "      if splits_for_placement[3] == ' Right Coat Pocket ':\n",
        "\n",
        "        placement = \"RCP\"\n",
        "\n",
        "\n",
        "      if splits_for_placement[3] == ' Left Jeans Pocket ':\n",
        "\n",
        "        placement = \"LJP\"\n",
        "\n",
        "\n",
        "      if splits_for_placement[3] == ' Right Jeans Pocket ':\n",
        "\n",
        "        placement = \"RJP\"\n",
        "\n",
        "\n",
        "      if splits_for_placement[3] == ' Other ':\n",
        "\n",
        "        placement = \"OTH\"\n",
        "\n",
        "\n",
        "    Placement = placement\n",
        "\n",
        "    try:\n",
        "      # preprocess function , step 50 datapoints (0.5 seconds) with 50% overlap (0.25 seconds)\n",
        "      original_df_resampled , original_df_rotated_resampled , handcraft_features_segment_df , reshaped_segments , labels_seg = preprocess_func(acc , true_ori , magnet , gyro , markers , ID=ID, Run = Run , fc= 0.3 , n_time_steps= sliding_window_size , step = overlap_window_size)\n",
        "\n",
        "\n",
        "      ################### 1 Original DF Resampled  ########################\n",
        "      ## Write to CSV \n",
        "      original_df_resampled.to_csv(f'{ID}_{Run}_Participant_SlideSize_{sliding_window_size}_Original_DF_Resampled_{Placement}')\n",
        "\n",
        "\n",
        "      ################## 2 Original DF Rotated Resampled ##########################\n",
        "      ## Write to CSV \n",
        "      original_df_rotated_resampled.to_csv(f'{ID}_{Run}_Participant_SlideSize_{sliding_window_size}_Original_DF_Rotated_Resampled_{Placement}')\n",
        "\n",
        "\n",
        "      ################## 3 Handcrafted DF Rotated Resampled ##########################\n",
        "      ## Write to CSV \n",
        "      handcraft_features_segment_df.to_csv(f'{ID}_{Run}_Participant_SlideSize_{sliding_window_size}_Handcrafted_Features_DF_Resampled_{Placement}')\n",
        "\n",
        "\n",
        "      ################## 4 Signal Segments ##########################\n",
        "      # Write to numpy file\n",
        "      np.save(f'{ID}_{Run}_Participant_SlideSize_{sliding_window_size}_Signal_Segments_{Placement}', reshaped_segments) # save the file as \"outfile_name.npy\" \n",
        "\n",
        "\n",
        "      ################## 5 Label Segments ##########################\n",
        "      # Write to numpy file\n",
        "      np.save(f'{ID}_{Run}_Participant_SlideSize_{sliding_window_size}_Labels_Segments_{Placement}', labels_seg) # save the file as \"outfile_name.npy\" \n",
        "\n",
        "\n",
        "      # unique values contains an 'not set' dont dowloand the data \n",
        "\n",
        "      checker_notSet = 'not set' in np.unique(labels_seg)\n",
        "\n",
        "      if checker_notSet == True:\n",
        "\n",
        "        print(f'---------------------------------------------------------------')\n",
        "        print(f'\\nNot Downloading this set: {ID} , Not set is contained in labels')\n",
        "        print(f'---------------------------------------------------------------')\n",
        "\n",
        "      else:\n",
        "\n",
        "        ################################## Download files ###########################\n",
        "\n",
        "        #Download Files (I dont believe these are of any use for this project , however I'll leave code)\n",
        "        #files.download(f'{ID}_Participant_SlideSize_{sliding_window_size}_Original_DF_Resampled')\n",
        "        #files.download(f'{ID}_Participant_SlideSize_{sliding_window_size}_Original_DF_Rotated_Resampled')\n",
        "        \n",
        "\n",
        "        #Download Files \n",
        "        files.download(f'{ID}_{Run}_Participant_SlideSize_{sliding_window_size}_Handcrafted_Features_DF_Resampled_{Placement}')\n",
        "\n",
        "        files.download(f'{ID}_{Run}_Participant_SlideSize_{sliding_window_size}_Labels_Segments_{Placement}.npy')\n",
        "        files.download(f'{ID}_{Run}_Participant_SlideSize_{sliding_window_size}_Signal_Segments_{Placement}.npy')\n",
        "    \n",
        "    except:\n",
        "      print(f\"Exception Occured Run {i}\")\n",
        "      continue\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJ8d38b0myL3"
      },
      "source": [
        "#look_at_window = input(\"Stop in code to let downloads happen, press anything to proceed: \")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0kGkEkFypLCf"
      },
      "source": [
        "while True:\n",
        "  pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9i2fV4e3eiS0"
      },
      "source": [
        "--------------------------------------------------\n",
        "\n",
        "Sliding Size 10 - 5 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2u_2c5gfeh9q"
      },
      "source": [
        "# for ID_run in range(len(big_array)):\n",
        "\n",
        "#   print(f'\\n-----------------------------------------------------------------------  ID Run: {ID_run} -------------------------------------------------------------------\\n')\n",
        "\n",
        "#   # will be iterating over 8 runs , 2-9 (inclusive so its 8)\n",
        "#   # 5 outputs from preprocess:\n",
        "#   # original_df_resampled , original_df_rotated_resampled , handcraft_features_segment_df , reshaped_segments , labels_seg\n",
        "\n",
        "#   # lists to hold all 8 dataframes/arrays  , also resets in each loop\n",
        "#   original_df_resampled_list = []\n",
        "#   original_df_rotated_resampled_list = []\n",
        "#   handcraft_features_segment_df_list = []\n",
        "#   reshaped_segments_list = []\n",
        "#   labels_seg_list = []\n",
        "\n",
        "#   #################################################### Define Sliding Window Here! ################################################################\n",
        "\n",
        "#   # define sliding window size \n",
        "#   sliding_window_size = 10\n",
        "#   overlap_window_size = 5\n",
        "\n",
        "\n",
        "\n",
        "#   for i in range(len(big_array[0][0])):\n",
        "\n",
        "#     print(f'\\n---------------------  ID Run: {ID_run}  -  Run{i} --------------------------------\\n')\n",
        "\n",
        "#     ######################### set up cvs files names from array ##########################\n",
        "\n",
        "#     # acceleration \n",
        "#     acc = big_array[ID_run][0][i]\n",
        "\n",
        "#     # true orientation\n",
        "#     true_ori = big_array[ID_run][1][i]\n",
        "\n",
        "#     # magnetometer\n",
        "#     magnet = big_array[ID_run][2][i]\n",
        "\n",
        "#     # gyro \n",
        "#     gyro = big_array[ID_run][3][i]\n",
        "\n",
        "#     # markers\n",
        "#     markers = big_array[ID_run][4][i]\n",
        "\n",
        "\n",
        "#     ########################### get participant ID and run  #################################\n",
        "\n",
        "#     for m in big_array[ID_run][0][i].split(\" \"):\n",
        "\n",
        "#       if \"TrialFPSV\" in m:\n",
        "#         id = m[9:11]\n",
        "#         run = m[-1]\n",
        "\n",
        "#     ID  = id\n",
        "#     Run = run \n",
        "\n",
        "#     try:\n",
        "#       # preprocess function , step 50 datapoints (0.5 seconds) with 50% overlap (0.25 seconds)\n",
        "#       original_df_resampled , original_df_rotated_resampled , handcraft_features_segment_df , reshaped_segments , labels_seg = preprocess_func(acc , true_ori , magnet , gyro , markers , ID=ID, Run = Run , fc= 0.3 , n_time_steps= sliding_window_size , step = overlap_window_size)\n",
        "\n",
        "\n",
        "#       # append these to list \n",
        "#       original_df_resampled_list.append(original_df_resampled)\n",
        "#       original_df_rotated_resampled_list.append(original_df_rotated_resampled )\n",
        "#       handcraft_features_segment_df_list.append(handcraft_features_segment_df)\n",
        "#       reshaped_segments_list.append(reshaped_segments)\n",
        "#       labels_seg_list.append(labels_seg)\n",
        " \n",
        "#     except:\n",
        "#       print(f\"Exception Occured Run {i}\")\n",
        "#       continue\n",
        "\n",
        "\n",
        "#   # ################### 1 Original DF Resampled  ########################\n",
        "#   # # combine into one dataframe\n",
        "#   # original_df_resampled_list_participant = pd.concat(original_df_resampled_list)\n",
        "#   # ## Write to CSV \n",
        "#   # original_df_resampled_list_participant.to_csv(f'{ID}_Participant_SlideSize_{sliding_window_size}_Original_DF_Resampled')\n",
        "\n",
        "\n",
        "#   # ################## 2 Original DF Rotated Resampled ##########################\n",
        "#   # # combine into one dataframe\n",
        "#   # original_df_rotated_resampled_list_participant = pd.concat(original_df_rotated_resampled_list)\n",
        "#   # ## Write to CSV \n",
        "#   # original_df_rotated_resampled_list_participant.to_csv(f'{ID}_Participant_SlideSize_{sliding_window_size}_Original_DF_Rotated_Resampled')\n",
        "\n",
        "\n",
        "#   # ################## 3 Handcrafted DF Rotated Resampled ##########################\n",
        "#   # # combine into one dataframe\n",
        "#   # handcraft_features_segment_df_list_participant = pd.concat(handcraft_features_segment_df_list)\n",
        "#   # ## Write to CSV \n",
        "#   # handcraft_features_segment_df_list_participant.to_csv(f'{ID}_Participant_SlideSize_{sliding_window_size}_Handcrafted_Features_DF_Resampled')\n",
        "\n",
        "\n",
        "\n",
        "#   # ################## 4 Signal Segments ##########################\n",
        "#   # # combine into one array\n",
        "#   # reshaped_segments_list_participant = np.concatenate((reshaped_segments_list))\n",
        "#   # # Write to numpy file\n",
        "#   # np.save(f'{ID}_Participant_SlideSize_{sliding_window_size}_Signal_Segments', reshaped_segments_list_participant) # save the file as \"outfile_name.npy\" \n",
        "\n",
        "\n",
        "\n",
        "#   # ################## 5 Label Segments ##########################\n",
        "#   # # combine into one array\n",
        "#   # labels_seg_list_participant = np.concatenate((labels_seg_list))\n",
        "#   # # Write to numpy file\n",
        "#   # np.save(f'{ID}_Participant_SlideSize_{sliding_window_size}_Labels_Segments', labels_seg_list_participant) # save the file as \"outfile_name.npy\" \n",
        "\n",
        "\n",
        "#   # # unique values contains an 'not set' dont dowloand the data \n",
        "\n",
        "#   # checker_notSet = 'not set' in np.unique(labels_seg_list_participant)\n",
        "\n",
        "#   # if checker_notSet == True:\n",
        "\n",
        "#   #   print(f'---------------------------------------------------------------')\n",
        "#   #   print(f'\\nNot Downloading this set: {ID} , Not set is contained in labels')\n",
        "#   #   print(f'---------------------------------------------------------------')\n",
        "\n",
        "#   # else:\n",
        "\n",
        "#   #   ################################## Download files ###########################\n",
        "\n",
        "#   #   #Download Files (I dont believe these are of any use for this project , however I'll leave code)\n",
        "#   #   #files.download(f'{ID}_Participant_SlideSize_{sliding_window_size}_Original_DF_Resampled')\n",
        "#   #   #files.download(f'{ID}_Participant_SlideSize_{sliding_window_size}_Original_DF_Rotated_Resampled')\n",
        "    \n",
        "#   #   #Download Files \n",
        "#   #   files.download(f'{ID}_Participant_SlideSize_{sliding_window_size}_Handcrafted_Features_DF_Resampled')\n",
        "\n",
        "#   #   files.download(f'{ID}_Participant_SlideSize_{sliding_window_size}_Labels_Segments.npy')\n",
        "#   #   files.download(f'{ID}_Participant_SlideSize_{sliding_window_size}_Signal_Segments.npy')\n",
        "        \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOWZKlaLm5px"
      },
      "source": [
        "# look_at_window = input(\"Stop in code to let downloads happen, press anything to proceed: \")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAepjf4dep2e"
      },
      "source": [
        "----------------------------------------------\n",
        "\n",
        "Sliding Window 20 - 10 \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3B8clek_erwK"
      },
      "source": [
        "# for ID_run in range(len(big_array)):\n",
        "\n",
        "#   print(f'\\n-----------------------------------------------------------------------  ID Run: {ID_run} -------------------------------------------------------------------\\n')\n",
        "\n",
        "#   # will be iterating over 8 runs , 2-9 (inclusive so its 8)\n",
        "#   # 5 outputs from preprocess:\n",
        "#   # original_df_resampled , original_df_rotated_resampled , handcraft_features_segment_df , reshaped_segments , labels_seg\n",
        "\n",
        "#   # lists to hold all 8 dataframes/arrays  , also resets in each loop\n",
        "#   original_df_resampled_list = []\n",
        "#   original_df_rotated_resampled_list = []\n",
        "#   handcraft_features_segment_df_list = []\n",
        "#   reshaped_segments_list = []\n",
        "#   labels_seg_list = []\n",
        "\n",
        "#   #################################################### Define Sliding Window Here! ################################################################\n",
        "\n",
        "#   # define sliding window size \n",
        "#   sliding_window_size = 20\n",
        "#   overlap_window_size = 10\n",
        "\n",
        "\n",
        "\n",
        "#   for i in range(len(big_array[0][0])):\n",
        "\n",
        "#     print(f'\\n---------------------  ID Run: {ID_run}  -  Run{i} --------------------------------\\n')\n",
        "\n",
        "#     ######################### set up cvs files names from array ##########################\n",
        "\n",
        "#     # acceleration \n",
        "#     acc = big_array[ID_run][0][i]\n",
        "\n",
        "#     # true orientation\n",
        "#     true_ori = big_array[ID_run][1][i]\n",
        "\n",
        "#     # magnetometer\n",
        "#     magnet = big_array[ID_run][2][i]\n",
        "\n",
        "#     # gyro \n",
        "#     gyro = big_array[ID_run][3][i]\n",
        "\n",
        "#     # markers\n",
        "#     markers = big_array[ID_run][4][i]\n",
        "\n",
        "\n",
        "#     ########################### get participant ID and run  #################################\n",
        "\n",
        "#     for m in big_array[ID_run][0][i].split(\" \"):\n",
        "\n",
        "#       if \"TrialFPSV\" in m:\n",
        "#         id = m[9:11]\n",
        "#         run = m[-1]\n",
        "\n",
        "#     ID  = id\n",
        "#     Run = run \n",
        "\n",
        "#     try:\n",
        "#       # preprocess function , step 50 datapoints (0.5 seconds) with 50% overlap (0.25 seconds)\n",
        "#       original_df_resampled , original_df_rotated_resampled , handcraft_features_segment_df , reshaped_segments , labels_seg = preprocess_func(acc , true_ori , magnet , gyro , markers , ID=ID, Run = Run , fc= 0.3 , n_time_steps= sliding_window_size , step = overlap_window_size)\n",
        "\n",
        "\n",
        "#       # append these to list \n",
        "#       original_df_resampled_list.append(original_df_resampled)\n",
        "#       original_df_rotated_resampled_list.append(original_df_rotated_resampled )\n",
        "#       handcraft_features_segment_df_list.append(handcraft_features_segment_df)\n",
        "#       reshaped_segments_list.append(reshaped_segments)\n",
        "#       labels_seg_list.append(labels_seg)\n",
        " \n",
        "#     except:\n",
        "#       print(f\"Exception Occured Run {i}\")\n",
        "#       continue\n",
        "\n",
        "\n",
        "#   ################### 1 Original DF Resampled  ########################\n",
        "#   # combine into one dataframe\n",
        "#   original_df_resampled_list_participant = pd.concat(original_df_resampled_list)\n",
        "#   ## Write to CSV \n",
        "#   original_df_resampled_list_participant.to_csv(f'{ID}_Participant_SlideSize_{sliding_window_size}_Original_DF_Resampled')\n",
        "\n",
        "\n",
        "#   ################## 2 Original DF Rotated Resampled ##########################\n",
        "#   # combine into one dataframe\n",
        "#   original_df_rotated_resampled_list_participant = pd.concat(original_df_rotated_resampled_list)\n",
        "#   ## Write to CSV \n",
        "#   original_df_rotated_resampled_list_participant.to_csv(f'{ID}_Participant_SlideSize_{sliding_window_size}_Original_DF_Rotated_Resampled')\n",
        "\n",
        "\n",
        "#   ################## 3 Handcrafted DF Rotated Resampled ##########################\n",
        "#   # combine into one dataframe\n",
        "#   handcraft_features_segment_df_list_participant = pd.concat(handcraft_features_segment_df_list)\n",
        "#   ## Write to CSV \n",
        "#   handcraft_features_segment_df_list_participant.to_csv(f'{ID}_Participant_SlideSize_{sliding_window_size}_Handcrafted_Features_DF_Resampled')\n",
        "\n",
        "\n",
        "\n",
        "#   ################## 4 Signal Segments ##########################\n",
        "#   # combine into one array\n",
        "#   reshaped_segments_list_participant = np.concatenate((reshaped_segments_list))\n",
        "#   # Write to numpy file\n",
        "#   np.save(f'{ID}_Participant_SlideSize_{sliding_window_size}_Signal_Segments', reshaped_segments_list_participant) # save the file as \"outfile_name.npy\" \n",
        "\n",
        "\n",
        "\n",
        "#   ################## 5 Label Segments ##########################\n",
        "#   # combine into one array\n",
        "#   labels_seg_list_participant = np.concatenate((labels_seg_list))\n",
        "#   # Write to numpy file\n",
        "#   np.save(f'{ID}_Participant_SlideSize_{sliding_window_size}_Labels_Segments', labels_seg_list_participant) # save the file as \"outfile_name.npy\" \n",
        "\n",
        "\n",
        "#   # unique values contains an 'not set' dont dowloand the data \n",
        "\n",
        "#   checker_notSet = 'not set' in np.unique(labels_seg_list_participant)\n",
        "\n",
        "#   if checker_notSet == True:\n",
        "\n",
        "#     print(f'---------------------------------------------------------------')\n",
        "#     print(f'\\nNot Downloading this set: {ID} , Not set is contained in labels')\n",
        "#     print(f'---------------------------------------------------------------')\n",
        "\n",
        "#   else:\n",
        "\n",
        "#     ################################## Download files ###########################\n",
        "\n",
        "#     #Download Files (I dont believe these are of any use for this project , however I'll leave code)\n",
        "#     #files.download(f'{ID}_Participant_SlideSize_{sliding_window_size}_Original_DF_Resampled')\n",
        "#     #files.download(f'{ID}_Participant_SlideSize_{sliding_window_size}_Original_DF_Rotated_Resampled')\n",
        "    \n",
        "#     #Download Files \n",
        "#     files.download(f'{ID}_Participant_SlideSize_{sliding_window_size}_Handcrafted_Features_DF_Resampled')\n",
        "\n",
        "#     files.download(f'{ID}_Participant_SlideSize_{sliding_window_size}_Labels_Segments.npy')\n",
        "#     files.download(f'{ID}_Participant_SlideSize_{sliding_window_size}_Signal_Segments.npy')\n",
        "        \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRg8puPSm9qK"
      },
      "source": [
        "# look_at_window = input(\"Stop in code to let downloads happen, press anything to proceed: \")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHYt0XsaevNX"
      },
      "source": [
        "-----------------------------\n",
        "\n",
        "Sliding Window 50 - 25"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5PVEFGZexMO"
      },
      "source": [
        "# for ID_run in range(len(big_array)):\n",
        "\n",
        "#   print(f'\\n-----------------------------------------------------------------------  ID Run: {ID_run} -------------------------------------------------------------------\\n')\n",
        "\n",
        "#   # will be iterating over 8 runs , 2-9 (inclusive so its 8)\n",
        "#   # 5 outputs from preprocess:\n",
        "#   # original_df_resampled , original_df_rotated_resampled , handcraft_features_segment_df , reshaped_segments , labels_seg\n",
        "\n",
        "#   # lists to hold all 8 dataframes/arrays  , also resets in each loop\n",
        "#   original_df_resampled_list = []\n",
        "#   original_df_rotated_resampled_list = []\n",
        "#   handcraft_features_segment_df_list = []\n",
        "#   reshaped_segments_list = []\n",
        "#   labels_seg_list = []\n",
        "\n",
        "#   #################################################### Define Sliding Window Here! ################################################################\n",
        "\n",
        "#   # define sliding window size \n",
        "#   sliding_window_size = 50\n",
        "#   overlap_window_size = 25\n",
        "\n",
        "\n",
        "\n",
        "#   for i in range(len(big_array[0][0])):\n",
        "\n",
        "#     print(f'\\n---------------------  ID Run: {ID_run}  -  Run{i} --------------------------------\\n')\n",
        "\n",
        "#     ######################### set up cvs files names from array ##########################\n",
        "\n",
        "#     # acceleration \n",
        "#     acc = big_array[ID_run][0][i]\n",
        "\n",
        "#     # true orientation\n",
        "#     true_ori = big_array[ID_run][1][i]\n",
        "\n",
        "#     # magnetometer\n",
        "#     magnet = big_array[ID_run][2][i]\n",
        "\n",
        "#     # gyro \n",
        "#     gyro = big_array[ID_run][3][i]\n",
        "\n",
        "#     # markers\n",
        "#     markers = big_array[ID_run][4][i]\n",
        "\n",
        "\n",
        "#     ########################### get participant ID and run  #################################\n",
        "\n",
        "#     for m in big_array[ID_run][0][i].split(\" \"):\n",
        "\n",
        "#       if \"TrialFPSV\" in m:\n",
        "#         id = m[9:11]\n",
        "#         run = m[-1]\n",
        "\n",
        "#     ID  = id\n",
        "#     Run = run \n",
        "\n",
        "#     try:\n",
        "#       # preprocess function , step 50 datapoints (0.5 seconds) with 50% overlap (0.25 seconds)\n",
        "#       original_df_resampled , original_df_rotated_resampled , handcraft_features_segment_df , reshaped_segments , labels_seg = preprocess_func(acc , true_ori , magnet , gyro , markers , ID=ID, Run = Run , fc= 0.3 , n_time_steps= sliding_window_size , step = overlap_window_size)\n",
        "\n",
        "\n",
        "#       # append these to list \n",
        "#       original_df_resampled_list.append(original_df_resampled)\n",
        "#       original_df_rotated_resampled_list.append(original_df_rotated_resampled )\n",
        "#       handcraft_features_segment_df_list.append(handcraft_features_segment_df)\n",
        "#       reshaped_segments_list.append(reshaped_segments)\n",
        "#       labels_seg_list.append(labels_seg)\n",
        " \n",
        "#     except:\n",
        "#       print(f\"Exception Occured Run {i}\")\n",
        "#       continue\n",
        "\n",
        "\n",
        "#   ################### 1 Original DF Resampled  ########################\n",
        "#   # combine into one dataframe\n",
        "#   original_df_resampled_list_participant = pd.concat(original_df_resampled_list)\n",
        "#   ## Write to CSV \n",
        "#   original_df_resampled_list_participant.to_csv(f'{ID}_Participant_SlideSize_{sliding_window_size}_Original_DF_Resampled')\n",
        "\n",
        "\n",
        "#   ################## 2 Original DF Rotated Resampled ##########################\n",
        "#   # combine into one dataframe\n",
        "#   original_df_rotated_resampled_list_participant = pd.concat(original_df_rotated_resampled_list)\n",
        "#   ## Write to CSV \n",
        "#   original_df_rotated_resampled_list_participant.to_csv(f'{ID}_Participant_SlideSize_{sliding_window_size}_Original_DF_Rotated_Resampled')\n",
        "\n",
        "\n",
        "#   ################## 3 Handcrafted DF Rotated Resampled ##########################\n",
        "#   # combine into one dataframe\n",
        "#   handcraft_features_segment_df_list_participant = pd.concat(handcraft_features_segment_df_list)\n",
        "#   ## Write to CSV \n",
        "#   handcraft_features_segment_df_list_participant.to_csv(f'{ID}_Participant_SlideSize_{sliding_window_size}_Handcrafted_Features_DF_Resampled')\n",
        "\n",
        "\n",
        "\n",
        "#   ################## 4 Signal Segments ##########################\n",
        "#   # combine into one array\n",
        "#   reshaped_segments_list_participant = np.concatenate((reshaped_segments_list))\n",
        "#   # Write to numpy file\n",
        "#   np.save(f'{ID}_Participant_SlideSize_{sliding_window_size}_Signal_Segments', reshaped_segments_list_participant) # save the file as \"outfile_name.npy\" \n",
        "\n",
        "\n",
        "\n",
        "#   ################## 5 Label Segments ##########################\n",
        "#   # combine into one array\n",
        "#   labels_seg_list_participant = np.concatenate((labels_seg_list))\n",
        "#   # Write to numpy file\n",
        "#   np.save(f'{ID}_Participant_SlideSize_{sliding_window_size}_Labels_Segments', labels_seg_list_participant) # save the file as \"outfile_name.npy\" \n",
        "\n",
        "\n",
        "#   # unique values contains an 'not set' dont dowloand the data \n",
        "\n",
        "#   checker_notSet = 'not set' in np.unique(labels_seg_list_participant)\n",
        "\n",
        "#   if checker_notSet == True:\n",
        "\n",
        "#     print(f'---------------------------------------------------------------')\n",
        "#     print(f'\\nNot Downloading this set: {ID} , Not set is contained in labels')\n",
        "#     print(f'---------------------------------------------------------------')\n",
        "\n",
        "#   else:\n",
        "\n",
        "#     ################################## Download files ###########################\n",
        "\n",
        "#     #Download Files (I dont believe these are of any use for this project , however I'll leave code)\n",
        "#     #files.download(f'{ID}_Participant_SlideSize_{sliding_window_size}_Original_DF_Resampled')\n",
        "#     #files.download(f'{ID}_Participant_SlideSize_{sliding_window_size}_Original_DF_Rotated_Resampled')\n",
        "    \n",
        "#     #Download Files \n",
        "#     files.download(f'{ID}_Participant_SlideSize_{sliding_window_size}_Handcrafted_Features_DF_Resampled')\n",
        "\n",
        "#     files.download(f'{ID}_Participant_SlideSize_{sliding_window_size}_Labels_Segments.npy')\n",
        "#     files.download(f'{ID}_Participant_SlideSize_{sliding_window_size}_Signal_Segments.npy')\n",
        "        \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-yVhXTTm_d6"
      },
      "source": [
        "# look_at_window = input(\"Stop in code to let downloads happen, press anything to proceed: \")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-TG4V2oe0jL"
      },
      "source": [
        "-------------------------------\n",
        "\n",
        "Sliding Window 100 - 50 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLMdWEoUe2hH"
      },
      "source": [
        "# for ID_run in range(len(big_array)):\n",
        "\n",
        "#   print(f'\\n-----------------------------------------------------------------------  ID Run: {ID_run} -------------------------------------------------------------------\\n')\n",
        "\n",
        "#   # will be iterating over 8 runs , 2-9 (inclusive so its 8)\n",
        "#   # 5 outputs from preprocess:\n",
        "#   # original_df_resampled , original_df_rotated_resampled , handcraft_features_segment_df , reshaped_segments , labels_seg\n",
        "\n",
        "#   # lists to hold all 8 dataframes/arrays  , also resets in each loop\n",
        "#   original_df_resampled_list = []\n",
        "#   original_df_rotated_resampled_list = []\n",
        "#   handcraft_features_segment_df_list = []\n",
        "#   reshaped_segments_list = []\n",
        "#   labels_seg_list = []\n",
        "\n",
        "#   #################################################### Define Sliding Window Here! ################################################################\n",
        "\n",
        "#   # define sliding window size \n",
        "#   sliding_window_size = 100\n",
        "#   overlap_window_size = 50\n",
        "\n",
        "\n",
        "\n",
        "#   for i in range(len(big_array[0][0])):\n",
        "\n",
        "#     print(f'\\n---------------------  ID Run: {ID_run}  -  Run{i} --------------------------------\\n')\n",
        "\n",
        "#     ######################### set up cvs files names from array ##########################\n",
        "\n",
        "#     # acceleration \n",
        "#     acc = big_array[ID_run][0][i]\n",
        "\n",
        "#     # true orientation\n",
        "#     true_ori = big_array[ID_run][1][i]\n",
        "\n",
        "#     # magnetometer\n",
        "#     magnet = big_array[ID_run][2][i]\n",
        "\n",
        "#     # gyro \n",
        "#     gyro = big_array[ID_run][3][i]\n",
        "\n",
        "#     # markers\n",
        "#     markers = big_array[ID_run][4][i]\n",
        "\n",
        "\n",
        "#     ########################### get participant ID and run  #################################\n",
        "\n",
        "#     for m in big_array[ID_run][0][i].split(\" \"):\n",
        "\n",
        "#       if \"TrialFPSV\" in m:\n",
        "#         id = m[9:11]\n",
        "#         run = m[-1]\n",
        "\n",
        "#     ID  = id\n",
        "#     Run = run \n",
        "\n",
        "#     try:\n",
        "#       # preprocess function , step 50 datapoints (0.5 seconds) with 50% overlap (0.25 seconds)\n",
        "#       original_df_resampled , original_df_rotated_resampled , handcraft_features_segment_df , reshaped_segments , labels_seg = preprocess_func(acc , true_ori , magnet , gyro , markers , ID=ID, Run = Run , fc= 0.3 , n_time_steps= sliding_window_size , step = overlap_window_size)\n",
        "\n",
        "\n",
        "#       # append these to list \n",
        "#       original_df_resampled_list.append(original_df_resampled)\n",
        "#       original_df_rotated_resampled_list.append(original_df_rotated_resampled )\n",
        "#       handcraft_features_segment_df_list.append(handcraft_features_segment_df)\n",
        "#       reshaped_segments_list.append(reshaped_segments)\n",
        "#       labels_seg_list.append(labels_seg)\n",
        " \n",
        "#     except:\n",
        "#       print(f\"Exception Occured Run {i}\")\n",
        "#       continue\n",
        "\n",
        "\n",
        "#   ################### 1 Original DF Resampled  ########################\n",
        "#   # combine into one dataframe\n",
        "#   original_df_resampled_list_participant = pd.concat(original_df_resampled_list)\n",
        "#   ## Write to CSV \n",
        "#   original_df_resampled_list_participant.to_csv(f'{ID}_Participant_SlideSize_{sliding_window_size}_Original_DF_Resampled')\n",
        "\n",
        "\n",
        "#   ################## 2 Original DF Rotated Resampled ##########################\n",
        "#   # combine into one dataframe\n",
        "#   original_df_rotated_resampled_list_participant = pd.concat(original_df_rotated_resampled_list)\n",
        "#   ## Write to CSV \n",
        "#   original_df_rotated_resampled_list_participant.to_csv(f'{ID}_Participant_SlideSize_{sliding_window_size}_Original_DF_Rotated_Resampled')\n",
        "\n",
        "\n",
        "#   ################## 3 Handcrafted DF Rotated Resampled ##########################\n",
        "#   # combine into one dataframe\n",
        "#   handcraft_features_segment_df_list_participant = pd.concat(handcraft_features_segment_df_list)\n",
        "#   ## Write to CSV \n",
        "#   handcraft_features_segment_df_list_participant.to_csv(f'{ID}_Participant_SlideSize_{sliding_window_size}_Handcrafted_Features_DF_Resampled')\n",
        "\n",
        "\n",
        "\n",
        "#   ################## 4 Signal Segments ##########################\n",
        "#   # combine into one array\n",
        "#   reshaped_segments_list_participant = np.concatenate((reshaped_segments_list))\n",
        "#   # Write to numpy file\n",
        "#   np.save(f'{ID}_Participant_SlideSize_{sliding_window_size}_Signal_Segments', reshaped_segments_list_participant) # save the file as \"outfile_name.npy\" \n",
        "\n",
        "\n",
        "\n",
        "#   ################## 5 Label Segments ##########################\n",
        "#   # combine into one array\n",
        "#   labels_seg_list_participant = np.concatenate((labels_seg_list))\n",
        "#   # Write to numpy file\n",
        "#   np.save(f'{ID}_Participant_SlideSize_{sliding_window_size}_Labels_Segments', labels_seg_list_participant) # save the file as \"outfile_name.npy\" \n",
        "\n",
        "\n",
        "#   # unique values contains an 'not set' dont dowloand the data \n",
        "\n",
        "#   checker_notSet = 'not set' in np.unique(labels_seg_list_participant)\n",
        "\n",
        "#   if checker_notSet == True:\n",
        "\n",
        "#     print(f'---------------------------------------------------------------')\n",
        "#     print(f'\\nNot Downloading this set: {ID} , Not set is contained in labels')\n",
        "#     print(f'---------------------------------------------------------------')\n",
        "\n",
        "#   else:\n",
        "\n",
        "#     ################################## Download files ###########################\n",
        "\n",
        "#     #Download Files (I dont believe these are of any use for this project , however I'll leave code)\n",
        "#     #files.download(f'{ID}_Participant_SlideSize_{sliding_window_size}_Original_DF_Resampled')\n",
        "#     #files.download(f'{ID}_Participant_SlideSize_{sliding_window_size}_Original_DF_Rotated_Resampled')\n",
        "    \n",
        "#     #Download Files \n",
        "#     files.download(f'{ID}_Participant_SlideSize_{sliding_window_size}_Handcrafted_Features_DF_Resampled')\n",
        "\n",
        "#     files.download(f'{ID}_Participant_SlideSize_{sliding_window_size}_Labels_Segments.npy')\n",
        "#     files.download(f'{ID}_Participant_SlideSize_{sliding_window_size}_Signal_Segments.npy')\n",
        "        \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axZmkfdnqGKK"
      },
      "source": [
        "\n",
        "\n",
        "# # will be iterating over 8 runs , 2-9 (inclusive so its 8)\n",
        "# # 5 outputs from preprocess:\n",
        "# # original_df_resampled , original_df_rotated_resampled , handcraft_features_segment_df , reshaped_segments , labels_seg\n",
        "\n",
        "# # lists to hold all 8 dataframes/arrays\n",
        "# original_df_resampled_list = []\n",
        "# original_df_rotated_resampled_list = []\n",
        "# handcraft_features_segment_df_list = []\n",
        "# reshaped_segments_list = []\n",
        "# labels_seg_list = []\n",
        "\n",
        "# # define sliding window size \n",
        "# sliding_window_size = 6\n",
        "# overlap_window_size = 3\n",
        "\n",
        "\n",
        "\n",
        "# for i in range(len(array_setup[0])):\n",
        "\n",
        "#   print(f'\\n--------------------- Run{i} --------------------------------\\n')\n",
        "\n",
        "#   ######################### set up cvs files names from array ##########################\n",
        "\n",
        "#   # acceleration \n",
        "#   acc = array_setup[0][i]\n",
        "\n",
        "#   # true orientation\n",
        "#   true_ori = array_setup[1][i]\n",
        "\n",
        "#   # magnetometer\n",
        "#   magnet = array_setup[2][i]\n",
        "\n",
        "#   # gyro \n",
        "#   gyro = array_setup[3][i]\n",
        "\n",
        "#   # markers\n",
        "#   markers = array_setup[4][i]\n",
        "\n",
        "\n",
        "#   ########################### get participant ID and run  #################################\n",
        "\n",
        "#   for m in array_setup[0][i].split(\" \"):\n",
        "\n",
        "#     if \"TrialFPSV\" in m:\n",
        "#       id = m[9:11]\n",
        "#       run = m[-1]\n",
        "\n",
        "#   ID  = id\n",
        "#   Run = run \n",
        "\n",
        "#   try:\n",
        "#     # preprocess function , step 50 datapoints (0.5 seconds) with 50% overlap (0.25 seconds)\n",
        "#     original_df_resampled , original_df_rotated_resampled , handcraft_features_segment_df , reshaped_segments , labels_seg = preprocess_func(acc , true_ori , magnet , gyro , markers , ID=ID, Run = Run , fc= 0.3 , n_time_steps= sliding_window_size , step = overlap_window_size)\n",
        "\n",
        "\n",
        "#     # append these to list \n",
        "#     original_df_resampled_list.append(original_df_resampled)\n",
        "#     original_df_rotated_resampled_list.append(original_df_rotated_resampled )\n",
        "#     handcraft_features_segment_df_list.append(handcraft_features_segment_df)\n",
        "#     reshaped_segments_list.append(reshaped_segments)\n",
        "#     labels_seg_list.append(labels_seg)\n",
        "\n",
        "#   except:\n",
        "#     print(f\"Exception Occured Run {i}\")\n",
        "#     continue\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Yg2RWD3iXcs"
      },
      "source": [
        "# # ask if want to download \n",
        "# look_at_graph = input(\"Stop in code to look at graph, press anything to proceed: \")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgmBRmTfKttZ"
      },
      "source": [
        "------------------------------------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwnmIL2HNZmK"
      },
      "source": [
        "#original_df_resampled.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HjKih4DOCUf"
      },
      "source": [
        "#original_df_rotated_resampled.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvqGNn2ROPZs"
      },
      "source": [
        "#reshaped_segments[0][0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rPmdmy0RARU"
      },
      "source": [
        "# Now combine all runs together and write out to CSV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQh5nn03hLH0"
      },
      "source": [
        "-----------------------------------------------------------\n",
        "Save Outputs Automate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ciV81AJfh7hh"
      },
      "source": [
        "# print(ID)\n",
        "\n",
        "# print(sliding_window_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BtERgirhNQt"
      },
      "source": [
        "\n",
        "# ################### 1 Original DF Resampled  ########################\n",
        "\n",
        "# # combine into one dataframe\n",
        "# original_df_resampled_list_participant = pd.concat(original_df_resampled_list)\n",
        "\n",
        "# ## Write to CSV \n",
        "# original_df_resampled_list_participant.to_csv(f'{ID}_Participant_SlideSize_{sliding_window_size}_Original_DF_Resampled')\n",
        "\n",
        "\n",
        "# ################## 2 Original DF Rotated Resampled ##########################\n",
        "\n",
        "# # combine into one dataframe\n",
        "# original_df_rotated_resampled_list_participant = pd.concat(original_df_rotated_resampled_list)\n",
        "\n",
        "# ## Write to CSV \n",
        "# original_df_rotated_resampled_list_participant.to_csv(f'{ID}_Participant_SlideSize_{sliding_window_size}_Original_DF_Rotated_Resampled')\n",
        "\n",
        "\n",
        "# ################## 3 Handcrafted DF Rotated Resampled ##########################\n",
        "\n",
        "# # combine into one dataframe\n",
        "# handcraft_features_segment_df_list_participant = pd.concat(handcraft_features_segment_df_list)\n",
        "\n",
        "# ## Write to CSV \n",
        "# handcraft_features_segment_df_list_participant.to_csv(f'{ID}_Participant_SlideSize_{sliding_window_size}_Handcrafted_Features_DF_Resampled')\n",
        "\n",
        "\n",
        "\n",
        "# ################## 4 Signal Segments ##########################\n",
        "\n",
        "# # combine into one array\n",
        "# reshaped_segments_list_participant = np.concatenate((reshaped_segments_list))\n",
        "\n",
        "# # Write to numpy file\n",
        "# np.save(f'{ID}_Participant_SlideSize_{sliding_window_size}_Signal_Segments', reshaped_segments_list_participant) # save the file as \"outfile_name.npy\" \n",
        "\n",
        "\n",
        "\n",
        "# ################## 5 Label Segments ##########################\n",
        "\n",
        "# # combine into one array\n",
        "# labels_seg_list_participant = np.concatenate((labels_seg_list))\n",
        "\n",
        "# # Write to numpy file\n",
        "# np.save(f'{ID}_Participant_SlideSize_{sliding_window_size}_Labels_Segments', labels_seg_list_participant) # save the file as \"outfile_name.npy\" \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mhn713rgC2fv"
      },
      "source": [
        "# Download files "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMLn0UtCCqu8"
      },
      "source": [
        "# # ask if want to download \n",
        "# val = input(\"Download y/n: \")\n",
        "\n",
        "# if val == 'y':\n",
        "\n",
        "#   #Download Files \n",
        "#   files.download(f'{ID}_Participant_SlideSize_{sliding_window_size}_Original_DF_Resampled')\n",
        "#   files.download(f'{ID}_Participant_SlideSize_{sliding_window_size}_Original_DF_Rotated_Resampled')\n",
        "#   files.download(f'{ID}_Participant_SlideSize_{sliding_window_size}_Handcrafted_Features_DF_Resampled')\n",
        "\n",
        "#   files.download(f'{ID}_Participant_SlideSize_{sliding_window_size}_Labels_Segments.npy')\n",
        "#   files.download(f'{ID}_Participant_SlideSize_{sliding_window_size}_Signal_Segments.npy')\n",
        "\n",
        "\n",
        "# else:\n",
        "#   print(\"No Downloads. Finished Notebook\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}