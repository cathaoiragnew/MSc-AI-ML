{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2_July_HC_LSTM_Manual_Train_Test_HandCraft_Thesis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EKoxDdSsr8e"
      },
      "source": [
        "# Handcrafted Features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrVWaVNkPW2k"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtX5iMQHPDII"
      },
      "source": [
        "\n",
        "########################### (https://github.com/curiousily/TensorFlow-on-Android-for-Human-Activity-Recognition-with-LSTMs/blob/master/human_activity_recognition.ipynb) imports\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "from scipy import stats\n",
        "import tensorflow as tf\n",
        "import seaborn as sns\n",
        "from pylab import rcParams\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "%matplotlib inline\n",
        "sns.set(style='whitegrid', palette='muted', font_scale=1.5)\n",
        "rcParams['figure.figsize'] = 14, 8\n",
        "RANDOM_SEED = 42\n",
        "\n",
        "#!pip install imbalanced-learn\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from collections import Counter\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from keras import backend as K\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "from matplotlib.pyplot import figure\n",
        "\n",
        "\n",
        "########################### (https://github.com/curiousily/TensorFlow-on-Android-for-Human-Activity-Recognition-with-LSTMs/blob/master/human_activity_recognition.ipynb) imports\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "from scipy import stats\n",
        "import tensorflow as tf\n",
        "import seaborn as sns\n",
        "from pylab import rcParams\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_M5F5DwPrKk"
      },
      "source": [
        "# Upload Data \n",
        "\n",
        "---------------------------------\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZX9OGsWPzvD"
      },
      "source": [
        "Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IyDYp-eLY8K"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded_signal_train = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "juXPVt1AP0v1"
      },
      "source": [
        "Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDlYInx_Pyx5"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded_signal_test = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFIL8q5nvqUf"
      },
      "source": [
        "### Reading in segments & labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y70o5U5mSOUU"
      },
      "source": [
        "Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxXU40eBttE6"
      },
      "source": [
        "# getting keys, which is file names of npy \n",
        "list_of_dataframes_train = [key for key in uploaded_signal_train.keys()]\n",
        "\n",
        "\n",
        "# set up list to hold all loaded npy \n",
        "all_dataframe_train = [] \n",
        "\n",
        "\n",
        "for i in range(len(list_of_dataframes_train)):\n",
        "\n",
        "    # load in the data \n",
        "    dataframe_train = pd.read_csv(list_of_dataframes_train[i])\n",
        "\n",
        "\n",
        "    # append the data to 'all' list\n",
        "    all_dataframe_train.append(dataframe_train) \n",
        "\n",
        "\n",
        "all_df_train = pd.concat(all_dataframe_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXzYX7vVSPqK"
      },
      "source": [
        "Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4s9Wo8YGSQeN"
      },
      "source": [
        "# getting keys, which is file names of npy \n",
        "list_of_dataframes_test = [key for key in uploaded_signal_test.keys()]\n",
        "\n",
        "\n",
        "# set up list to hold all loaded npy \n",
        "all_dataframe_test = [] \n",
        "\n",
        "\n",
        "for i in range(len(list_of_dataframes_test)):\n",
        "\n",
        "    # load in the data \n",
        "    dataframe_test = pd.read_csv(list_of_dataframes_test[i])\n",
        "\n",
        "\n",
        "    # append the data to 'all' list\n",
        "    all_dataframe_test.append(dataframe_test) \n",
        "\n",
        "\n",
        "all_df_test = pd.concat(all_dataframe_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tv9p0IN6UTkW"
      },
      "source": [
        "# Quick Shuffle "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yza_3-7pUVHI"
      },
      "source": [
        "all_df_train = shuffle(all_df_train)\n",
        "all_df_test = shuffle(all_df_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8jsSnExgGesF"
      },
      "source": [
        "# Quick Look "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCEZ0lTrGiz3"
      },
      "source": [
        "all_df_train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJ-KTwnDGhYv"
      },
      "source": [
        "all_df_test.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVPv0iQ6SPeH"
      },
      "source": [
        "# Train Test Split "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlyxtKg4SRMP"
      },
      "source": [
        "# Getting X_train & y_train'\n",
        "X_train = all_df_train.drop(['Unnamed: 0' , 'Label_segment' , 'Participant_ID' , 'Participant_Run', 'X_Acc_Move_FFT_EnergyBands', \t'Y_Acc_Move_FFT_EnergyBands', \t'Z_Acc_Move_FFT_EnergyBands'\t], axis = 1)\n",
        "#X_train = all_df_train.drop(['Unnamed: 0' , 'Label_segment' , 'Participant_ID' , 'Participant_Run'\t], axis = 1)\n",
        "\n",
        "y_train = all_df_train['Label_segment'].values\n",
        "\n",
        "\n",
        "# convert to dummy category\n",
        "y_train_dum = pd.get_dummies(y_train)\n",
        "\n",
        "print(f'\\nDummy labels Shape {y_train_dum.shape}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyOL-dTlTDbw"
      },
      "source": [
        "# Getting X_train & y_train\n",
        "\n",
        "X_test = all_df_test.drop(['Unnamed: 0' , 'Label_segment' , 'Participant_ID' , 'Participant_Run',  'X_Acc_Move_FFT_EnergyBands', \t'Y_Acc_Move_FFT_EnergyBands', \t'Z_Acc_Move_FFT_EnergyBands'], axis = 1)\n",
        "#X_test = all_df_test.drop(['Unnamed: 0' , 'Label_segment' , 'Participant_ID' , 'Participant_Run'\t], axis = 1)\n",
        "\n",
        "y_test = all_df_test['Label_segment'].values\n",
        "\n",
        "# convert to dummy category\n",
        "y_test_dum = pd.get_dummies(y_test)\n",
        "\n",
        "print(f'\\nDummy labels Shape {y_test_dum.shape}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFFnYKxVTIf6"
      },
      "source": [
        "--------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tVnwD0csNgw"
      },
      "source": [
        "Standard Scale "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFhyhbcjsO7K"
      },
      "source": [
        "# Set up ss for non-shuffled data\n",
        "ss = StandardScaler()\n",
        "\n",
        "# fit for non-shuffled\n",
        "X_train_scale = ss.fit_transform(X_train)\n",
        "X_test_scale = ss.transform(X_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmI_62XaSoYf"
      },
      "source": [
        "---------------------------\n",
        "\n",
        "Deep "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWbPnaf7S09a"
      },
      "source": [
        "# lstm model\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from numpy import dstack\n",
        "from pandas import read_csv\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import TimeDistributed\n",
        "from matplotlib import pyplot\n",
        "\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "import time\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijn3-yBIS6SX"
      },
      "source": [
        "#n_timesteps, n_features, n_outputs = X_train.shape[1] , X_train.shape[2] , y_train_dum.shape[1]\n",
        "\n",
        "n_outputs =  y_train_dum.shape[1]\n",
        "\n",
        "# set up model\n",
        "model = Sequential()\n",
        "\n",
        "#input layer\n",
        "model.add(Dense(100, activation='relu' , input_shape = (X_train_scale.shape[1], )))\n",
        "\n",
        "# hidden layers\n",
        "model.add(Dense(50, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(50, activation='relu'))\n",
        "\n",
        "\n",
        "# output layer\n",
        "model.add(Dense(n_outputs, activation='softmax'))\n",
        "\n",
        "# compile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[tf.keras.metrics.CategoricalAccuracy()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZnLHWPxT4mP"
      },
      "source": [
        "Early Stopping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pH_6vdl4T4K4"
      },
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        " \t\n",
        "# patient early stopping\n",
        "#es = EarlyStopping(monitor='val_loss', mode='auto', verbose=1, patience=5 , min_delta=0.05)\n",
        "\n",
        "\n",
        "earlyStopping = EarlyStopping(monitor='val_loss', patience=5, verbose=0, mode='min')\n",
        "mcp_save = ModelCheckpoint('.base_model_wts.hdf5', save_best_only=True, monitor='val_loss', mode='min')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8aidJIMEaG0Y"
      },
      "source": [
        "X_train_scale.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDcTe09pT90L"
      },
      "source": [
        "Fit "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJ1jMHoyT7IS"
      },
      "source": [
        "# just for timing model\n",
        "t0 = time.time()\n",
        "\n",
        "# fitting model \n",
        "history = model.fit(X_train_scale, y_train_dum,\n",
        "                    validation_data=(X_test_scale, y_test_dum),\n",
        "                    epochs = 100,\n",
        "                    batch_size=200,\n",
        "                    callbacks=[earlyStopping, mcp_save]\n",
        "                    )\n",
        "\n",
        "\n",
        "t1 = time.time()\n",
        "\n",
        "total = t1-t0\n",
        "\n",
        "print(f'Time Taken: {total}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnCgxPxEatRz"
      },
      "source": [
        "Learning Curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noy3cqnyaxCZ"
      },
      "source": [
        "history_dict = history.history\n",
        "loss_values = history_dict['loss']\n",
        "val_loss_values = history_dict['val_loss']\n",
        "accuracy = history_dict['categorical_accuracy']\n",
        "val_accuracy = history_dict['val_categorical_accuracy']\n",
        " \n",
        "epochs = range(1, len(loss_values) + 1)\n",
        "fig, ax = plt.subplots(1, 2, figsize=(14, 6))\n",
        "#\n",
        "# Plot the model accuracy vs Epochs\n",
        "#\n",
        "ax[0].plot(epochs, accuracy, 'r', label='Training accuracy')\n",
        "ax[0].plot(epochs, val_accuracy, 'b', label='Validation accuracy')\n",
        "ax[0].set_title('Training & Validation Accuracy', fontsize=16)\n",
        "ax[0].set_xlabel('Epochs', fontsize=16)\n",
        "ax[0].set_ylabel('Accuracy', fontsize=16)\n",
        "ax[0].legend()\n",
        "#\n",
        "# Plot the loss vs Epochs\n",
        "#\n",
        "ax[1].plot(epochs, loss_values, 'r', label='Training loss')\n",
        "ax[1].plot(epochs, val_loss_values, 'b', label='Validation loss')\n",
        "ax[1].set_title('Training & Validation Loss', fontsize=16)\n",
        "ax[1].set_xlabel('Epochs', fontsize=16)\n",
        "ax[1].set_ylabel('Loss', fontsize=16)\n",
        "ax[1].legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oB3ENVF9a6xv"
      },
      "source": [
        "------------------------\n",
        "\n",
        "Reports"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OI5PTbCb6MJW"
      },
      "source": [
        "Make Predicitions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pZrUb3e9SSH"
      },
      "source": [
        "# For Confusion matrix & Classification Report \n",
        "\n",
        "y_preds = model.predict(X_test_scale)\n",
        "max_predictions = np.argmax(y_preds, axis=1)\n",
        "\n",
        "max_test = np.argmax(np.asarray(y_test_dum), axis=1)\n",
        "\n",
        "##################\n",
        "\n",
        "\n",
        "y_preds_train = model.predict(X_train_scale)\n",
        "\n",
        "max_predictions_train = np.argmax(y_preds_train, axis=1)\n",
        "max_train = np.argmax(np.asarray(y_train_dum), axis=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocbl1VTVaZXO"
      },
      "source": [
        "# Metrics "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGPfaIQna1qB"
      },
      "source": [
        "Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63JnyIrJaai2"
      },
      "source": [
        "from sklearn.metrics import accuracy_score , precision_score\n",
        "from sklearn.metrics import balanced_accuracy_score, recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "\n",
        "print(\"Test Balanced Accuracy : \\t\" , balanced_accuracy_score(max_test, max_predictions))\n",
        "print(\"Test F1 Score : \\t\\t\" , f1_score(max_test, max_predictions , average='weighted'))\n",
        "print(\"Test Precision Score : \\t\\t\" , precision_score(max_test, max_predictions , average='weighted'))\n",
        "print(\"Test Recall Score : \\t\\t\" , recall_score(max_test, max_predictions , average='weighted'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1EjHZjy0a2vF"
      },
      "source": [
        "Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6DnA8cfa_wz"
      },
      "source": [
        "print(\"Train Accuracy : \\t\\t\" ,accuracy_score(max_train, max_predictions_train))\n",
        "print(\"Train Balanced Accuracy : \\t\" , balanced_accuracy_score(max_train, max_predictions_train))\n",
        "print(\"Train F1 Score : \\t\\t\" , f1_score(max_train, max_predictions_train, average='weighted'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2LpL8jl3WE1"
      },
      "source": [
        "Imports "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9cJEhcm7Hcv"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# set up labels \n",
        "LABELS = ['Go', 'Turn1',  'Turn2' , 'Walk1', 'Walk2', 'Sit']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VPW38Ol13r7"
      },
      "source": [
        "# Test Set "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cmqio-IFxVKT"
      },
      "source": [
        "print(classification_report(max_test, max_predictions , target_names=LABELS))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmAM0Jp115kv"
      },
      "source": [
        "# Train Set "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLpbBnmV11_2"
      },
      "source": [
        "print(classification_report(max_train, max_predictions_train , target_names=LABELS))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGyuwOAC3RTT"
      },
      "source": [
        "--------------------\n",
        "\n",
        "# Confusion Matrix "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3I2gx2Z_BGG"
      },
      "source": [
        "confusion_matrix = metrics.confusion_matrix(max_test, max_predictions  )\n",
        "\n",
        "confusion_matrix_t = metrics.confusion_matrix(max_train, max_predictions_train )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qU1i78_3_m23"
      },
      "source": [
        "plt.figure(figsize=(14, 10))\n",
        "sns.heatmap(confusion_matrix, xticklabels=LABELS, yticklabels=LABELS,  annot=True, fmt=\"d\");\n",
        "plt.title(\"Test Data Confusion matrix\")\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u31mjLP2Dxwp"
      },
      "source": [
        "plt.figure(figsize=(14, 10))\n",
        "sns.heatmap(confusion_matrix_t, xticklabels=LABELS, yticklabels=LABELS, annot=True, fmt=\"d\");\n",
        "plt.title(\"Train Confusion matrix\")\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_zZcYxTSqFQ"
      },
      "source": [
        "-------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1FdW-A3SvYG"
      },
      "source": [
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58PH8YT0SxK1"
      },
      "source": [
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rcBBSUHvqYv"
      },
      "source": [
        "---------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVLILmUMvu_8"
      },
      "source": [
        "Check if SMOTE helps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGqsOBJ8uDyb"
      },
      "source": [
        "print(Counter(y_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HG4rgil4twz5"
      },
      "source": [
        "\n",
        "# transform the dataset\n",
        "oversample = SMOTE()\n",
        "X_train_smote, y_train_smote = oversample.fit_resample(X_train_scale, y_train)\n",
        "\n",
        "# convert to dummy category\n",
        "y_train_smote_dum = pd.get_dummies(y_train_smote)\n",
        "\n",
        "print(f'\\nDummy labels Shape {y_train_smote_dum.shape}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCXSiUfCuOVP"
      },
      "source": [
        "print(Counter(y_train_smote))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5EXGNacv4Hf"
      },
      "source": [
        "-----------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qct63LuGfGG"
      },
      "source": [
        "-------------------------------\n",
        "\n",
        "Deep + Smote"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7R4NDyQhGgvA"
      },
      "source": [
        "#n_timesteps, n_features, n_outputs = X_train.shape[1] , X_train.shape[2] , y_train_dum.shape[1]\n",
        "\n",
        "n_outputs =  y_train_dum.shape[1]\n",
        "\n",
        "# set up model\n",
        "model_smote = Sequential()\n",
        "\n",
        "#input layer\n",
        "model_smote.add(Dense(50, activation='relu'))\n",
        "\n",
        "\n",
        "# hidden layers\n",
        "model_smote.add(Dense(50, activation='relu'))\n",
        "model_smote.add(Dropout(0.5))\n",
        "model_smote.add(Dense(50, activation='relu'))\n",
        "#model_smote.add(Dropout(0.5))\n",
        "#model_smote.add(Dense(100, activation='relu'))\n",
        "\n",
        "\n",
        "# output layer\n",
        "model_smote.add(Dense(n_outputs, activation='softmax'))\n",
        "\n",
        "# compile model\n",
        "model_smote.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[tf.keras.metrics.CategoricalAccuracy()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEIcMm4_Xi6Y"
      },
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        " \t\n",
        "# patient early stopping\n",
        "#es = EarlyStopping(monitor='val_loss', mode='auto', verbose=1, patience=5 , min_delta=0.05)\n",
        "\n",
        "\n",
        "earlyStopping = EarlyStopping(monitor='val_loss', patience=2, verbose=0, mode='min')\n",
        "mcp_save = ModelCheckpoint('.base_model_wts.hdf5', save_best_only=True, monitor='val_loss', mode='min')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32CFsexdXj69"
      },
      "source": [
        "# just for timing model\n",
        "t0 = time.time()\n",
        "\n",
        "# fitting model \n",
        "history_smote = model_smote.fit(X_train_smote, y_train_smote_dum,\n",
        "                    validation_data=(X_test_scale, y_test_dum),\n",
        "                    epochs = 100,\n",
        "                    batch_size=200,\n",
        "                    callbacks=[earlyStopping, mcp_save]\n",
        "                    )\n",
        "\n",
        "\n",
        "t1 = time.time()\n",
        "\n",
        "total = t1-t0\n",
        "\n",
        "print(f'Time Taken: {total}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GcPAF5Qcvb7"
      },
      "source": [
        "-----------------------------\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qtq8sUI8dASA"
      },
      "source": [
        "Learning Curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIKMVwmudASC"
      },
      "source": [
        "history_dict = history_smote.history\n",
        "loss_values = history_dict['loss']\n",
        "val_loss_values = history_dict['val_loss']\n",
        "accuracy = history_dict['categorical_accuracy']\n",
        "val_accuracy = history_dict['val_categorical_accuracy']\n",
        " \n",
        "epochs = range(1, len(loss_values) + 1)\n",
        "fig, ax = plt.subplots(1, 2, figsize=(14, 6))\n",
        "#\n",
        "# Plot the model accuracy vs Epochs\n",
        "#\n",
        "ax[0].plot(epochs, accuracy, 'r', label='Training accuracy')\n",
        "ax[0].plot(epochs, val_accuracy, 'b', label='Validation accuracy')\n",
        "ax[0].set_title('Training & Validation Accuracy', fontsize=16)\n",
        "ax[0].set_xlabel('Epochs', fontsize=16)\n",
        "ax[0].set_ylabel('Accuracy', fontsize=16)\n",
        "ax[0].legend()\n",
        "#\n",
        "# Plot the loss vs Epochs\n",
        "#\n",
        "ax[1].plot(epochs, loss_values, 'r', label='Training loss')\n",
        "ax[1].plot(epochs, val_loss_values, 'b', label='Validation loss')\n",
        "ax[1].set_title('Training & Validation Loss', fontsize=16)\n",
        "ax[1].set_xlabel('Epochs', fontsize=16)\n",
        "ax[1].set_ylabel('Loss', fontsize=16)\n",
        "ax[1].legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5L7vcoKdASF"
      },
      "source": [
        "------------------------\n",
        "\n",
        "Reports"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVgJNPX4dASH"
      },
      "source": [
        "Make Predicitions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwPBzvkKdASJ"
      },
      "source": [
        "# For Confusion matrix & Classification Report \n",
        "\n",
        "y_preds = model_smote.predict(X_test_scale)\n",
        "max_predictions = np.argmax(y_preds, axis=1)\n",
        "\n",
        "max_test = np.argmax(np.asarray(y_test_dum), axis=1)\n",
        "\n",
        "##################\n",
        "\n",
        "\n",
        "y_preds_train = model_smote.predict(X_train_smote)\n",
        "\n",
        "max_predictions_train = np.argmax(y_preds_train, axis=1)\n",
        "max_train = np.argmax(np.asarray(y_train_smote_dum), axis=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KENTFbedASK"
      },
      "source": [
        "# Metrics "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7G4Q5qrjdASM"
      },
      "source": [
        "Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyoTPFCadASM"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "print(\"Test Accuracy : \\t\\t\" ,accuracy_score(max_test, max_predictions))\n",
        "print(\"Test Balanced Accuracy : \\t\" , balanced_accuracy_score(max_test, max_predictions))\n",
        "print(\"Test F1 Score : \\t\\t\" , f1_score(max_test, max_predictions , average='weighted'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Y5AiholdASN"
      },
      "source": [
        "Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-mPl3NKdASP"
      },
      "source": [
        "print(\"Train Accuracy : \\t\\t\" ,accuracy_score(max_train, max_predictions_train))\n",
        "print(\"Train Balanced Accuracy : \\t\" , balanced_accuracy_score(max_train, max_predictions_train))\n",
        "print(\"Train F1 Score : \\t\\t\" , f1_score(max_train, max_predictions_train, average='weighted'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3z-2XFA1dASQ"
      },
      "source": [
        "Imports "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sw9KxVWGdASQ"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "LABELS = ['Go', 'Walk1', 'Turn1', 'Walk2', 'Turn2', 'Sit']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-LY75MJdASR"
      },
      "source": [
        "# Test Set "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fVEiWdzdASS"
      },
      "source": [
        "print(classification_report(max_test, max_predictions , target_names=LABELS))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxaivX71dASS"
      },
      "source": [
        "# Train Set "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zCbm9vWdAST"
      },
      "source": [
        "print(classification_report(max_train, max_predictions_train , target_names=LABELS))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2G4KdQFdAST"
      },
      "source": [
        "--------------------\n",
        "\n",
        "# Confusion Matrix "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZFHHJ-JdASU"
      },
      "source": [
        "confusion_matrix = metrics.confusion_matrix(max_test, max_predictions  )\n",
        "\n",
        "confusion_matrix_t = metrics.confusion_matrix(max_train, max_predictions_train )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8hlVtFudASU"
      },
      "source": [
        "plt.figure(figsize=(14, 10))\n",
        "sns.heatmap(confusion_matrix, xticklabels=LABELS, yticklabels=LABELS,  annot=True, fmt=\"d\");\n",
        "plt.title(\"Test Data Confusion matrix\")\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ev7mQ0l9dASV"
      },
      "source": [
        "plt.figure(figsize=(14, 10))\n",
        "sns.heatmap(confusion_matrix_t, xticklabels=LABELS, yticklabels=LABELS, annot=True, fmt=\"d\");\n",
        "plt.title(\"Train Confusion matrix\")\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pu2VehGAdASV"
      },
      "source": [
        "-------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFVqYm7t39_n"
      },
      "source": [
        "# Transfer Learning Touch Up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjRb6wP639wh"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded_dataframe_train_id = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMHI7ZWl4fCO"
      },
      "source": [
        "# getting keys, which is file names of npy \n",
        "list_of_dataframes_train_trans = [key for key in uploaded_dataframe_train_id.keys()]\n",
        "\n",
        "\n",
        "# set up list to hold all loaded npy \n",
        "all_dataframe_train_trans = [] \n",
        "\n",
        "\n",
        "for i in range(len(list_of_dataframes_train_trans)):\n",
        "\n",
        "    # load in the data \n",
        "    dataframe_train = pd.read_csv(list_of_dataframes_train_trans[i])\n",
        "\n",
        "\n",
        "    # append the data to 'all' list\n",
        "    all_dataframe_train_trans.append(dataframe_train) \n",
        "\n",
        "\n",
        "all_df_train_trans = pd.concat(all_dataframe_train_trans)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhA7cVqN4H2e"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded_dataframe_validation_id = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XGe-Md44u1R"
      },
      "source": [
        "# getting keys, which is file names of df\n",
        "list_of_dataframes_val_trans = [key for key in uploaded_dataframe_validation_id.keys()]\n",
        "\n",
        "\n",
        "# set up list to hold all loaded npy \n",
        "all_dataframe_val_trans = [] \n",
        "\n",
        "\n",
        "for i in range(len(list_of_dataframes_val_trans)):\n",
        "\n",
        "    # load in the data \n",
        "    dataframe_val = pd.read_csv(list_of_dataframes_val_trans[i])\n",
        "\n",
        "\n",
        "    # append the data to 'all' list\n",
        "    all_dataframe_val_trans.append(dataframe_val) \n",
        "\n",
        "\n",
        "all_df_val_trans = pd.concat(all_dataframe_val_trans)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8iPxcM6h5P-F"
      },
      "source": [
        "--------------------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKEf3kf65SbD"
      },
      "source": [
        "# Getting X_train & y_train\n",
        "X_train_trans = all_df_train_trans.drop(['Unnamed: 0' , 'Label_segment' , 'Participant_ID' , 'Participant_Run',  'X_Acc_Move_FFT_EnergyBands', \t'Y_Acc_Move_FFT_EnergyBands', \t'Z_Acc_Move_FFT_EnergyBands'], axis = 1)\n",
        "y_train_trans = all_df_train_trans['Label_segment'].values\n",
        "\n",
        "# convert to dummy category\n",
        "y_train_trans_dum = pd.get_dummies(y_train_trans)\n",
        "\n",
        "# scale data using fitted ss\n",
        "X_train_trans_scale = ss.transform(X_train_trans)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pq5IXyEs4-3j"
      },
      "source": [
        "# Getting X_val & y_val\n",
        "X_val_trans = all_df_val_trans.drop(['Unnamed: 0' , 'Label_segment' , 'Participant_ID' , 'Participant_Run',  'X_Acc_Move_FFT_EnergyBands', \t'Y_Acc_Move_FFT_EnergyBands', \t'Z_Acc_Move_FFT_EnergyBands'], axis = 1)\n",
        "y_val_trans = all_df_val_trans['Label_segment'].values\n",
        "\n",
        "# convert to dummy category\n",
        "y_val_trans_dum = pd.get_dummies(y_val_trans)\n",
        "\n",
        "# scale data using fitted ss\n",
        "X_val_trans_scale = ss.transform(X_val_trans)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jk4iFxu0539j"
      },
      "source": [
        "-------------------------\n",
        "\n",
        "Now give quick train on specific case \"Calibration\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WlkUrKH58q1"
      },
      "source": [
        "# Change learning rate from default adam = 0.001 , to 0.0001 and train for handful more epochs on specific participant data \n",
        "K.set_value(model.optimizer.learning_rate, 0.001)\n",
        "#K.set_value(model_smote.optimizer.learning_rate, 0.001)\n",
        "\n",
        "print(\"Learning rate before second fit:\", model.optimizer.learning_rate.numpy())\n",
        "#print(\"Learning rate before second fit:\", model_smote.optimizer.learning_rate.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mYM7rht6ING"
      },
      "source": [
        "Fit Specfic ID"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUkXnX7d6NF9"
      },
      "source": [
        "# just for timing model\n",
        "t0 = time.time()\n",
        "\n",
        "# fitting model \n",
        "new_history = model.fit(X_train_trans_scale, y_train_trans_dum,\n",
        "                    validation_data=(X_val_trans_scale, y_val_trans_dum),\n",
        "                    epochs = 3,\n",
        "                    batch_size= 200,\n",
        "                    callbacks = [earlyStopping]\n",
        "                    \n",
        "                    )\n",
        "\n",
        "\n",
        "t1 = time.time()\n",
        "\n",
        "total = t1-t0\n",
        "\n",
        "print(f'Time Taken: {total}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9Frg8beCZm4"
      },
      "source": [
        "**Smote Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r543b8LhCZ5t"
      },
      "source": [
        "# just for timing model\n",
        "t0 = time.time()\n",
        "\n",
        "# fitting model \n",
        "new_history = model_smote.fit(X_train_trans_scale, y_train_trans_dum,\n",
        "                    validation_data=(X_val_trans_scale, y_val_trans_dum),\n",
        "                    epochs = 5,\n",
        "                    batch_size= 200,\n",
        "                    callbacks = [earlyStopping]\n",
        "                    \n",
        "                    )\n",
        "\n",
        "\n",
        "t1 = time.time()\n",
        "\n",
        "total = t1-t0\n",
        "\n",
        "print(f'Time Taken: {total}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGs_oxsnGhkP"
      },
      "source": [
        "---------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7aTO9RpvsOO"
      },
      "source": [
        "def holdout_checker(smote = False):\n",
        "\n",
        "  # Read in Fresh Data to see what predictions looks like\n",
        "  from google.colab import files\n",
        "  uploaded_test = files.upload()\n",
        "\n",
        "  # getting keys, which is file names of csv\n",
        "  val_file_name = [key for key in uploaded_test.keys()]\n",
        "\n",
        "  # read in csv \n",
        "  signal_test = pd.read_csv(val_file_name[0])\n",
        "\n",
        "\n",
        "  # Getting X_train & y_train\n",
        "  X_data = signal_test.drop(['Unnamed: 0' , 'Label_segment' , 'Participant_ID' , 'Participant_Run','X_Acc_Move_FFT_EnergyBands', \t'Y_Acc_Move_FFT_EnergyBands', \t'Z_Acc_Move_FFT_EnergyBands' ], axis = 1)\n",
        "  #X_data = signal_test.drop(['Unnamed: 0' , 'Label_segment' , 'Participant_ID' , 'Participant_Run' ], axis = 1)\n",
        "\n",
        "  y_data = signal_test['Label_segment'].values\n",
        "\n",
        "  # scale with already fit ss \n",
        "  X_data_scale = ss.transform(X_data)\n",
        "\n",
        "  # convert to dummy category\n",
        "  y_data_dum = pd.get_dummies(y_data)\n",
        "  \n",
        "  # Take max of dummy classifier\n",
        "  y_data = np.argmax(np.asarray(y_data_dum), axis=1)\n",
        "\n",
        "  # make prediction with model\n",
        "\n",
        "  # if selecting smote trained model\n",
        "  if smote == True:\n",
        "    hold_preds = model_smote.predict(X_data_scale)\n",
        "\n",
        "  # else non-smote trained model\n",
        "  else:\n",
        "    hold_preds = model.predict(X_data_scale)\n",
        "\n",
        "  # take max of predictions \n",
        "  max_predictions = np.argmax(hold_preds, axis=1)\n",
        "\n",
        "  # metrics \n",
        "  print(\"\\n---------------------- Metrics ----------------------------------------\")\n",
        "\n",
        "  #print(\"Accuracy : \\t\\t\" ,accuracy_score(y_data, max_predictions))\n",
        "  print(\"Balanced Accuracy : \\t\" , balanced_accuracy_score(y_data, max_predictions))\n",
        "  print(\"F1 Score : \\t\\t\" , f1_score(y_data, max_predictions, average='weighted'))\n",
        "  print(\"Precision Score : \\t\\t\" , precision_score(y_data, max_predictions, average='weighted'))\n",
        "  print(\"Recall Score : \\t\\t\" , recall_score(y_data, max_predictions, average='weighted'))\n",
        "\n",
        "\n",
        "  # set up labels \n",
        "  LABELS = ['Go', 'Turn1',  'Turn2' , 'Walk1', 'Walk2', 'Sit']\n",
        "\n",
        "  # classification report \n",
        "  print(\"\\n------------------- HoldOut Classification Report ---------------\")\n",
        "  print(classification_report(y_data ,max_predictions))\n",
        "  print(\" \")\n",
        "\n",
        "  # confusion matrix\n",
        "  confusion_matrix_out = metrics.confusion_matrix(y_data, max_predictions )\n",
        "\n",
        "  plt.figure(figsize=(14, 10))\n",
        "  sns.heatmap(confusion_matrix_out, xticklabels=LABELS, yticklabels=LABELS, annot=True ,fmt=\"d\" )\n",
        "\n",
        "\n",
        "\n",
        "  plt.title(\"HoldOut Data Confusion matrix\")\n",
        "  plt.ylabel('True label')\n",
        "  plt.xlabel('Predicted label')\n",
        "  plt.show()\n",
        "\n",
        "  # lastly just printing actual predictions\n",
        "  print(\"\\n0 = Go \\t\\t 1 = Turn 1 \\t 2 = Turn 2\")\n",
        "  print(\"\\n3 = Walk 1 \\t 4 = Walk 2 \\t 5 = Sit\")\n",
        "\n",
        "  print(\" \")\n",
        "  print(max_predictions)\n",
        "\n",
        "  print(\"\\nTest Counts\" ,Counter(max_predictions))\n",
        "  print(\"\\nReal Counts\" ,Counter(y_data))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOlZc9dh0Jz-"
      },
      "source": [
        "holdout_checker()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOZpCTmRCmuw"
      },
      "source": [
        "holdout_checker(smote=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBL79MvpIZYB"
      },
      "source": [
        "holdout_checker()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIbWPE2DIZxX"
      },
      "source": [
        "holdout_checker(smote=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bf0fa5JnkymK"
      },
      "source": [
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "woUnPpP1k180"
      },
      "source": [
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yX_HPnTjQkf8"
      },
      "source": [
        "--------------------\n",
        "\n",
        "Hyper Tuning \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G01FtvYIQ8nT"
      },
      "source": [
        "from keras.optimizers import Adam , RMSprop, Adagrad"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaBrN0BQQ6Uc"
      },
      "source": [
        "optimisers = ['Adam' , 'RMSprop', 'Adagrad']\n",
        "\n",
        "batch_sizes = [50,200,1000]\n",
        "\n",
        "#learning_rate = [0.001 , 0.01, 0.1]\n",
        "\n",
        "learning_rate = [0.00001 , 0.0001]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQtR2PClQ2eV"
      },
      "source": [
        "#n_timesteps, n_features, n_outputs = X_train.shape[1] , X_train.shape[2] , y_train_dum.shape[1]\n",
        "\n",
        "n_outputs =  y_train_dum.shape[1]\n",
        "\n",
        "# set up model\n",
        "model = Sequential()\n",
        "\n",
        "#input layer\n",
        "model.add(Dense(100, activation='relu' , input_shape = (X_train_scale.shape[1], )))\n",
        "\n",
        "\n",
        "# hidden layers\n",
        "model.add(Dense(50, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(50, activation='relu'))\n",
        "# model.add(Dropout(0.5))\n",
        "# model.add(Dense(100, activation='relu'))\n",
        "\n",
        "# output layer\n",
        "model.add(Dense(n_outputs, activation='softmax'))\n",
        "\n",
        "model.save_weights('basemodel.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfp36iiDQ2eZ"
      },
      "source": [
        "Early Stopping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrfOeaGDQ2ea"
      },
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        " \t\n",
        "# patient early stopping\n",
        "#es = EarlyStopping(monitor='val_loss', mode='auto', verbose=1, patience=5 , min_delta=0.05)\n",
        "\n",
        "\n",
        "earlyStopping = EarlyStopping(monitor='val_loss', patience=5, verbose=0, mode='min')\n",
        "mcp_save = ModelCheckpoint('.base_model_wts.hdf5', save_best_only=True, monitor='val_loss', mode='min')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lN4neLfj_o_K"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, recall_score , precision_score\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yo9tfQkQ2ed"
      },
      "source": [
        "Fit "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "cVnWue1LQ2ef"
      },
      "source": [
        "list_of_f1           = []\n",
        "list_of_recall       = []\n",
        "list_of_precision    = []\n",
        "list_of_balacc       = []\n",
        "list_of_learningrate = []\n",
        "list_of_optim        = []\n",
        "list_of_batch        = []\n",
        "\n",
        "\n",
        "\n",
        "for i in range(len(optimisers)):\n",
        "\n",
        "  for size in batch_sizes:\n",
        "\n",
        "    for learn in learning_rate:\n",
        "\n",
        "      # resets the weights back to random\n",
        "      model.load_weights('basemodel.h5')\n",
        "\n",
        "      # compile model\n",
        "      model.compile(loss='categorical_crossentropy', optimizer= optimisers[i] , metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
        "\n",
        "      # set learning rate\n",
        "      K.set_value(model.optimizer.learning_rate, learn)\n",
        "\n",
        "      # just for timing model\n",
        "      t0 = time.time()\n",
        "\n",
        "      # fitting model \n",
        "      history = model.fit(X_train_scale, y_train_dum,\n",
        "                          validation_data=(X_test_scale, y_test_dum),\n",
        "                          epochs = 100,\n",
        "                          batch_size=size,\n",
        "                          callbacks=[earlyStopping, mcp_save]\n",
        "                          )\n",
        "\n",
        "\n",
        "      t1 = time.time()\n",
        "\n",
        "      total = t1-t0\n",
        "\n",
        "      print(f'Time Taken: {total}')\n",
        "\n",
        "      # For Confusion matrix & Classification Report \n",
        "\n",
        "      y_preds = model.predict(X_test_scale)\n",
        "      max_predictions = np.argmax(y_preds, axis=1)\n",
        "\n",
        "      max_test = np.argmax(np.asarray(y_test_dum), axis=1)\n",
        "\n",
        "      ##################\n",
        "\n",
        "\n",
        "      y_preds_train = model.predict(X_train_scale)\n",
        "\n",
        "      max_predictions_train = np.argmax(y_preds_train, axis=1)\n",
        "      max_train = np.argmax(np.asarray(y_train_dum), axis=1)\n",
        "\n",
        "\n",
        "      #############################\n",
        "\n",
        "      list_of_f1.append(f1_score(max_test, max_predictions , average='weighted'))          \n",
        "      list_of_recall.append(recall_score(max_test, max_predictions , average='weighted'))       \n",
        "      list_of_precision.append(precision_score(max_test, max_predictions , average='weighted'))    \n",
        "      list_of_balacc.append(balanced_accuracy_score(max_test, max_predictions))       \n",
        "      list_of_learningrate.append(learn) \n",
        "      list_of_optim.append(optimisers[i])\n",
        "      list_of_batch.append(size)\n",
        "\n",
        "\n",
        "      print(\"-\"*50)\n",
        "      print(\"\\n\")\n",
        "      #Metrics\n",
        "      print(f\"{optimisers[i]} - Learning Rate {learn} - Batch Size: {size}  -  Test Balanced Accuracy : \\t\" , balanced_accuracy_score(max_test, max_predictions))\n",
        "      print(f\"{optimisers[i]} - Learning Rate {learn} - Batch Size: {size}  -  Test F1 Score : \\t\\t\" , f1_score(max_test, max_predictions , average='weighted'))\n",
        "      print(f\"{optimisers[i]} - Learning Rate {learn} - Batch Size: {size}  -  Test Precision Score : \\t\\t\" , precision_score(max_test, max_predictions , average='weighted'))\n",
        "      print(f\"{optimisers[i]} - Learning Rate {learn} - Batch Size: {size}  -  Test Recall Score : \\t\\t\" , recall_score(max_test, max_predictions , average='weighted'))\n",
        "\n",
        "      print(\"\\n\")\n",
        "      print(\"-\"*50)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHVQksoIN565"
      },
      "source": [
        "new_df = pd.DataFrame()\n",
        "\n",
        "new_df['Optimizer'] = list_of_optim\n",
        "new_df['BatchSize'] = list_of_batch\n",
        "new_df['LearningRate'] = list_of_learningrate\n",
        "new_df['F1-Score'] = list_of_f1\n",
        "new_df['Balanced Accuracy'] = list_of_balacc\n",
        "new_df['Recall Score'] = list_of_recall\n",
        "new_df['Precision Score'] = list_of_precision\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0JuzqeuORAM"
      },
      "source": [
        "new_df[ (new_df['LearningRate'] == 0.001)  | (new_df['LearningRate'] == 0.01)   ]"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}