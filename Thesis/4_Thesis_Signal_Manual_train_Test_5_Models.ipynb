{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4_five_models_July_HC_5_LSTM_Manual_Train_Test_HandCraft_Thesis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrpbwbMBuGfd"
      },
      "source": [
        "# Handcrafted Features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrVWaVNkPW2k"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtX5iMQHPDII"
      },
      "source": [
        "\n",
        "########################### (https://github.com/curiousily/TensorFlow-on-Android-for-Human-Activity-Recognition-with-LSTMs/blob/master/human_activity_recognition.ipynb) imports\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "from scipy import stats\n",
        "import tensorflow as tf\n",
        "import seaborn as sns\n",
        "from pylab import rcParams\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "%matplotlib inline\n",
        "sns.set(style='whitegrid', palette='muted', font_scale=1.5)\n",
        "rcParams['figure.figsize'] = 14, 8\n",
        "RANDOM_SEED = 42\n",
        "\n",
        "#!pip install imbalanced-learn\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from collections import Counter\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from keras import backend as K\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "from matplotlib.pyplot import figure\n",
        "\n",
        "\n",
        "########################### (https://github.com/curiousily/TensorFlow-on-Android-for-Human-Activity-Recognition-with-LSTMs/blob/master/human_activity_recognition.ipynb) imports\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "from scipy import stats\n",
        "import tensorflow as tf\n",
        "import seaborn as sns\n",
        "from pylab import rcParams\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_M5F5DwPrKk"
      },
      "source": [
        "# Upload Data \n",
        "\n",
        "---------------------------------\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZX9OGsWPzvD"
      },
      "source": [
        "Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IyDYp-eLY8K"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded_signal_train = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "juXPVt1AP0v1"
      },
      "source": [
        "Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDlYInx_Pyx5"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded_signal_test = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFIL8q5nvqUf"
      },
      "source": [
        "### Reading in segments & labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y70o5U5mSOUU"
      },
      "source": [
        "Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxXU40eBttE6"
      },
      "source": [
        "# getting keys, which is file names of npy \n",
        "list_of_dataframes_train = [key for key in uploaded_signal_train.keys()]\n",
        "\n",
        "\n",
        "# set up list to hold all loaded npy \n",
        "all_dataframe_train = [] \n",
        "\n",
        "\n",
        "for i in range(len(list_of_dataframes_train)):\n",
        "\n",
        "    # load in the data \n",
        "    dataframe_train = pd.read_csv(list_of_dataframes_train[i])\n",
        "\n",
        "\n",
        "    # append the data to 'all' list\n",
        "    all_dataframe_train.append(dataframe_train) \n",
        "\n",
        "\n",
        "all_df_train = pd.concat(all_dataframe_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXzYX7vVSPqK"
      },
      "source": [
        "Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4s9Wo8YGSQeN"
      },
      "source": [
        "# getting keys, which is file names of npy \n",
        "list_of_dataframes_test = [key for key in uploaded_signal_test.keys()]\n",
        "\n",
        "\n",
        "# set up list to hold all loaded npy \n",
        "all_dataframe_test = [] \n",
        "\n",
        "\n",
        "for i in range(len(list_of_dataframes_test)):\n",
        "\n",
        "    # load in the data \n",
        "    dataframe_test = pd.read_csv(list_of_dataframes_test[i])\n",
        "\n",
        "\n",
        "    # append the data to 'all' list\n",
        "    all_dataframe_test.append(dataframe_test) \n",
        "\n",
        "\n",
        "all_df_test = pd.concat(all_dataframe_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8jsSnExgGesF"
      },
      "source": [
        "# Quick Look "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCEZ0lTrGiz3"
      },
      "source": [
        "all_df_train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJ-KTwnDGhYv"
      },
      "source": [
        "all_df_test.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVPv0iQ6SPeH"
      },
      "source": [
        "# Train Test Split for each phase "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLiLVQ8s5gxe"
      },
      "source": [
        "--------------------------------------------------\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcQsAFHs5pXd"
      },
      "source": [
        "all_df_train['Label_segment'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofYtU4o058nF"
      },
      "source": [
        "all_df_test['Label_segment'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdZVaJYR6Cmp"
      },
      "source": [
        "-------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raFK73r-TINN"
      },
      "source": [
        "dum_train = pd.get_dummies(all_df_train['Label_segment'] ,  prefix='Binary')\n",
        "dum_test  = pd.get_dummies(all_df_test['Label_segment'] ,  prefix='Binary')\n",
        "\n",
        "print(dum_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGPncWXdTeMe"
      },
      "source": [
        "# Concate the dummy variables back into dataframe \n",
        "\n",
        "all_df_train = pd.concat([all_df_train, dum_train] , axis=1)\n",
        "all_df_test = pd.concat([all_df_test, dum_test] , axis=1)\n",
        "\n",
        "all_df_train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2C9pvTS5eCr"
      },
      "source": [
        "-------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OoV7ljxDJ9I"
      },
      "source": [
        "Quick Shuffle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y24PtCKVDKMU"
      },
      "source": [
        "all_df_train = shuffle(all_df_train)\n",
        "all_df_test = shuffle(all_df_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogGPt-RCU2rX"
      },
      "source": [
        "all_df_train.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlyxtKg4SRMP"
      },
      "source": [
        "# Getting X_train & y_train\n",
        "X_train = all_df_train.drop(['Unnamed: 0' , 'Label_segment' , 'Participant_ID' , 'Participant_Run', 'X_Acc_Move_FFT_EnergyBands', \t'Y_Acc_Move_FFT_EnergyBands', \t'Z_Acc_Move_FFT_EnergyBands' ,\n",
        "                             'Binary_Go' , 'Binary_Walk 1', 'Binary_Turn 1', 'Binary_Walk 2', 'Binary_Turn 2', 'Binary_sit' \t], axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0U8FMop_Cie5"
      },
      "source": [
        "# Y Train Go\n",
        "y_train_go = all_df_train['Binary_Go'].values\n",
        "\n",
        "# Y Train Walk 1 \n",
        "y_train_walk1 = all_df_train['Binary_Walk 1'].values\n",
        "\n",
        "# Y Train Turn 1 \n",
        "y_train_turn1 = all_df_train['Binary_Turn 1'].values\n",
        "\n",
        "# Y Train Walk 2 \n",
        "y_train_walk2 = all_df_train['Binary_Walk 2'].values\n",
        "\n",
        "# Y Train Turn 2 \n",
        "y_train_turn2 = all_df_train['Binary_Turn 2'].values\n",
        "\n",
        "# Y Train Sit \n",
        "y_train_sit = all_df_train['Binary_sit'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fvy2g_7hFgeo"
      },
      "source": [
        "import imblearn\n",
        "#print(imblearn.__version__)\n",
        "\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "rs = RandomUnderSampler(random_state=42 ,sampling_strategy ='majority')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2g-9YZcVoaO"
      },
      "source": [
        "# fit and apply the transform\n",
        "X_train_under_go, y_train_under_go = rs.fit_resample(X_train, y_train_go)\n",
        "\n",
        "\n",
        "# fit and apply the transform\n",
        "X_train_under_walk1, y_train_under_walk1 = X_train, y_train_walk1\n",
        "\n",
        "\n",
        "# fit and apply the transform\n",
        "X_train_under_walk2, y_train_under_walk2 = X_train, y_train_walk2\n",
        "\n",
        "\n",
        "# fit and apply the transform\n",
        "X_train_under_turn1, y_train_under_turn1 = X_train, y_train_turn1\n",
        "\n",
        "\n",
        "# fit and apply the transform\n",
        "X_train_under_turn2, y_train_under_turn2 = X_train, y_train_turn2\n",
        "\n",
        "# fit and apply the transform\n",
        "X_train_under_sit, y_train_under_sit = rs.fit_resample(X_train, y_train_sit)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccrTNM-wpUH2"
      },
      "source": [
        "--------------------------\n",
        "\n",
        "Logic Check since using 2 pd.get_dums \n",
        "\n",
        "Go's will be coded as 0 and not Go 1 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "As_C58Mom4rD"
      },
      "source": [
        "print(Counter(y_train_go))\n",
        "\n",
        "print(Counter( y_train_under_go))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0a-oryQpcPD"
      },
      "source": [
        "-----------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcQuIfcXMipf"
      },
      "source": [
        "# convert to dummy category\n",
        "y_train_under_dum_go = pd.get_dummies(y_train_under_go)\n",
        "\n",
        "# convert to dummy category\n",
        "y_train_under_dum_walk1 = pd.get_dummies(y_train_under_walk1)\n",
        "\n",
        "\n",
        "# convert to dummy category\n",
        "y_train_under_dum_walk2 = pd.get_dummies(y_train_under_walk2)\n",
        "\n",
        "\n",
        "# convert to dummy category\n",
        "y_train_under_dum_turn1 = pd.get_dummies(y_train_under_turn1)\n",
        "\n",
        "# convert to dummy category\n",
        "y_train_under_dum_turn2 = pd.get_dummies(y_train_under_turn2)\n",
        "\n",
        "# convert to dummy category\n",
        "y_train_under_dum_sit = pd.get_dummies(y_train_under_sit)\n",
        "\n",
        "\n",
        "# check one \n",
        "print(f'\\nDummy labels Shape {y_train_under_dum_go.shape}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1ArXqwrFhFK"
      },
      "source": [
        "------------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyOL-dTlTDbw"
      },
      "source": [
        "# Getting X_train & y_train\n",
        "\n",
        "X_test =  all_df_test.drop(['Unnamed: 0' , 'Label_segment' , 'Participant_ID' , 'Participant_Run',  'X_Acc_Move_FFT_EnergyBands', \t'Y_Acc_Move_FFT_EnergyBands', \t'Z_Acc_Move_FFT_EnergyBands' ,\n",
        "                             'Binary_Go' , 'Binary_Walk 1', 'Binary_Turn 1', 'Binary_Walk 2', 'Binary_Turn 2', 'Binary_sit' \t], axis = 1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bm4EnbuWuCp"
      },
      "source": [
        "y_test_go =  all_df_test['Binary_Go'].values\n",
        "\n",
        "y_test_walk1=  all_df_test['Binary_Walk 1'].values\n",
        "\n",
        "y_test_walk2 =  all_df_test['Binary_Walk 2'].values\n",
        "\n",
        "y_test_turn1 =  all_df_test['Binary_Turn 1'].values\n",
        "\n",
        "y_test_turn2 =  all_df_test['Binary_Turn 2'].values\n",
        "\n",
        "y_test_sit =  all_df_test['Binary_sit'].values\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYho3uJKC0FZ"
      },
      "source": [
        "# convert to dummy category\n",
        "y_test_dum_go = pd.get_dummies(y_test_go)\n",
        "\n",
        "# convert to dummy category\n",
        "y_test_dum_walk1 = pd.get_dummies(y_test_walk1)\n",
        "\n",
        "# convert to dummy category\n",
        "y_test_dum_walk2 = pd.get_dummies(y_test_walk2)\n",
        "\n",
        "# convert to dummy category\n",
        "y_test_dum_turn1 = pd.get_dummies(y_test_turn1)\n",
        "\n",
        "# convert to dummy category\n",
        "y_test_dum_turn2 = pd.get_dummies(y_test_turn2)\n",
        "\n",
        "# convert to dummy category\n",
        "y_test_dum_sit = pd.get_dummies(y_test_sit)\n",
        "\n",
        "\n",
        "# test one\n",
        "print(f'\\nDummy labels Shape {y_test_dum_go.shape}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFFnYKxVTIf6"
      },
      "source": [
        "--------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tVnwD0csNgw"
      },
      "source": [
        "Standard Scale "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFhyhbcjsO7K"
      },
      "source": [
        "# Set up ss for non-shuffled data\n",
        "ss = StandardScaler()\n",
        "\n",
        "\n",
        "X_train_under_go_scale = ss.fit_transform(X_train_under_go)\n",
        "\n",
        "X_train_under_walk1_scale = ss.fit_transform(X_train_under_walk1)\n",
        "\n",
        "X_train_under_walk2_scale = ss.fit_transform(X_train_under_walk2)\n",
        "\n",
        "X_train_under_turn1_scale = ss.fit_transform(X_train_under_turn1)\n",
        "\n",
        "X_train_under_turn2_scale = ss.fit_transform(X_train_under_turn2)\n",
        "\n",
        "X_train_under_sit_scale = ss.fit_transform(X_train_under_sit)\n",
        "\n",
        "\n",
        "X_test_scale = ss.transform(X_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TyYBySVJQjQY"
      },
      "source": [
        "----------------------\n",
        "\n",
        "Shuffle Again"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnMt4WSEQlMt"
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "\n",
        "X_train_under_go_scale    , y_train_under_dum_go    = shuffle(X_train_under_go_scale , y_train_under_dum_go , random_state= 0)\n",
        "\n",
        "X_train_under_walk1_scale , y_train_under_dum_walk1 = shuffle(X_train_under_walk1_scale , y_train_under_dum_walk1 , random_state= 0)\n",
        "\n",
        "X_train_under_walk2_scale, y_train_under_dum_walk2 = shuffle(X_train_under_walk2_scale, y_train_under_dum_walk2 , random_state= 0)\n",
        "\n",
        "X_train_under_turn1_scale, y_train_under_dum_turn1 = shuffle(X_train_under_turn1_scale, y_train_under_dum_turn1 , random_state= 0)\n",
        "\n",
        "X_train_under_turn2_scale, y_train_under_dum_turn2 = shuffle(X_train_under_turn2_scale, y_train_under_dum_turn2 , random_state= 0)\n",
        "\n",
        "X_train_under_sit_scale,   y_train_under_dum_sit = shuffle(X_train_under_sit_scale, y_train_under_dum_sit , random_state= 0)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmI_62XaSoYf"
      },
      "source": [
        "---------------------------\n",
        "\n",
        "Deep "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWbPnaf7S09a"
      },
      "source": [
        "# lstm model\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from numpy import dstack\n",
        "from pandas import read_csv\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import TimeDistributed\n",
        "from matplotlib import pyplot\n",
        "\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "import time\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezQ2HI9qYE9E"
      },
      "source": [
        "------------------------------------------------------\n",
        "\n",
        "# Go"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijn3-yBIS6SX"
      },
      "source": [
        "#n_timesteps, n_features, n_outputs = X_train.shape[1] , X_train.shape[2] , y_train_dum.shape[1]\n",
        "\n",
        "n_outputs =  y_train_under_dum_go.shape[1]\n",
        "\n",
        "# set up model\n",
        "model = Sequential()\n",
        "\n",
        "#input layer\n",
        "model.add(Dense(100, activation='relu' , input_shape = (X_train_under_go_scale.shape[1], )))\n",
        "\n",
        "\n",
        "# hidden layers\n",
        "model.add(Dense(50, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(50, activation='relu'))\n",
        "# model.add(Dropout(0.5))\n",
        "# model.add(Dense(100, activation='relu'))\n",
        "\n",
        "# output layer\n",
        "model.add(Dense(n_outputs, activation='softmax'))\n",
        "\n",
        "# compile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[tf.keras.metrics.CategoricalAccuracy()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZnLHWPxT4mP"
      },
      "source": [
        "Early Stopping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pH_6vdl4T4K4"
      },
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        " \t\n",
        "# patient early stopping\n",
        "#es = EarlyStopping(monitor='val_loss', mode='auto', verbose=1, patience=5 , min_delta=0.05)\n",
        "\n",
        "\n",
        "earlyStopping = EarlyStopping(monitor='val_loss', patience=5, verbose=0, mode='min')\n",
        "mcp_save = ModelCheckpoint('.base_model_wts.hdf5', save_best_only=True, monitor='val_loss', mode='min')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDcTe09pT90L"
      },
      "source": [
        "Fit "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJ1jMHoyT7IS"
      },
      "source": [
        "# just for timing model\n",
        "t0 = time.time()\n",
        "\n",
        "# fitting model \n",
        "history = model.fit(X_train_under_go_scale, y_train_under_dum_go,\n",
        "                    validation_data=(X_test_scale, y_test_dum_go ),\n",
        "                    epochs = 100,\n",
        "                    batch_size=200,\n",
        "                    callbacks=[earlyStopping, mcp_save]\n",
        "                    )\n",
        "\n",
        "\n",
        "t1 = time.time()\n",
        "\n",
        "total = t1-t0\n",
        "\n",
        "print(f'Time Taken: {total}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnCgxPxEatRz"
      },
      "source": [
        "Learning Curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noy3cqnyaxCZ"
      },
      "source": [
        "history_dict = history.history\n",
        "loss_values = history_dict['loss']\n",
        "val_loss_values = history_dict['val_loss']\n",
        "accuracy = history_dict['categorical_accuracy']\n",
        "val_accuracy = history_dict['val_categorical_accuracy']\n",
        " \n",
        "epochs = range(1, len(loss_values) + 1)\n",
        "fig, ax = plt.subplots(1, 2, figsize=(14, 6))\n",
        "#\n",
        "# Plot the model accuracy vs Epochs\n",
        "#\n",
        "ax[0].plot(epochs, accuracy, 'r', label='Training accuracy')\n",
        "ax[0].plot(epochs, val_accuracy, 'b', label='Validation accuracy')\n",
        "ax[0].set_title('Training & Validation Accuracy', fontsize=16)\n",
        "ax[0].set_xlabel('Epochs', fontsize=16)\n",
        "ax[0].set_ylabel('Accuracy', fontsize=16)\n",
        "ax[0].legend()\n",
        "#\n",
        "# Plot the loss vs Epochs\n",
        "#\n",
        "ax[1].plot(epochs, loss_values, 'r', label='Training loss')\n",
        "ax[1].plot(epochs, val_loss_values, 'b', label='Validation loss')\n",
        "ax[1].set_title('Training & Validation Loss', fontsize=16)\n",
        "ax[1].set_xlabel('Epochs', fontsize=16)\n",
        "ax[1].set_ylabel('Loss', fontsize=16)\n",
        "ax[1].legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oB3ENVF9a6xv"
      },
      "source": [
        "------------------------\n",
        "\n",
        "Reports"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OI5PTbCb6MJW"
      },
      "source": [
        "Make Predicitions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pZrUb3e9SSH"
      },
      "source": [
        "# For Confusion matrix & Classification Report \n",
        "\n",
        "y_preds = model.predict(X_test_scale)\n",
        "max_predictions = np.argmax(y_preds, axis=1)\n",
        "\n",
        "max_test = np.argmax(np.asarray(y_test_dum_go), axis=1)\n",
        "\n",
        "\n",
        "\n",
        "##################\n",
        "\n",
        "\n",
        "y_preds_train = model.predict(X_train_under_go_scale)\n",
        "\n",
        "max_predictions_train = np.argmax(y_preds_train, axis=1)\n",
        "max_train = np.argmax(np.asarray(y_train_under_dum_go), axis=1)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocbl1VTVaZXO"
      },
      "source": [
        "# Metrics "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGPfaIQna1qB"
      },
      "source": [
        "Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63JnyIrJaai2"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "print(\"Test Accuracy : \\t\\t\" ,accuracy_score(max_test, max_predictions))\n",
        "print(\"Test Balanced Accuracy : \\t\" , balanced_accuracy_score(max_test, max_predictions))\n",
        "print(\"Test F1 Score : \\t\\t\" , f1_score(max_test, max_predictions , average='weighted'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1EjHZjy0a2vF"
      },
      "source": [
        "Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6DnA8cfa_wz"
      },
      "source": [
        "print(\"Train Accuracy : \\t\\t\" ,accuracy_score(max_train, max_predictions_train))\n",
        "print(\"Train Balanced Accuracy : \\t\" , balanced_accuracy_score(max_train, max_predictions_train))\n",
        "print(\"Train F1 Score : \\t\\t\" , f1_score(max_train, max_predictions_train, average='weighted'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2LpL8jl3WE1"
      },
      "source": [
        "Imports "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9cJEhcm7Hcv"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# set up labels \n",
        "LABELS = [ 'Not Go' , 'Go' ]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VPW38Ol13r7"
      },
      "source": [
        "# Test Set "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cmqio-IFxVKT"
      },
      "source": [
        "print(classification_report(max_test, max_predictions , target_names=LABELS))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmAM0Jp115kv"
      },
      "source": [
        "# Train Set "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLpbBnmV11_2"
      },
      "source": [
        "print(classification_report(max_train, max_predictions_train , target_names=LABELS))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGyuwOAC3RTT"
      },
      "source": [
        "--------------------\n",
        "\n",
        "# Confusion Matrix "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3I2gx2Z_BGG"
      },
      "source": [
        "confusion_matrix = metrics.confusion_matrix(max_test, max_predictions  )\n",
        "\n",
        "confusion_matrix_t = metrics.confusion_matrix(max_train, max_predictions_train )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qU1i78_3_m23"
      },
      "source": [
        "plt.figure(figsize=(14, 10))\n",
        "sns.heatmap(confusion_matrix, xticklabels=LABELS, yticklabels=LABELS,  annot=True, fmt=\"d\");\n",
        "plt.title(\"Test Data Confusion matrix\")\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u31mjLP2Dxwp"
      },
      "source": [
        "plt.figure(figsize=(14, 10))\n",
        "sns.heatmap(confusion_matrix_t, xticklabels=LABELS, yticklabels=LABELS, annot=True, fmt=\"d\");\n",
        "plt.title(\"Train Confusion matrix\")\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_zZcYxTSqFQ"
      },
      "source": [
        "-------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1FdW-A3SvYG"
      },
      "source": [
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fI8_OztyBMYW"
      },
      "source": [
        "------------------------------------------------------\n",
        "\n",
        "# Walk 1 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CNhaSgNBMYX"
      },
      "source": [
        "#n_timesteps, n_features, n_outputs = X_train.shape[1] , X_train.shape[2] , y_train_dum.shape[1]\n",
        "\n",
        "n_outputs =  y_train_under_dum_go.shape[1]\n",
        "\n",
        "# set up model\n",
        "model_walk1 = Sequential()\n",
        "\n",
        "#input layer\n",
        "model_walk1.add(Dense(100, activation='relu' , input_shape = (X_train_under_go_scale.shape[1], )))\n",
        "\n",
        "\n",
        "# hidden layers\n",
        "model_walk1.add(Dense(50, activation='relu'))\n",
        "model_walk1.add(Dropout(0.5))\n",
        "model_walk1.add(Dense(50, activation='relu'))\n",
        "# model.add(Dropout(0.5))\n",
        "# model.add(Dense(100, activation='relu'))\n",
        "\n",
        "# output layer\n",
        "model_walk1.add(Dense(n_outputs, activation='softmax'))\n",
        "\n",
        "# compile model\n",
        "model_walk1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[tf.keras.metrics.CategoricalAccuracy()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rr8weJMoBMYX"
      },
      "source": [
        "Early Stopping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oB8Vi5SOBMYY"
      },
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        " \t\n",
        "# patient early stopping\n",
        "#es = EarlyStopping(monitor='val_loss', mode='auto', verbose=1, patience=5 , min_delta=0.05)\n",
        "\n",
        "\n",
        "earlyStopping = EarlyStopping(monitor='val_loss', patience=5, verbose=0, mode='min')\n",
        "mcp_save = ModelCheckpoint('.base_model_wts.hdf5', save_best_only=True, monitor='val_loss', mode='min')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMz6zYjrBMYZ"
      },
      "source": [
        "Fit "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DK88lscaBMYa"
      },
      "source": [
        "# just for timing model\n",
        "t0 = time.time()\n",
        "\n",
        "# fitting model \n",
        "history_walk1 = model_walk1.fit(X_train_under_walk1_scale, y_train_under_dum_walk1,\n",
        "                    validation_data=(X_test_scale, y_test_dum_walk1 ),\n",
        "                    epochs = 100,\n",
        "                    batch_size=20,\n",
        "                    callbacks=[earlyStopping, mcp_save]\n",
        "                    )\n",
        "\n",
        "\n",
        "t1 = time.time()\n",
        "\n",
        "total = t1-t0\n",
        "\n",
        "print(f'Time Taken: {total}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NoKbfK-lBMYb"
      },
      "source": [
        "Learning Curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmvfS3cfBMYb"
      },
      "source": [
        "history_dict = history_walk1.history\n",
        "loss_values = history_dict['loss']\n",
        "val_loss_values = history_dict['val_loss']\n",
        "accuracy = history_dict['categorical_accuracy']\n",
        "val_accuracy = history_dict['val_categorical_accuracy']\n",
        " \n",
        "epochs = range(1, len(loss_values) + 1)\n",
        "fig, ax = plt.subplots(1, 2, figsize=(14, 6))\n",
        "#\n",
        "# Plot the model accuracy vs Epochs\n",
        "#\n",
        "ax[0].plot(epochs, accuracy, 'r', label='Training accuracy')\n",
        "ax[0].plot(epochs, val_accuracy, 'b', label='Validation accuracy')\n",
        "ax[0].set_title('Training & Validation Accuracy', fontsize=16)\n",
        "ax[0].set_xlabel('Epochs', fontsize=16)\n",
        "ax[0].set_ylabel('Accuracy', fontsize=16)\n",
        "ax[0].legend()\n",
        "#\n",
        "# Plot the loss vs Epochs\n",
        "#\n",
        "ax[1].plot(epochs, loss_values, 'r', label='Training loss')\n",
        "ax[1].plot(epochs, val_loss_values, 'b', label='Validation loss')\n",
        "ax[1].set_title('Training & Validation Loss', fontsize=16)\n",
        "ax[1].set_xlabel('Epochs', fontsize=16)\n",
        "ax[1].set_ylabel('Loss', fontsize=16)\n",
        "ax[1].legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SboXTO5YBMYc"
      },
      "source": [
        "------------------------\n",
        "\n",
        "Reports"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pr0wUDeyBMYc"
      },
      "source": [
        "Make Predicitions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dex3MEH8BMYd"
      },
      "source": [
        "# For Confusion matrix & Classification Report \n",
        "\n",
        "y_preds = model_walk1.predict(X_test_scale)\n",
        "max_predictions = np.argmax(y_preds, axis=1)\n",
        "\n",
        "max_test = np.argmax(np.asarray(y_test_dum_walk1), axis=1)\n",
        "\n",
        "##################\n",
        "\n",
        "\n",
        "y_preds_train = model_walk1.predict(X_train_under_walk1_scale)\n",
        "\n",
        "max_predictions_train = np.argmax(y_preds_train, axis=1)\n",
        "max_train = np.argmax(np.asarray(y_train_under_dum_walk1), axis=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGzsdvC6BMYe"
      },
      "source": [
        "# Metrics "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZUqJX-TBMYe"
      },
      "source": [
        "Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwgeO5PGBMYe"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "print(\"Test Accuracy : \\t\\t\" ,accuracy_score(max_test, max_predictions))\n",
        "print(\"Test Balanced Accuracy : \\t\" , balanced_accuracy_score(max_test, max_predictions))\n",
        "print(\"Test F1 Score : \\t\\t\" , f1_score(max_test, max_predictions , average='weighted'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2-E7q0YBMYf"
      },
      "source": [
        "Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9njF2-3tBMYf"
      },
      "source": [
        "print(\"Train Accuracy : \\t\\t\" ,accuracy_score(max_train, max_predictions_train))\n",
        "print(\"Train Balanced Accuracy : \\t\" , balanced_accuracy_score(max_train, max_predictions_train))\n",
        "print(\"Train F1 Score : \\t\\t\" , f1_score(max_train, max_predictions_train, average='weighted'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycWmDlkLBMYf"
      },
      "source": [
        "Imports "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTxb4gehBMYg"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# set up labels \n",
        "LABELS = ['Not Walk 1', 'Walk 1']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5flAubuBMYg"
      },
      "source": [
        "# Test Set "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UIDuhO6BMYg"
      },
      "source": [
        "print(classification_report(max_test, max_predictions , target_names=LABELS))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QupKrgLBMYh"
      },
      "source": [
        "# Train Set "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTBYnipKBMYh"
      },
      "source": [
        "print(classification_report(max_train, max_predictions_train , target_names=LABELS))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfNGkOwkBMYi"
      },
      "source": [
        "--------------------\n",
        "\n",
        "# Confusion Matrix "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zObafPveBMYi"
      },
      "source": [
        "confusion_matrix = metrics.confusion_matrix(max_test, max_predictions  )\n",
        "\n",
        "confusion_matrix_t = metrics.confusion_matrix(max_train, max_predictions_train )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0oNxQtWqBMYi"
      },
      "source": [
        "plt.figure(figsize=(14, 10))\n",
        "sns.heatmap(confusion_matrix, xticklabels=LABELS, yticklabels=LABELS,  annot=True, fmt=\"d\");\n",
        "plt.title(\"Test Data Confusion matrix\")\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4gkGad5BMYj"
      },
      "source": [
        "plt.figure(figsize=(14, 10))\n",
        "sns.heatmap(confusion_matrix_t, xticklabels=LABELS, yticklabels=LABELS, annot=True, fmt=\"d\");\n",
        "plt.title(\"Train Confusion matrix\")\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKY-ZKvXBMYj"
      },
      "source": [
        "-------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_sPKAn_CEAm"
      },
      "source": [
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pm2KQ3bLB_q9"
      },
      "source": [
        "------------------------------------------------------\n",
        "\n",
        "# Walk 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_7NadeKB_q-"
      },
      "source": [
        "#n_timesteps, n_features, n_outputs = X_train.shape[1] , X_train.shape[2] , y_train_dum.shape[1]\n",
        "\n",
        "n_outputs =  y_train_under_dum_go.shape[1]\n",
        "\n",
        "# set up model\n",
        "model_walk2 = Sequential()\n",
        "\n",
        "#input layer\n",
        "model_walk2.add(Dense(100, activation='relu' , input_shape = (X_train_under_go_scale.shape[1], )))\n",
        "\n",
        "\n",
        "# hidden layers\n",
        "model_walk2.add(Dense(50, activation='relu'))\n",
        "model_walk2.add(Dropout(0.5))\n",
        "model_walk2.add(Dense(50, activation='relu'))\n",
        "# model.add(Dropout(0.5))\n",
        "# model.add(Dense(100, activation='relu'))\n",
        "\n",
        "# output layer\n",
        "model_walk2.add(Dense(n_outputs, activation='softmax'))\n",
        "\n",
        "# compile model\n",
        "model_walk2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[tf.keras.metrics.CategoricalAccuracy()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fK0KOat_B_q_"
      },
      "source": [
        "Early Stopping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OyiTMoIsB_rA"
      },
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        " \t\n",
        "# patient early stopping\n",
        "#es = EarlyStopping(monitor='val_loss', mode='auto', verbose=1, patience=5 , min_delta=0.05)\n",
        "\n",
        "\n",
        "earlyStopping = EarlyStopping(monitor='val_loss', patience=5, verbose=0, mode='min')\n",
        "mcp_save = ModelCheckpoint('.base_model_wts.hdf5', save_best_only=True, monitor='val_loss', mode='min')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d71CcQMVB_rB"
      },
      "source": [
        "Fit "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_RuKUXgB_rB"
      },
      "source": [
        "# just for timing model\n",
        "t0 = time.time()\n",
        "\n",
        "# fitting model \n",
        "history_walk2 = model_walk2.fit(X_train_under_walk2_scale, y_train_under_dum_walk2,\n",
        "                    validation_data=(X_test_scale, y_test_dum_walk2 ),\n",
        "                    epochs = 100,\n",
        "                    batch_size=200,\n",
        "                    callbacks=[earlyStopping, mcp_save]\n",
        "                    )\n",
        "\n",
        "\n",
        "t1 = time.time()\n",
        "\n",
        "total = t1-t0\n",
        "\n",
        "print(f'Time Taken: {total}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSygf17YB_rC"
      },
      "source": [
        "Learning Curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYw0BD7BB_rC"
      },
      "source": [
        "history_dict = history_walk2.history\n",
        "loss_values = history_dict['loss']\n",
        "val_loss_values = history_dict['val_loss']\n",
        "accuracy = history_dict['categorical_accuracy']\n",
        "val_accuracy = history_dict['val_categorical_accuracy']\n",
        " \n",
        "epochs = range(1, len(loss_values) + 1)\n",
        "fig, ax = plt.subplots(1, 2, figsize=(14, 6))\n",
        "#\n",
        "# Plot the model accuracy vs Epochs\n",
        "#\n",
        "ax[0].plot(epochs, accuracy, 'r', label='Training accuracy')\n",
        "ax[0].plot(epochs, val_accuracy, 'b', label='Validation accuracy')\n",
        "ax[0].set_title('Training & Validation Accuracy', fontsize=16)\n",
        "ax[0].set_xlabel('Epochs', fontsize=16)\n",
        "ax[0].set_ylabel('Accuracy', fontsize=16)\n",
        "ax[0].legend()\n",
        "#\n",
        "# Plot the loss vs Epochs\n",
        "#\n",
        "ax[1].plot(epochs, loss_values, 'r', label='Training loss')\n",
        "ax[1].plot(epochs, val_loss_values, 'b', label='Validation loss')\n",
        "ax[1].set_title('Training & Validation Loss', fontsize=16)\n",
        "ax[1].set_xlabel('Epochs', fontsize=16)\n",
        "ax[1].set_ylabel('Loss', fontsize=16)\n",
        "ax[1].legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QbW5k4WB_rD"
      },
      "source": [
        "------------------------\n",
        "\n",
        "Reports"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZ5sWaVLB_rE"
      },
      "source": [
        "Make Predicitions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiDWgIZyB_rG"
      },
      "source": [
        "# For Confusion matrix & Classification Report \n",
        "\n",
        "y_preds = model_walk2.predict(X_test_scale)\n",
        "max_predictions = np.argmax(y_preds, axis=1)\n",
        "\n",
        "max_test = np.argmax(np.asarray(y_test_dum_walk2), axis=1)\n",
        "\n",
        "##################\n",
        "\n",
        "\n",
        "y_preds_train = model_walk2.predict(X_train_under_walk2_scale)\n",
        "\n",
        "max_predictions_train = np.argmax(y_preds_train, axis=1)\n",
        "max_train = np.argmax(np.asarray(y_train_under_dum_walk2), axis=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOGvqzkSB_rG"
      },
      "source": [
        "# Metrics "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQCoQbm1B_rG"
      },
      "source": [
        "Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_d118mSEB_rH"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "print(\"Test Accuracy : \\t\\t\" ,accuracy_score(max_test, max_predictions))\n",
        "print(\"Test Balanced Accuracy : \\t\" , balanced_accuracy_score(max_test, max_predictions))\n",
        "print(\"Test F1 Score : \\t\\t\" , f1_score(max_test, max_predictions , average='weighted'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgP1UPzJB_rH"
      },
      "source": [
        "Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxIkIgZeB_rH"
      },
      "source": [
        "print(\"Train Accuracy : \\t\\t\" ,accuracy_score(max_train, max_predictions_train))\n",
        "print(\"Train Balanced Accuracy : \\t\" , balanced_accuracy_score(max_train, max_predictions_train))\n",
        "print(\"Train F1 Score : \\t\\t\" , f1_score(max_train, max_predictions_train, average='weighted'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0eM8qXjB_rI"
      },
      "source": [
        "Imports "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PngMew-8B_rI"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# set up labels \n",
        "LABELS = ['Not Walk 2', 'Walk 2']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7Cm2eaJB_rJ"
      },
      "source": [
        "# Test Set "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdpZuQNhB_rJ"
      },
      "source": [
        "print(classification_report(max_test, max_predictions,  target_names=LABELS))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iz_4mHFlB_rK"
      },
      "source": [
        "# Train Set "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pp4K_llZB_rK"
      },
      "source": [
        "print(classification_report(max_train, max_predictions_train , target_names=LABELS))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZKp7rBeB_rK"
      },
      "source": [
        "--------------------\n",
        "\n",
        "# Confusion Matrix "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7T9N9gcJB_rL"
      },
      "source": [
        "confusion_matrix = metrics.confusion_matrix(max_test, max_predictions  )\n",
        "\n",
        "confusion_matrix_t = metrics.confusion_matrix(max_train, max_predictions_train )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyR79d7kB_rL"
      },
      "source": [
        "plt.figure(figsize=(14, 10))\n",
        "sns.heatmap(confusion_matrix, xticklabels=LABELS, yticklabels=LABELS,  annot=True, fmt=\"d\");\n",
        "plt.title(\"Test Data Confusion matrix\")\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hJBpMUUB_rM"
      },
      "source": [
        "plt.figure(figsize=(14, 10))\n",
        "sns.heatmap(confusion_matrix_t, xticklabels=LABELS, yticklabels=LABELS, annot=True, fmt=\"d\");\n",
        "plt.title(\"Train Confusion matrix\")\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luG-HdlzB_rM"
      },
      "source": [
        "-------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dpqs43SJ3YZ"
      },
      "source": [
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srDuvMA-Fsal"
      },
      "source": [
        "------------------------------------------------------\n",
        "\n",
        "# Turn 1 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVvpwv5xFsam"
      },
      "source": [
        "#n_timesteps, n_features, n_outputs = X_train.shape[1] , X_train.shape[2] , y_train_dum.shape[1]\n",
        "\n",
        "n_outputs =  y_train_under_dum_go.shape[1]\n",
        "\n",
        "# set up model\n",
        "model_turn1 = Sequential()\n",
        "\n",
        "#input layer\n",
        "model_turn1.add(Dense(100, activation='relu' , input_shape = (X_train_under_go_scale.shape[1], )))\n",
        "\n",
        "\n",
        "# hidden layers\n",
        "model_turn1.add(Dense(50, activation='relu'))\n",
        "model_turn1.add(Dropout(0.5))\n",
        "model_turn1.add(Dense(50, activation='relu'))\n",
        "# model.add(Dropout(0.5))\n",
        "# model.add(Dense(100, activation='relu'))\n",
        "\n",
        "# output layer\n",
        "model_turn1.add(Dense(n_outputs, activation='softmax'))\n",
        "\n",
        "# compile model\n",
        "model_turn1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[tf.keras.metrics.CategoricalAccuracy()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vo4bTcaoFsan"
      },
      "source": [
        "Early Stopping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98vkcHB-Fsao"
      },
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        " \t\n",
        "# patient early stopping\n",
        "#es = EarlyStopping(monitor='val_loss', mode='auto', verbose=1, patience=5 , min_delta=0.05)\n",
        "\n",
        "\n",
        "earlyStopping = EarlyStopping(monitor='val_loss', patience=5, verbose=0, mode='min')\n",
        "mcp_save = ModelCheckpoint('.base_model_wts.hdf5', save_best_only=True, monitor='val_loss', mode='min')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3CdW7HFLFsap"
      },
      "source": [
        "Fit "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VncaTH3GFsar"
      },
      "source": [
        "# just for timing model\n",
        "t0 = time.time()\n",
        "\n",
        "# fitting model \n",
        "history_turn1 = model_turn1.fit(X_train_under_turn1_scale, y_train_under_dum_turn1,\n",
        "                    validation_data=(X_test_scale, y_test_dum_turn1 ),\n",
        "                    epochs = 100,\n",
        "                    batch_size=200,\n",
        "                    callbacks=[earlyStopping, mcp_save]\n",
        "                    )\n",
        "\n",
        "\n",
        "t1 = time.time()\n",
        "\n",
        "total = t1-t0\n",
        "\n",
        "print(f'Time Taken: {total}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLIXCmfdFsat"
      },
      "source": [
        "Learning Curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWHjVucMFsau"
      },
      "source": [
        "history_dict = history_turn1.history\n",
        "loss_values = history_dict['loss']\n",
        "val_loss_values = history_dict['val_loss']\n",
        "accuracy = history_dict['categorical_accuracy']\n",
        "val_accuracy = history_dict['val_categorical_accuracy']\n",
        " \n",
        "epochs = range(1, len(loss_values) + 1)\n",
        "fig, ax = plt.subplots(1, 2, figsize=(14, 6))\n",
        "#\n",
        "# Plot the model accuracy vs Epochs\n",
        "#\n",
        "ax[0].plot(epochs, accuracy, 'r', label='Training accuracy')\n",
        "ax[0].plot(epochs, val_accuracy, 'b', label='Validation accuracy')\n",
        "ax[0].set_title('Training & Validation Accuracy', fontsize=16)\n",
        "ax[0].set_xlabel('Epochs', fontsize=16)\n",
        "ax[0].set_ylabel('Accuracy', fontsize=16)\n",
        "ax[0].legend()\n",
        "#\n",
        "# Plot the loss vs Epochs\n",
        "#\n",
        "ax[1].plot(epochs, loss_values, 'r', label='Training loss')\n",
        "ax[1].plot(epochs, val_loss_values, 'b', label='Validation loss')\n",
        "ax[1].set_title('Training & Validation Loss', fontsize=16)\n",
        "ax[1].set_xlabel('Epochs', fontsize=16)\n",
        "ax[1].set_ylabel('Loss', fontsize=16)\n",
        "ax[1].legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uitKz9VAFsav"
      },
      "source": [
        "------------------------\n",
        "\n",
        "Reports"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuynk_FMFsav"
      },
      "source": [
        "Make Predicitions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twgvKhEdFsav"
      },
      "source": [
        "# For Confusion matrix & Classification Report \n",
        "\n",
        "y_preds = model_turn1.predict(X_test_scale)\n",
        "max_predictions = np.argmax(y_preds, axis=1)\n",
        "\n",
        "max_test = np.argmax(np.asarray(y_test_dum_turn1), axis=1)\n",
        "\n",
        "##################\n",
        "\n",
        "\n",
        "y_preds_train = model_turn1.predict(X_train_under_turn1_scale)\n",
        "\n",
        "max_predictions_train = np.argmax(y_preds_train, axis=1)\n",
        "max_train = np.argmax(np.asarray(y_train_under_dum_turn1), axis=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6zz9wi8Fsaw"
      },
      "source": [
        "# Metrics "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLWybQhyFsaw"
      },
      "source": [
        "Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_eJtE8nuFsax"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "print(\"Test Accuracy : \\t\\t\" ,accuracy_score(max_test, max_predictions))\n",
        "print(\"Test Balanced Accuracy : \\t\" , balanced_accuracy_score(max_test, max_predictions))\n",
        "print(\"Test F1 Score : \\t\\t\" , f1_score(max_test, max_predictions , average='weighted'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkA6_NxrFsax"
      },
      "source": [
        "Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pmy01UMrFsay"
      },
      "source": [
        "print(\"Train Accuracy : \\t\\t\" ,accuracy_score(max_train, max_predictions_train))\n",
        "print(\"Train Balanced Accuracy : \\t\" , balanced_accuracy_score(max_train, max_predictions_train))\n",
        "print(\"Train F1 Score : \\t\\t\" , f1_score(max_train, max_predictions_train, average='weighted'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwgxx5mzFsay"
      },
      "source": [
        "Imports "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4IYmYmNCFsay"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# set up labels \n",
        "LABELS = ['Not Turn 1', 'Turn 1']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOt7VOmkFsaz"
      },
      "source": [
        "# Test Set "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lqw7BaYwFsaz"
      },
      "source": [
        "print(classification_report(max_test, max_predictions , target_names=LABELS))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgdbNE2zFsaz"
      },
      "source": [
        "# Train Set "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBlcMiRpFsa0"
      },
      "source": [
        "print(classification_report(max_train, max_predictions_train , target_names=LABELS))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGSS4jegFsa0"
      },
      "source": [
        "--------------------\n",
        "\n",
        "# Confusion Matrix "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMzb_LsHFsa0"
      },
      "source": [
        "confusion_matrix = metrics.confusion_matrix(max_test, max_predictions  )\n",
        "\n",
        "confusion_matrix_t = metrics.confusion_matrix(max_train, max_predictions_train )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbOwYPeUFsa1"
      },
      "source": [
        "plt.figure(figsize=(14, 10))\n",
        "sns.heatmap(confusion_matrix, xticklabels=LABELS, yticklabels=LABELS,  annot=True, fmt=\"d\");\n",
        "plt.title(\"Test Data Confusion matrix\")\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPoN93qtFsa1"
      },
      "source": [
        "plt.figure(figsize=(14, 10))\n",
        "sns.heatmap(confusion_matrix_t, xticklabels=LABELS, yticklabels=LABELS, annot=True, fmt=\"d\");\n",
        "plt.title(\"Train Confusion matrix\")\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOSVHyDUFsa2"
      },
      "source": [
        "-------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58PH8YT0SxK1"
      },
      "source": [
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7630ampIAgk"
      },
      "source": [
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPAV2AesIAnt"
      },
      "source": [
        "------------------------------------------------------\n",
        "\n",
        "# Turn 2 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zftGL-kWIAnu"
      },
      "source": [
        "#n_timesteps, n_features, n_outputs = X_train.shape[1] , X_train.shape[2] , y_train_dum.shape[1]\n",
        "\n",
        "n_outputs =  y_train_under_dum_go.shape[1]\n",
        "\n",
        "# set up model\n",
        "model_turn2 = Sequential()\n",
        "\n",
        "#input layer\n",
        "model_turn2.add(Dense(100, activation='relu' , input_shape = (X_train_under_go_scale.shape[1], )))\n",
        "\n",
        "\n",
        "# hidden layers\n",
        "model_turn2.add(Dense(50, activation='relu'))\n",
        "model_turn2.add(Dropout(0.5))\n",
        "model_turn2.add(Dense(50, activation='relu'))\n",
        "# model.add(Dropout(0.5))\n",
        "# model.add(Dense(100, activation='relu'))\n",
        "\n",
        "# output layer\n",
        "model_turn2.add(Dense(n_outputs, activation='softmax'))\n",
        "\n",
        "# compile model\n",
        "model_turn2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[tf.keras.metrics.CategoricalAccuracy()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEVO7ZiwIAnv"
      },
      "source": [
        "Early Stopping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oizBQns1IAnv"
      },
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        " \t\n",
        "# patient early stopping\n",
        "#es = EarlyStopping(monitor='val_loss', mode='auto', verbose=1, patience=5 , min_delta=0.05)\n",
        "\n",
        "\n",
        "earlyStopping = EarlyStopping(monitor='val_loss', patience=5, verbose=0, mode='min')\n",
        "mcp_save = ModelCheckpoint('.base_model_wts.hdf5', save_best_only=True, monitor='val_loss', mode='min')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_8Blf82IAny"
      },
      "source": [
        "Fit "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IuVH29KIAnz"
      },
      "source": [
        "# just for timing model\n",
        "t0 = time.time()\n",
        "\n",
        "# fitting model \n",
        "history_turn2 = model_turn2.fit(X_train_under_turn2_scale, y_train_under_dum_turn2,\n",
        "                    validation_data=(X_test_scale, y_test_dum_turn2 ),\n",
        "                    epochs = 100,\n",
        "                    batch_size=200,\n",
        "                    callbacks=[earlyStopping, mcp_save]\n",
        "                    )\n",
        "\n",
        "\n",
        "t1 = time.time()\n",
        "\n",
        "total = t1-t0\n",
        "\n",
        "print(f'Time Taken: {total}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZnWsn1UIAn1"
      },
      "source": [
        "Learning Curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUqXsVnpIAn2"
      },
      "source": [
        "history_dict = history_turn2.history\n",
        "loss_values = history_dict['loss']\n",
        "val_loss_values = history_dict['val_loss']\n",
        "accuracy = history_dict['categorical_accuracy']\n",
        "val_accuracy = history_dict['val_categorical_accuracy']\n",
        " \n",
        "epochs = range(1, len(loss_values) + 1)\n",
        "fig, ax = plt.subplots(1, 2, figsize=(14, 6))\n",
        "#\n",
        "# Plot the model accuracy vs Epochs\n",
        "#\n",
        "ax[0].plot(epochs, accuracy, 'r', label='Training accuracy')\n",
        "ax[0].plot(epochs, val_accuracy, 'b', label='Validation accuracy')\n",
        "ax[0].set_title('Training & Validation Accuracy', fontsize=16)\n",
        "ax[0].set_xlabel('Epochs', fontsize=16)\n",
        "ax[0].set_ylabel('Accuracy', fontsize=16)\n",
        "ax[0].legend()\n",
        "#\n",
        "# Plot the loss vs Epochs\n",
        "#\n",
        "ax[1].plot(epochs, loss_values, 'r', label='Training loss')\n",
        "ax[1].plot(epochs, val_loss_values, 'b', label='Validation loss')\n",
        "ax[1].set_title('Training & Validation Loss', fontsize=16)\n",
        "ax[1].set_xlabel('Epochs', fontsize=16)\n",
        "ax[1].set_ylabel('Loss', fontsize=16)\n",
        "ax[1].legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzqYJO-dIAn2"
      },
      "source": [
        "------------------------\n",
        "\n",
        "Reports"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Olo3i8mmIAn3"
      },
      "source": [
        "Make Predicitions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGxwuliFIAn4"
      },
      "source": [
        "# For Confusion matrix & Classification Report \n",
        "\n",
        "y_preds = model_turn2.predict(X_test_scale)\n",
        "max_predictions = np.argmax(y_preds, axis=1)\n",
        "\n",
        "max_test = np.argmax(np.asarray(y_test_dum_turn2), axis=1)\n",
        "\n",
        "##################\n",
        "\n",
        "\n",
        "y_preds_train = model_turn2.predict(X_train_under_turn2_scale)\n",
        "\n",
        "max_predictions_train = np.argmax(y_preds_train, axis=1)\n",
        "max_train = np.argmax(np.asarray(y_train_under_dum_turn2), axis=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_rTuI1EIAn5"
      },
      "source": [
        "# Metrics "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_18fXgAIAn6"
      },
      "source": [
        "Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKrX193vIAn6"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "print(\"Test Accuracy : \\t\\t\" ,accuracy_score(max_test, max_predictions))\n",
        "print(\"Test Balanced Accuracy : \\t\" , balanced_accuracy_score(max_test, max_predictions))\n",
        "print(\"Test F1 Score : \\t\\t\" , f1_score(max_test, max_predictions , average='weighted'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BJXWDQEIAn6"
      },
      "source": [
        "Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ru_qENQmIAn7"
      },
      "source": [
        "print(\"Train Accuracy : \\t\\t\" ,accuracy_score(max_train, max_predictions_train))\n",
        "print(\"Train Balanced Accuracy : \\t\" , balanced_accuracy_score(max_train, max_predictions_train))\n",
        "print(\"Train F1 Score : \\t\\t\" , f1_score(max_train, max_predictions_train, average='weighted'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Lp7A59nIAn7"
      },
      "source": [
        "Imports "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzExB_ivIAn8"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# set up labels \n",
        "LABELS = ['Not Turn 2', 'Turn 2']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZagFjIFIAn8"
      },
      "source": [
        "# Test Set "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQu-vkkPIAn9"
      },
      "source": [
        "print(classification_report(max_test, max_predictions , target_names=LABELS))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqZfri0pIAn-"
      },
      "source": [
        "# Train Set "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgF8fapmIAn_"
      },
      "source": [
        "print(classification_report(max_train, max_predictions_train , target_names=LABELS))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GhmKN9ctIAn_"
      },
      "source": [
        "--------------------\n",
        "\n",
        "# Confusion Matrix "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qaqlU8HFIAoA"
      },
      "source": [
        "confusion_matrix = metrics.confusion_matrix(max_test, max_predictions  )\n",
        "\n",
        "confusion_matrix_t = metrics.confusion_matrix(max_train, max_predictions_train )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytmcY4stIAoA"
      },
      "source": [
        "plt.figure(figsize=(14, 10))\n",
        "sns.heatmap(confusion_matrix, xticklabels=LABELS, yticklabels=LABELS,  annot=True, fmt=\"d\");\n",
        "plt.title(\"Test Data Confusion matrix\")\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCmFr6OFIAoB"
      },
      "source": [
        "plt.figure(figsize=(14, 10))\n",
        "sns.heatmap(confusion_matrix_t, xticklabels=LABELS, yticklabels=LABELS, annot=True, fmt=\"d\");\n",
        "plt.title(\"Train Confusion matrix\")\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rYcS-EeIAoC"
      },
      "source": [
        "-------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbcJJltTIj71"
      },
      "source": [
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "js32krSvIj71"
      },
      "source": [
        "------------------------------------------------------\n",
        "\n",
        "# Sit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJLKDl1ZIj72"
      },
      "source": [
        "#n_timesteps, n_features, n_outputs = X_train.shape[1] , X_train.shape[2] , y_train_dum.shape[1]\n",
        "\n",
        "n_outputs =  y_train_under_dum_go.shape[1]\n",
        "\n",
        "# set up model\n",
        "model_sit = Sequential()\n",
        "\n",
        "#input layer\n",
        "model_sit.add(Dense(100, activation='relu' , input_shape = (X_train_under_go_scale.shape[1], )))\n",
        "\n",
        "\n",
        "# hidden layers\n",
        "model_sit.add(Dense(50, activation='relu'))\n",
        "model_sit.add(Dropout(0.5))\n",
        "model_sit.add(Dense(50, activation='relu'))\n",
        "# model.add(Dropout(0.5))\n",
        "# model.add(Dense(100, activation='relu'))\n",
        "\n",
        "# output layer\n",
        "model_sit.add(Dense(n_outputs, activation='softmax'))\n",
        "\n",
        "# compile model\n",
        "model_sit.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[tf.keras.metrics.CategoricalAccuracy()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59VfGnj3Ij72"
      },
      "source": [
        "Early Stopping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "415B9ndZIj73"
      },
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        " \t\n",
        "# patient early stopping\n",
        "#es = EarlyStopping(monitor='val_loss', mode='auto', verbose=1, patience=5 , min_delta=0.05)\n",
        "\n",
        "\n",
        "earlyStopping = EarlyStopping(monitor='val_loss', patience=5, verbose=0, mode='min')\n",
        "mcp_save = ModelCheckpoint('.base_model_wts.hdf5', save_best_only=True, monitor='val_loss', mode='min')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYMahGLjIj73"
      },
      "source": [
        "Fit "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e72X8cOfIj73"
      },
      "source": [
        "# just for timing model\n",
        "t0 = time.time()\n",
        "\n",
        "# fitting model \n",
        "history_sit = model_sit.fit(X_train_under_sit_scale, y_train_under_dum_sit,\n",
        "                    validation_data=(X_test_scale, y_test_dum_sit),\n",
        "                    epochs = 100,\n",
        "                    batch_size=200,\n",
        "                    callbacks=[earlyStopping, mcp_save]\n",
        "                    )\n",
        "\n",
        "\n",
        "t1 = time.time()\n",
        "\n",
        "total = t1-t0\n",
        "\n",
        "print(f'Time Taken: {total}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWjCG5QRIj73"
      },
      "source": [
        "Learning Curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8C_dYr1Ij74"
      },
      "source": [
        "history_dict = history_sit.history\n",
        "loss_values = history_dict['loss']\n",
        "val_loss_values = history_dict['val_loss']\n",
        "accuracy = history_dict['categorical_accuracy']\n",
        "val_accuracy = history_dict['val_categorical_accuracy']\n",
        " \n",
        "epochs = range(1, len(loss_values) + 1)\n",
        "fig, ax = plt.subplots(1, 2, figsize=(14, 6))\n",
        "#\n",
        "# Plot the model accuracy vs Epochs\n",
        "#\n",
        "ax[0].plot(epochs, accuracy, 'r', label='Training accuracy')\n",
        "ax[0].plot(epochs, val_accuracy, 'b', label='Validation accuracy')\n",
        "ax[0].set_title('Training & Validation Accuracy', fontsize=16)\n",
        "ax[0].set_xlabel('Epochs', fontsize=16)\n",
        "ax[0].set_ylabel('Accuracy', fontsize=16)\n",
        "ax[0].legend()\n",
        "#\n",
        "# Plot the loss vs Epochs\n",
        "#\n",
        "ax[1].plot(epochs, loss_values, 'r', label='Training loss')\n",
        "ax[1].plot(epochs, val_loss_values, 'b', label='Validation loss')\n",
        "ax[1].set_title('Training & Validation Loss', fontsize=16)\n",
        "ax[1].set_xlabel('Epochs', fontsize=16)\n",
        "ax[1].set_ylabel('Loss', fontsize=16)\n",
        "ax[1].legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwxAT_cnIj74"
      },
      "source": [
        "------------------------\n",
        "\n",
        "Reports"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ADEOZLMIj75"
      },
      "source": [
        "Make Predicitions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7j7WOseIj75"
      },
      "source": [
        "# For Confusion matrix & Classification Report \n",
        "\n",
        "y_preds = model_sit.predict(X_test_scale)\n",
        "max_predictions = np.argmax(y_preds, axis=1)\n",
        "\n",
        "max_test = np.argmax(np.asarray(y_test_dum_sit), axis=1)\n",
        "\n",
        "##################\n",
        "\n",
        "\n",
        "y_preds_train = model_sit.predict(X_train_under_sit_scale)\n",
        "\n",
        "max_predictions_train = np.argmax(y_preds_train, axis=1)\n",
        "max_train = np.argmax(np.asarray(y_train_under_dum_sit), axis=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnHnes4vIj75"
      },
      "source": [
        "# Metrics "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kb7UtTBPIj76"
      },
      "source": [
        "Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zX_bnklhIj76"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "print(\"Test Accuracy : \\t\\t\" ,accuracy_score(max_test, max_predictions))\n",
        "print(\"Test Balanced Accuracy : \\t\" , balanced_accuracy_score(max_test, max_predictions))\n",
        "print(\"Test F1 Score : \\t\\t\" , f1_score(max_test, max_predictions , average='weighted'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqVsQ4rBIj78"
      },
      "source": [
        "Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ph4eF6ZWIj78"
      },
      "source": [
        "print(\"Train Accuracy : \\t\\t\" ,accuracy_score(max_train, max_predictions_train))\n",
        "print(\"Train Balanced Accuracy : \\t\" , balanced_accuracy_score(max_train, max_predictions_train))\n",
        "print(\"Train F1 Score : \\t\\t\" , f1_score(max_train, max_predictions_train, average='weighted'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2qyNucOIj78"
      },
      "source": [
        "Imports "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGq9eQUZIj78"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# set up labels \n",
        "LABELS = ['Not Sit', 'Sit']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjeuJ207Ij79"
      },
      "source": [
        "# Test Set "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhC09jUtIj79"
      },
      "source": [
        "print(classification_report(max_test, max_predictions , target_names=LABELS))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hL6IDYgIj79"
      },
      "source": [
        "# Train Set "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fer2p7cbIj7-"
      },
      "source": [
        "print(classification_report(max_train, max_predictions_train , target_names=LABELS))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjZvRRpbIj7-"
      },
      "source": [
        "--------------------\n",
        "\n",
        "# Confusion Matrix "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0TN32ZGIj7-"
      },
      "source": [
        "confusion_matrix = metrics.confusion_matrix(max_test, max_predictions  )\n",
        "\n",
        "confusion_matrix_t = metrics.confusion_matrix(max_train, max_predictions_train )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJZG35w1Ij7-"
      },
      "source": [
        "plt.figure(figsize=(14, 10))\n",
        "sns.heatmap(confusion_matrix, xticklabels=LABELS, yticklabels=LABELS,  annot=True, fmt=\"d\");\n",
        "plt.title(\"Test Data Confusion matrix\")\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYj7ZtToIj7-"
      },
      "source": [
        "plt.figure(figsize=(14, 10))\n",
        "sns.heatmap(confusion_matrix_t, xticklabels=LABELS, yticklabels=LABELS, annot=True, fmt=\"d\");\n",
        "plt.title(\"Train Confusion matrix\")\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqdX7U_ZIj7-"
      },
      "source": [
        "-------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7KHWXMPNiD7"
      },
      "source": [
        "# upload one dataframe to test logic of model \n",
        "\n",
        "# from google.colab import files\n",
        "# uploaded_dataframe_test = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jtPfxxYN1fc"
      },
      "source": [
        "test_df = pd.read_csv('29_9_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RCP')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3kn2wxFODEQ"
      },
      "source": [
        "# Getting X_train & y_train\n",
        "X_data = test_df.drop(['Unnamed: 0' , 'Label_segment' , 'Participant_ID' , 'Participant_Run','X_Acc_Move_FFT_EnergyBands', \t'Y_Acc_Move_FFT_EnergyBands', \t'Z_Acc_Move_FFT_EnergyBands' ], axis = 1)\n",
        "#X_data = signal_test.drop(['Unnamed: 0' , 'Label_segment' , 'Participant_ID' , 'Participant_Run' ], axis = 1)\n",
        "\n",
        "y_data = test_df['Label_segment'].values\n",
        "\n",
        "# scale with already fit ss \n",
        "X_data_scale = ss.transform(X_data)\n",
        "\n",
        "# convert to dummy category\n",
        "y_data_dum = pd.get_dummies(y_data)\n",
        "\n",
        "# Take max of dummy classifier\n",
        "y_data = np.argmax(np.asarray(y_data_dum), axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1IoaQKBVOalb"
      },
      "source": [
        "# Go \n",
        "go_model_preds = model.predict(X_data_scale)\n",
        "\n",
        "# Walk 1\n",
        "walk1_model_preds = model_walk1.predict(X_data_scale)\n",
        "\n",
        "# Turn 1 \n",
        "turn1_model_preds = model_turn1.predict(X_data_scale)\n",
        "\n",
        "# Walk 2 \n",
        "walk2_model_preds = model_walk2.predict(X_data_scale)\n",
        "\n",
        "# Turn 2 \n",
        "turn2_model_preds = model_turn2.predict(X_data_scale)\n",
        "\n",
        "# Sit\n",
        "sit_model_preds = model_sit.predict(X_data_scale)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5MDQy8TA-pI"
      },
      "source": [
        "------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "woUnPpP1k180"
      },
      "source": [
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4L2GqWFzk2zS"
      },
      "source": [
        "<br>"
      ]
    }
  ]
}