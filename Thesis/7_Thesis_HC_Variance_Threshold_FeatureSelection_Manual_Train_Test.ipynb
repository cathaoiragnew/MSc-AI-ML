{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "7_Variance_Threshold_FeatureSelection_Manual_Train_Test_HandCraft_Thesis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrVWaVNkPW2k"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtX5iMQHPDII"
      },
      "source": [
        "\n",
        "########################### (https://github.com/curiousily/TensorFlow-on-Android-for-Human-Activity-Recognition-with-LSTMs/blob/master/human_activity_recognition.ipynb) imports\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from collections import Counter\n",
        "from scipy import stats\n",
        "import tensorflow as tf\n",
        "import seaborn as sns\n",
        "from pylab import rcParams\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "%matplotlib inline\n",
        "sns.set(style='whitegrid', palette='muted', font_scale=1.5)\n",
        "rcParams['figure.figsize'] = 14, 8\n",
        "RANDOM_SEED = 42\n",
        "\n",
        "#!pip install imbalanced-learn\n",
        "\n",
        "#from imblearn.over_sampling import SMOTE\n",
        "from collections import Counter\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "from matplotlib.pyplot import figure\n",
        "\n",
        "from sklearn.metrics import accuracy_score, log_loss\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.linear_model import PassiveAggressiveClassifier\n",
        "from sklearn.semi_supervised import LabelPropagation\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.tree import ExtraTreeClassifier\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_M5F5DwPrKk"
      },
      "source": [
        "# Upload Data \n",
        "\n",
        "---------------------------------\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZX9OGsWPzvD"
      },
      "source": [
        "Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IyDYp-eLY8K"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded_signal_train = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "juXPVt1AP0v1"
      },
      "source": [
        "Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDlYInx_Pyx5"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded_signal_test = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFIL8q5nvqUf"
      },
      "source": [
        "### Reading in segments & labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y70o5U5mSOUU"
      },
      "source": [
        "Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxXU40eBttE6"
      },
      "source": [
        "# getting keys, which is file names of npy \n",
        "list_of_dataframes_train = [key for key in uploaded_signal_train.keys()]\n",
        "\n",
        "\n",
        "# set up list to hold all loaded npy \n",
        "all_dataframe_train = [] \n",
        "\n",
        "\n",
        "for i in range(len(list_of_dataframes_train)):\n",
        "\n",
        "    # load in the data \n",
        "    dataframe_train = pd.read_csv(list_of_dataframes_train[i])\n",
        "\n",
        "\n",
        "    # append the data to 'all' list\n",
        "    all_dataframe_train.append(dataframe_train) \n",
        "\n",
        "\n",
        "all_df_train = pd.concat(all_dataframe_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXzYX7vVSPqK"
      },
      "source": [
        "Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4s9Wo8YGSQeN"
      },
      "source": [
        "# getting keys, which is file names of npy \n",
        "list_of_dataframes_test = [key for key in uploaded_signal_test.keys()]\n",
        "\n",
        "\n",
        "# set up list to hold all loaded npy \n",
        "all_dataframe_test = [] \n",
        "\n",
        "\n",
        "for i in range(len(list_of_dataframes_test)):\n",
        "\n",
        "    # load in the data \n",
        "    dataframe_test = pd.read_csv(list_of_dataframes_test[i])\n",
        "\n",
        "\n",
        "    # append the data to 'all' list\n",
        "    all_dataframe_test.append(dataframe_test) \n",
        "\n",
        "\n",
        "all_df_test = pd.concat(all_dataframe_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8jsSnExgGesF"
      },
      "source": [
        "# Quick Look "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCEZ0lTrGiz3"
      },
      "source": [
        "all_df_train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJ-KTwnDGhYv"
      },
      "source": [
        "all_df_test.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVPv0iQ6SPeH"
      },
      "source": [
        "# Train Test Split "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlyxtKg4SRMP"
      },
      "source": [
        "# Getting X_train & y_train'\n",
        "X_train = all_df_train.drop(['Unnamed: 0' , 'Label_segment' , 'Participant_ID' , 'Participant_Run', 'X_Acc_Move_FFT_EnergyBands', \t'Y_Acc_Move_FFT_EnergyBands', \t'Z_Acc_Move_FFT_EnergyBands'\t], axis = 1)\n",
        "y_train = all_df_train['Label_segment'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyOL-dTlTDbw"
      },
      "source": [
        "# Getting X_train & y_train\n",
        "X_test = all_df_test.drop(['Unnamed: 0' , 'Label_segment' , 'Participant_ID' , 'Participant_Run',  'X_Acc_Move_FFT_EnergyBands', \t'Y_Acc_Move_FFT_EnergyBands', \t'Z_Acc_Move_FFT_EnergyBands'], axis = 1)\n",
        "y_test = all_df_test['Label_segment'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vM6doFdbvla"
      },
      "source": [
        "---------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8tbgLDdClvm"
      },
      "source": [
        "Standard Scaler "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_kiRoz9Ckxu"
      },
      "source": [
        "ss = StandardScaler()\n",
        "\n",
        "# fit to training \n",
        "X_train_scale = ss.fit_transform(X_train)\n",
        "\n",
        "# transform testing \n",
        "X_test_scale = ss.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tVnwD0csNgw"
      },
      "source": [
        "Min/Max Scale On Original Data - This is for getting variance cut off idea"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3a2IPrKzBjOm"
      },
      "source": [
        "from sklearn.feature_selection import VarianceThreshold\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "\n",
        "minmax_scaler = MinMaxScaler()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFhyhbcjsO7K"
      },
      "source": [
        "# fit data\n",
        "X_train_mm_scale = minmax_scaler.fit_transform(X_train)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mc3SDYK1CDw7"
      },
      "source": [
        "# calculating variances & plotting it. Picked .015 just as it cuts off 3 lowest variances  \n",
        "var_features = np.var(X_train_mm_scale, axis=0)\n",
        "\n",
        "plt.plot(var_features , marker='o' , label='variance')\n",
        "plt.hlines(0.010, xmin = 0, xmax = 90, colors='r', linestyles='--', label='cutoff')\n",
        "\n",
        "plt.title(\"Feature Variance Plot\")\n",
        "plt.xlabel(\"Features\")\n",
        "plt.ylabel(\"Variance\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzBp-AizCcMx"
      },
      "source": [
        "from sklearn.feature_selection import VarianceThreshold\n",
        "\n",
        "selector = VarianceThreshold(threshold=0.010)\n",
        "\n",
        "selector_fitted = selector.fit(X_train_mm_scale)\n",
        "\n",
        "print(selector_fitted)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjYSNFTMCgrP"
      },
      "source": [
        "# using the fitted variance threshold selector\n",
        "\n",
        "X_train_scale_thresh = selector_fitted.transform(X_train_scale)\n",
        "X_test_scale_thresh = selector_fitted.transform(X_test_scale)\n",
        "\n",
        "\n",
        "# quick check to make sure it worked, should have 13 features\n",
        "# quick print of shapes to see difference\n",
        "print(f'Train data:\\nBefore feature reduction shape: {X_train_scale.shape} , after feature reduction applied: {X_train_scale_thresh.shape} ')\n",
        "print(f'\\nTest data:\\nBefore feature reduction shape: {X_test_scale.shape} , after feature reduction applied: {X_test_scale_thresh.shape} ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZSss6u0jQN_"
      },
      "source": [
        "----------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2uPaSPhEYGr"
      },
      "source": [
        "\n",
        "import time\n",
        "from sklearn.metrics import accuracy_score, log_loss , recall_score , f1_score, precision_score , roc_auc_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.linear_model import PassiveAggressiveClassifier , LogisticRegression\n",
        "from sklearn.semi_supervised import LabelPropagation\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.tree import ExtraTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "classifiers = [\n",
        "               \n",
        "    # Too much computation to run now since using entire data and not segmenting on location \n",
        "    ##KNeighborsClassifier(),\n",
        "    ##GradientBoostingClassifier(),\n",
        "    ##LabelPropagation(),\n",
        "    # DecisionTreeClassifier(),\n",
        "    # RandomForestClassifier(),\n",
        "    # AdaBoostClassifier(),\n",
        "    # GaussianNB(),\n",
        "    # LinearDiscriminantAnalysis(),\n",
        "    # QuadraticDiscriminantAnalysis(),\n",
        "    # LinearSVC(),\n",
        "    # SGDClassifier(),\n",
        "    # MLPClassifier(),\n",
        "    # PassiveAggressiveClassifier(),\n",
        "    # ExtraTreesClassifier(),\n",
        "    # BaggingClassifier(),\n",
        "\n",
        "    DecisionTreeClassifier(criterion = 'entropy' , max_depth = 10 , min_samples_leaf = 8 , min_samples_split = 3  ),\n",
        "    MLPClassifier(hidden_layer_sizes = (200, 50 , 100) , activation = 'tanh' , solver = 'sgd' , alpha = 0.00001 , learning_rate = 'adaptive' ),\n",
        "    LogisticRegression(C = 1 , multi_class = 'multinomial' , penalty = 'l2' , solver = 'newton-cg' )\n",
        "\n",
        "\n",
        "  \n",
        "    \n",
        "     ]\n",
        "\n",
        "\n",
        "# list to hold for dataframe\n",
        "classifier_name_list = []\n",
        "train_acc_list = []\n",
        "train_bacc_list = []\n",
        "test_acc_list = []\n",
        "test_bacc_list = []\n",
        "train_recall_list = []\n",
        "test_recall_list = []\n",
        "train_precision_list = []\n",
        "test_precision_list = []\n",
        "train_f1_list = []\n",
        "test_f1_list = []\n",
        "training_timing = [] \n",
        "training_pred_timing = [] \n",
        "testing_pred_timing = [] \n",
        "\n",
        "\n",
        "for clf in classifiers:\n",
        "\n",
        "    name = clf.__class__.__name__\n",
        "    \n",
        "    print(\"=\"*50)\n",
        "    print(name)\n",
        "\n",
        "    # just for timing model\n",
        "    training_time0 = time.time()\n",
        "\n",
        "\n",
        "    ################### This changes across runs ####################################################\n",
        "    clf.fit(X_train_scale_thresh, y_train)\n",
        "\n",
        "    # finished training \n",
        "    training_time1 = time.time()\n",
        "\n",
        "    training_time = training_time1 - training_time0 \n",
        "    \n",
        "    print('****Results****')\n",
        "\n",
        "    # just for timing model\n",
        "    test_time0 = time.time()\n",
        "    # Test Predictions\n",
        "\n",
        "    ################### This changes across runs ####################################################\n",
        "    test_predictions = clf.predict(X_test_scale_thresh)\n",
        "    # just for timing model\n",
        "    test_time1 = time.time()\n",
        "\n",
        "    test_time = test_time1 - test_time0\n",
        "\n",
        "\n",
        "    # Test Metrics\n",
        "    acc            = accuracy_score(y_test, test_predictions)\n",
        "    bal_acc        = balanced_accuracy_score(y_test, test_predictions)\n",
        "    recall_test    = recall_score(y_test, test_predictions, average = 'weighted')\n",
        "    f1_test        = f1_score(y_test, test_predictions ,  average = 'weighted')\n",
        "    precision_test = precision_score(y_test, test_predictions,  average = 'weighted') \n",
        "\n",
        "\n",
        "    # just for timing model\n",
        "    training_p_time0 = time.time()\n",
        "\n",
        "    # Train Predictions\n",
        "\n",
        "    ################### This changes across runs ####################################################\n",
        "    train_predictions = clf.predict(X_train_scale_thresh)\n",
        "\n",
        "    # just for timing model\n",
        "    training_p_time1 = time.time()\n",
        "\n",
        "    training_p_time = training_p_time1 - training_p_time0\n",
        "\n",
        "    # Train Metrics\n",
        "\n",
        "    ################### This changes across runs ####################################################\n",
        "    train_acc       = accuracy_score(y_train, train_predictions)\n",
        "    train_bal_acc   = balanced_accuracy_score(y_train, train_predictions)\n",
        "    recall_train    = recall_score(y_train, train_predictions , average = 'weighted')\n",
        "    f1_train        = f1_score(y_train, train_predictions ,  average = 'weighted')\n",
        "    precision_train = precision_score(y_train, train_predictions,  average = 'weighted') \n",
        "\n",
        "    print(\"\\n\\nTest Classification Report\\n\")\n",
        "    print(classification_report(y_test, test_predictions))\n",
        "\n",
        "\n",
        "    # append to list to make a dataframe \n",
        "    classifier_name_list.append(name)\n",
        "    \n",
        "    training_timing.append(training_time)\n",
        "    training_pred_timing.append(training_p_time)\n",
        "    testing_pred_timing.append(test_time)\n",
        "\n",
        "\n",
        "    train_acc_list.append(train_acc)\n",
        "    test_acc_list.append(acc)\n",
        "\n",
        "    train_bacc_list.append(train_bal_acc)\n",
        "    test_bacc_list.append(bal_acc)\n",
        "\n",
        "    train_recall_list.append(recall_train)\n",
        "    test_recall_list.append(recall_test)\n",
        "\n",
        "    train_precision_list.append(precision_train)\n",
        "    test_precision_list.append(precision_test)\n",
        "\n",
        "    train_f1_list.append(f1_train)\n",
        "    test_f1_list.append(f1_test)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"=\"*50)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQpvWdBPXCAE"
      },
      "source": [
        "train_metrics_df = pd.DataFrame()\n",
        "test_metrics_df = pd.DataFrame()\n",
        "\n",
        "\n",
        "train_metrics_df['Classifier'] = classifier_name_list\n",
        "test_metrics_df['Classifier'] = classifier_name_list\n",
        "\n",
        "\n",
        "# F1 Score First \n",
        "train_metrics_df['Train F1'] = train_f1_list\n",
        "test_metrics_df['Test F1'] = test_f1_list \n",
        "\n",
        "# Recall\n",
        "train_metrics_df['Train Recall'] = train_recall_list\n",
        "test_metrics_df['Test Recall'] = test_recall_list\n",
        "\n",
        "# Precision \n",
        "train_metrics_df['Train Precision'] = train_precision_list\n",
        "test_metrics_df['Test Precision'] = test_precision_list\n",
        "\n",
        "# Bal Acc\n",
        "train_metrics_df['Train Balanced Accuracy'] = train_bacc_list\n",
        "test_metrics_df['Test Balanced Accuracy'] = test_bacc_list\n",
        "\n",
        "# Accuracy \n",
        "train_metrics_df['Train Accuracy'] = train_acc_list\n",
        "test_metrics_df['Test Accuracy'] = test_acc_list \n",
        "\n",
        "\n",
        "#train_metrics_df.sort_values(\"Train F1\" , ascending=False , inplace=True)\n",
        "train_metrics_df.set_index('Classifier' , inplace=True)\n",
        "\n",
        "#test_metrics_df.sort_values(\"Test F1\" , ascending=False , inplace=True)\n",
        "test_metrics_df.set_index('Classifier' , inplace=True)\n",
        "\n",
        "train_metrics_df['Model Training Taken (seconds)']  = training_timing\n",
        "test_metrics_df['Model Training Taken (seconds)']  = training_timing\n",
        "\n",
        "train_metrics_df['Model Prediction Time Taken (seconds)']  = training_pred_timing\n",
        "test_metrics_df['Model Prediction Time Taken (seconds)']  = testing_pred_timing\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# display df\n",
        "display(train_metrics_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQXyo-j2FU1n"
      },
      "source": [
        "# display df\n",
        "display(test_metrics_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tegic1vTEt6t"
      },
      "source": [
        "------------------------------\n",
        "\n",
        "# Below is using SelectKBest for feature reduction from sklearn "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EiIxYJSpEz1s"
      },
      "source": [
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import f_classif\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQju7rg-Eur7"
      },
      "source": [
        "# Set up of lists\n",
        "list_of_bal = []\n",
        "list_of_recall = []\n",
        "list_of_precision = []\n",
        "list_of_f1 = []\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# using range(1, X_train_scale.shape[1]+1)\n",
        "\n",
        "for k in range(1, X_train_scale.shape[1]+1 , 5):\n",
        "\n",
        "    print(k)\n",
        "    \n",
        "    # initialize selector\n",
        "    sel = SelectKBest(f_classif, k = k )\n",
        "    \n",
        "    # fit to and transform train & test data\n",
        "    X_train_scale_sel = sel.fit_transform(X_train_scale , y_train)\n",
        "    X_test_scale_sel = sel.transform(X_test_scale)\n",
        "    \n",
        "    # initalize MLP\n",
        "    mlp_clf = MLPClassifier()\n",
        "    \n",
        "    # fit to train data \n",
        "    mlp_clf.fit(X_train_scale_sel , y_train)\n",
        "    \n",
        "    # predict on test data\n",
        "    y_pred= mlp_clf.predict(X_test_scale_sel)\n",
        "    \n",
        "    \n",
        "    # calculating bal acc\n",
        "    bal_acc = balanced_accuracy_score(y_test, y_pred)\n",
        "    recall_     = recall_score(y_test, y_pred , average = 'weighted')\n",
        "    f1_         = f1_score(y_test, y_pred ,  average = 'weighted')\n",
        "    precision_  = precision_score(y_test, y_pred,  average = 'weighted') \n",
        "\n",
        "    \n",
        "    # append score for this run\n",
        "    list_of_bal.append(bal_acc)\n",
        "    list_of_recall.append(recall_)\n",
        "    list_of_precision.append(f1_)\n",
        "    list_of_f1.append(precision_)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIcIUM1kgGBv"
      },
      "source": [
        "fig, axs = plt.subplots(2, 2 , sharex='col', sharey='row' , figsize=(10,10))\n",
        "\n",
        "fig.suptitle('Test Data Metrics')\n",
        "\n",
        "# No of features\n",
        "x = np.arange(1, X_train_scale.shape[1]+1 , 5)\n",
        "\n",
        "\n",
        "axs[0, 0].plot(x, list_of_bal)\n",
        "axs[0, 0].set_title('Balanced Accuracy')\n",
        "\n",
        "axs[0, 1].plot(x, list_of_recall, 'tab:orange')\n",
        "axs[0, 1].set_title('Recall')\n",
        "\n",
        "\n",
        "axs[1, 0].plot(x, list_of_f1, 'tab:green')\n",
        "axs[1, 0].set_title('F1 Score')\n",
        "\n",
        "\n",
        "axs[1, 1].plot(x, list_of_precision, 'tab:red')\n",
        "axs[1, 1].set_title('Precision')\n",
        "\n",
        "for ax in axs.flat:\n",
        "    ax.set(xlabel='Number of Features')\n",
        "\n",
        "# Hide x labels and tick labels for top plots and y ticks for right plots.\n",
        "for ax in axs.flat:\n",
        "    ax.label_outer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYzKL11IA-ah"
      },
      "source": [
        "---------------------------------\n",
        "\n",
        "Check all models for 65 features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-W8bDrBBDDB"
      },
      "source": [
        "# initialize selector\n",
        "sel = SelectKBest(f_classif, k = 65 )\n",
        "\n",
        "\n",
        "# fit to and transform train & test data\n",
        "X_train_scale_sel_65 = sel.fit_transform(X_train_scale , y_train)\n",
        "X_test_scale_sel_65 = sel.transform(X_test_scale)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QKskjhLA-wK"
      },
      "source": [
        "\n",
        "import time\n",
        "from sklearn.metrics import accuracy_score, log_loss , recall_score , f1_score, precision_score , roc_auc_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.linear_model import PassiveAggressiveClassifier , LogisticRegression\n",
        "from sklearn.semi_supervised import LabelPropagation\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.tree import ExtraTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "classifiers = [\n",
        "               \n",
        "    # Too much computation to run now since using entire data and not segmenting on location \n",
        "    ##KNeighborsClassifier(),\n",
        "    ##GradientBoostingClassifier(),\n",
        "    ##LabelPropagation(),\n",
        "    # DecisionTreeClassifier(),\n",
        "    # RandomForestClassifier(),\n",
        "    # AdaBoostClassifier(),\n",
        "    # GaussianNB(),\n",
        "    # LinearDiscriminantAnalysis(),\n",
        "    # QuadraticDiscriminantAnalysis(),\n",
        "    # LinearSVC(),\n",
        "    # SGDClassifier(),\n",
        "    # MLPClassifier(),\n",
        "    # PassiveAggressiveClassifier(),\n",
        "    # ExtraTreesClassifier(),\n",
        "    # BaggingClassifier(),\n",
        "\n",
        "    DecisionTreeClassifier(criterion = 'entropy' , max_depth = 10 , min_samples_leaf = 8 , min_samples_split = 3  ),\n",
        "    MLPClassifier(hidden_layer_sizes = (200, 50 , 100) , activation = 'tanh' , solver = 'sgd' , alpha = 0.00001 , learning_rate = 'adaptive' ),\n",
        "    LogisticRegression(C = 1 , multi_class = 'multinomial' , penalty = 'l2' , solver = 'newton-cg' )\n",
        "\n",
        "\n",
        "  \n",
        "    \n",
        "     ]\n",
        "\n",
        "\n",
        "# list to hold for dataframe\n",
        "classifier_name_list = []\n",
        "train_acc_list = []\n",
        "train_bacc_list = []\n",
        "test_acc_list = []\n",
        "test_bacc_list = []\n",
        "train_recall_list = []\n",
        "test_recall_list = []\n",
        "train_precision_list = []\n",
        "test_precision_list = []\n",
        "train_f1_list = []\n",
        "test_f1_list = []\n",
        "training_timing = [] \n",
        "training_pred_timing = [] \n",
        "testing_pred_timing = [] \n",
        "\n",
        "\n",
        "for clf in classifiers:\n",
        "\n",
        "    name = clf.__class__.__name__\n",
        "    \n",
        "    print(\"=\"*50)\n",
        "    print(name)\n",
        "\n",
        "    # just for timing model\n",
        "    training_time0 = time.time()\n",
        "\n",
        "\n",
        "    ################### This changes across runs ####################################################\n",
        "    clf.fit(X_train_scale_sel_65, y_train)\n",
        "\n",
        "    # finished training \n",
        "    training_time1 = time.time()\n",
        "\n",
        "    training_time = training_time1 - training_time0 \n",
        "    \n",
        "    print('****Results****')\n",
        "\n",
        "    # just for timing model\n",
        "    test_time0 = time.time()\n",
        "    # Test Predictions\n",
        "\n",
        "    ################### This changes across runs ####################################################\n",
        "    test_predictions = clf.predict(X_test_scale_sel_65)\n",
        "    # just for timing model\n",
        "    test_time1 = time.time()\n",
        "\n",
        "    test_time = test_time1 - test_time0\n",
        "\n",
        "\n",
        "    # Test Metrics\n",
        "    acc            = accuracy_score(y_test, test_predictions)\n",
        "    bal_acc        = balanced_accuracy_score(y_test, test_predictions)\n",
        "    recall_test    = recall_score(y_test, test_predictions, average = 'weighted')\n",
        "    f1_test        = f1_score(y_test, test_predictions ,  average = 'weighted')\n",
        "    precision_test = precision_score(y_test, test_predictions,  average = 'weighted') \n",
        "\n",
        "\n",
        "    # just for timing model\n",
        "    training_p_time0 = time.time()\n",
        "\n",
        "    # Train Predictions\n",
        "\n",
        "    ################### This changes across runs ####################################################\n",
        "    train_predictions = clf.predict(X_train_scale_sel_65)\n",
        "\n",
        "    # just for timing model\n",
        "    training_p_time1 = time.time()\n",
        "\n",
        "    training_p_time = training_p_time1 - training_p_time0\n",
        "\n",
        "    # Train Metrics\n",
        "\n",
        "    ################### This changes across runs ####################################################\n",
        "    train_acc       = accuracy_score(y_train, train_predictions)\n",
        "    train_bal_acc   = balanced_accuracy_score(y_train, train_predictions)\n",
        "    recall_train    = recall_score(y_train, train_predictions , average = 'weighted')\n",
        "    f1_train        = f1_score(y_train, train_predictions ,  average = 'weighted')\n",
        "    precision_train = precision_score(y_train, train_predictions,  average = 'weighted') \n",
        "\n",
        "    print(\"\\n\\nTest Classification Report\\n\")\n",
        "    print(classification_report(y_test, test_predictions))\n",
        "\n",
        "\n",
        "    # append to list to make a dataframe \n",
        "    classifier_name_list.append(name)\n",
        "    \n",
        "    training_timing.append(training_time)\n",
        "    training_pred_timing.append(training_p_time)\n",
        "    testing_pred_timing.append(test_time)\n",
        "\n",
        "\n",
        "    train_acc_list.append(train_acc)\n",
        "    test_acc_list.append(acc)\n",
        "\n",
        "    train_bacc_list.append(train_bal_acc)\n",
        "    test_bacc_list.append(bal_acc)\n",
        "\n",
        "    train_recall_list.append(recall_train)\n",
        "    test_recall_list.append(recall_test)\n",
        "\n",
        "    train_precision_list.append(precision_train)\n",
        "    test_precision_list.append(precision_test)\n",
        "\n",
        "    train_f1_list.append(f1_train)\n",
        "    test_f1_list.append(f1_test)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"=\"*50)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtTjNCZbBf6W"
      },
      "source": [
        "train_metrics_df = pd.DataFrame()\n",
        "test_metrics_df = pd.DataFrame()\n",
        "\n",
        "\n",
        "train_metrics_df['Classifier'] = classifier_name_list\n",
        "test_metrics_df['Classifier'] = classifier_name_list\n",
        "\n",
        "\n",
        "# F1 Score First \n",
        "train_metrics_df['Train F1'] = train_f1_list\n",
        "test_metrics_df['Test F1'] = test_f1_list \n",
        "\n",
        "# Recall\n",
        "train_metrics_df['Train Recall'] = train_recall_list\n",
        "test_metrics_df['Test Recall'] = test_recall_list\n",
        "\n",
        "# Precision \n",
        "train_metrics_df['Train Precision'] = train_precision_list\n",
        "test_metrics_df['Test Precision'] = test_precision_list\n",
        "\n",
        "# Bal Acc\n",
        "train_metrics_df['Train Balanced Accuracy'] = train_bacc_list\n",
        "test_metrics_df['Test Balanced Accuracy'] = test_bacc_list\n",
        "\n",
        "# Accuracy \n",
        "train_metrics_df['Train Accuracy'] = train_acc_list\n",
        "test_metrics_df['Test Accuracy'] = test_acc_list \n",
        "\n",
        "\n",
        "#train_metrics_df.sort_values(\"Train F1\" , ascending=False , inplace=True)\n",
        "train_metrics_df.set_index('Classifier' , inplace=True)\n",
        "\n",
        "#test_metrics_df.sort_values(\"Test F1\" , ascending=False , inplace=True)\n",
        "test_metrics_df.set_index('Classifier' , inplace=True)\n",
        "\n",
        "train_metrics_df['Model Training Taken (seconds)']  = training_timing\n",
        "test_metrics_df['Model Training Taken (seconds)']  = training_timing\n",
        "\n",
        "train_metrics_df['Model Prediction Time Taken (seconds)']  = training_pred_timing\n",
        "test_metrics_df['Model Prediction Time Taken (seconds)']  = testing_pred_timing\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# display df\n",
        "display(train_metrics_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_K60heJBgw7"
      },
      "source": [
        "# display df\n",
        "display(test_metrics_df)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}