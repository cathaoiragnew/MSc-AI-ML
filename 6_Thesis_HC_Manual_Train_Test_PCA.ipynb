{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "6_PCA_Manual_Train_Test_HandCraft_Thesis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwD-DLPOwbI-"
      },
      "source": [
        "-------------------------------------\n",
        "\n",
        "# Conclusions \n",
        "\n",
        "- PCA retaining 95% seems to perform slighly below baselines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrVWaVNkPW2k"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDjv2eMjASXA"
      },
      "source": [
        "#!pip install imbalanced-learn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtX5iMQHPDII",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06972591-62dc-48e0-e6ef-5f282156d4ff"
      },
      "source": [
        "\n",
        "########################### (https://github.com/curiousily/TensorFlow-on-Android-for-Human-Activity-Recognition-with-LSTMs/blob/master/human_activity_recognition.ipynb) imports\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "from scipy import stats\n",
        "import tensorflow as tf\n",
        "import seaborn as sns\n",
        "from pylab import rcParams\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "%matplotlib inline\n",
        "sns.set(style='whitegrid', palette='muted', font_scale=1.5)\n",
        "rcParams['figure.figsize'] = 14, 8\n",
        "RANDOM_SEED = 42\n",
        "\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from collections import Counter\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "from matplotlib.pyplot import figure\n",
        "\n",
        "from sklearn.metrics import accuracy_score, log_loss\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.linear_model import PassiveAggressiveClassifier\n",
        "from sklearn.semi_supervised import LabelPropagation\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.tree import ExtraTreeClassifier\n",
        "\n",
        "from sklearn.decomposition import PCA"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_M5F5DwPrKk"
      },
      "source": [
        "# Upload Data \n",
        "\n",
        "---------------------------------\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZX9OGsWPzvD"
      },
      "source": [
        "Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 432
        },
        "id": "7IyDYp-eLY8K",
        "outputId": "7127a824-4a62-4dda-cf77-54a357f80a6e"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded_signal_train = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-eae52b75-7feb-4371-823e-9db08d208c16\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-eae52b75-7feb-4371-823e-9db08d208c16\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving 28_2_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RJP to 28_2_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RJP\n",
            "Saving 28_3_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RJP to 28_3_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RJP\n",
            "Saving 28_4_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RJP to 28_4_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RJP\n",
            "Saving 28_5_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RJP to 28_5_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RJP\n",
            "Saving 28_6_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RJP to 28_6_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RJP\n",
            "Saving 29_2_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RCP to 29_2_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RCP\n",
            "Saving 29_3_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RCP to 29_3_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RCP\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "juXPVt1AP0v1"
      },
      "source": [
        "Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "eDlYInx_Pyx5",
        "outputId": "8af3b614-4bed-4136-d620-9cd11e673a80"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded_signal_test = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b8bab3b6-bde8-4cfe-9e59-5c2cbcc33227\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b8bab3b6-bde8-4cfe-9e59-5c2cbcc33227\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving 28_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RJP to 28_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RJP\n",
            "Saving 28_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RJP to 28_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RJP\n",
            "Saving 29_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RCP to 29_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RCP\n",
            "Saving 29_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RCP to 29_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RCP\n",
            "Saving 32_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RJP to 32_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RJP\n",
            "Saving 32_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RJP to 32_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RJP\n",
            "Saving 33_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_LJP to 33_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_LJP\n",
            "Saving 33_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_LJP to 33_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_LJP\n",
            "Saving 34_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RJP to 34_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RJP\n",
            "Saving 34_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RJP to 34_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RJP\n",
            "Saving 35_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RCP to 35_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RCP\n",
            "Saving 35_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RCP to 35_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RCP\n",
            "Saving 36_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_OTH to 36_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_OTH\n",
            "Saving 36_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_OTH to 36_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_OTH\n",
            "Saving 37_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RCP to 37_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RCP\n",
            "Saving 37_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RCP to 37_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RCP\n",
            "Saving 38_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RJP to 38_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RJP\n",
            "Saving 38_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RJP to 38_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RJP\n",
            "Saving 39_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_OTH to 39_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_OTH\n",
            "Saving 40_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_OTH to 40_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_OTH\n",
            "Saving 40_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_OTH to 40_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_OTH\n",
            "Saving 41_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_OTH to 41_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_OTH\n",
            "Saving 41_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_OTH to 41_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_OTH\n",
            "Saving 42_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_LCP to 42_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_LCP\n",
            "Saving 42_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_LCP to 42_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_LCP\n",
            "Saving 43_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RCP to 43_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RCP\n",
            "Saving 43_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RCP to 43_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RCP\n",
            "Saving 44_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_LJP to 44_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_LJP\n",
            "Saving 44_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_LJP to 44_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_LJP\n",
            "Saving 45_6_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_OTH to 45_6_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_OTH\n",
            "Saving 45_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_OTH to 45_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_OTH\n",
            "Saving 46_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_LJP to 46_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_LJP\n",
            "Saving 46_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_LJP to 46_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_LJP\n",
            "Saving 47_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_LJP to 47_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_LJP\n",
            "Saving 47_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_LJP to 47_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_LJP\n",
            "Saving 48_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_OTH to 48_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_OTH\n",
            "Saving 48_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_OTH to 48_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_OTH\n",
            "Saving 49_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_OTH to 49_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_OTH\n",
            "Saving 49_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_OTH to 49_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_OTH\n",
            "Saving 50_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_OTH to 50_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_OTH\n",
            "Saving 50_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_OTH to 50_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_OTH\n",
            "Saving 51_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RJP to 51_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RJP\n",
            "Saving 51_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RJP to 51_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RJP\n",
            "Saving 52_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RJP to 52_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RJP\n",
            "Saving 52_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RJP to 52_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RJP\n",
            "Saving 53_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RJP to 53_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RJP\n",
            "Saving 53_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RJP to 53_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RJP\n",
            "Saving 54_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_OTH to 54_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_OTH\n",
            "Saving 54_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_OTH to 54_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_OTH\n",
            "Saving 55_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_OTH to 55_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_OTH\n",
            "Saving 55_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_OTH to 55_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_OTH\n",
            "Saving 56_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RJP to 56_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RJP\n",
            "Saving 56_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RJP to 56_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RJP\n",
            "Saving 57_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RJP to 57_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RJP\n",
            "Saving 57_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RJP to 57_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RJP\n",
            "Saving 58_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_LJP to 58_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_LJP\n",
            "Saving 58_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_LJP to 58_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_LJP\n",
            "Saving 59_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RJP to 59_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RJP\n",
            "Saving 59_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RJP to 59_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RJP\n",
            "Saving 60_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RJP to 60_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RJP\n",
            "Saving 60_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RJP to 60_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RJP\n",
            "Saving 61_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RJP to 61_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RJP\n",
            "Saving 61_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RJP to 61_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RJP\n",
            "Saving 62_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RJP to 62_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RJP\n",
            "Saving 63_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RJP to 63_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RJP\n",
            "Saving 63_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RJP to 63_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RJP\n",
            "Saving 64_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_OTH to 64_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_OTH\n",
            "Saving 64_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_OTH to 64_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_OTH\n",
            "Saving 65_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_LCP to 65_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_LCP\n",
            "Saving 65_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_LCP to 65_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_LCP\n",
            "Saving 66_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RJP to 66_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RJP\n",
            "Saving 66_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RJP to 66_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RJP\n",
            "Saving 67_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RJP to 67_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RJP\n",
            "Saving 67_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RJP to 67_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RJP\n",
            "Saving 68_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_OTH to 68_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_OTH\n",
            "Saving 68_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_OTH to 68_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_OTH\n",
            "Saving 69_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_LCP to 69_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_LCP\n",
            "Saving 69_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_LCP to 69_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_LCP\n",
            "Saving 70_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_LJP to 70_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_LJP\n",
            "Saving 70_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_LJP to 70_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_LJP\n",
            "Saving 71_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RJP to 71_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RJP\n",
            "Saving 71_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RJP to 71_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RJP\n",
            "Saving 72_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_OTH to 72_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_OTH\n",
            "Saving 72_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_OTH to 72_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_OTH\n",
            "Saving 73_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_OTH to 73_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_OTH\n",
            "Saving 73_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_OTH to 73_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_OTH\n",
            "Saving 74_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_OTH to 74_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_OTH\n",
            "Saving 74_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_OTH to 74_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_OTH\n",
            "Saving 75_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RJP to 75_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RJP\n",
            "Saving 75_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RJP to 75_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RJP\n",
            "Saving 76_6_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_OTH to 76_6_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_OTH\n",
            "Saving 76_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_OTH to 76_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_OTH\n",
            "Saving 76_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_OTH to 76_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_OTH\n",
            "Saving 77_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_OTH to 77_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_OTH\n",
            "Saving 77_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_OTH to 77_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_OTH\n",
            "Saving 78_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RJP to 78_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RJP\n",
            "Saving 78_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RJP to 78_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RJP\n",
            "Saving 79_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RJP to 79_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RJP\n",
            "Saving 79_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RJP to 79_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RJP\n",
            "Saving 80_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RCP to 80_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RCP\n",
            "Saving 80_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RCP to 80_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RCP\n",
            "Saving 81_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RCP to 81_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RCP\n",
            "Saving 81_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RCP to 81_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RCP\n",
            "Saving 82_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RJP to 82_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RJP\n",
            "Saving 82_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RJP to 82_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RJP\n",
            "Saving 83_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_OTH to 83_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_OTH\n",
            "Saving 83_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_OTH to 83_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_OTH\n",
            "Saving 84_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_OTH to 84_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_OTH\n",
            "Saving 84_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_OTH to 84_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_OTH\n",
            "Saving 85_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_OTH to 85_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_OTH\n",
            "Saving 85_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_OTH to 85_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_OTH\n",
            "Saving 86_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RCP to 86_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RCP\n",
            "Saving 86_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RCP to 86_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RCP\n",
            "Saving 87_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_OTH to 87_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_OTH\n",
            "Saving 87_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_OTH to 87_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_OTH\n",
            "Saving 88_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_LJP to 88_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_LJP\n",
            "Saving 88_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_LJP to 88_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_LJP\n",
            "Saving 89_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_OTH to 89_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_OTH\n",
            "Saving 89_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_OTH to 89_8_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_OTH\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFIL8q5nvqUf"
      },
      "source": [
        "### Reading in segments & labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y70o5U5mSOUU"
      },
      "source": [
        "Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxXU40eBttE6"
      },
      "source": [
        "# getting keys, which is file names of npy \n",
        "list_of_dataframes_train = [key for key in uploaded_signal_train.keys()]\n",
        "\n",
        "\n",
        "# set up list to hold all loaded npy \n",
        "all_dataframe_train = [] \n",
        "\n",
        "\n",
        "for i in range(len(list_of_dataframes_train)):\n",
        "\n",
        "    # load in the data \n",
        "    dataframe_train = pd.read_csv(list_of_dataframes_train[i])\n",
        "\n",
        "\n",
        "    # append the data to 'all' list\n",
        "    all_dataframe_train.append(dataframe_train) \n",
        "\n",
        "\n",
        "all_df_train = pd.concat(all_dataframe_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXzYX7vVSPqK"
      },
      "source": [
        "Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4s9Wo8YGSQeN"
      },
      "source": [
        "# getting keys, which is file names of npy \n",
        "list_of_dataframes_test = [key for key in uploaded_signal_test.keys()]\n",
        "\n",
        "\n",
        "# set up list to hold all loaded npy \n",
        "all_dataframe_test = [] \n",
        "\n",
        "\n",
        "for i in range(len(list_of_dataframes_test)):\n",
        "\n",
        "    # load in the data \n",
        "    dataframe_test = pd.read_csv(list_of_dataframes_test[i])\n",
        "\n",
        "\n",
        "    # append the data to 'all' list\n",
        "    all_dataframe_test.append(dataframe_test) \n",
        "\n",
        "\n",
        "all_df_test = pd.concat(all_dataframe_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8jsSnExgGesF"
      },
      "source": [
        "# Quick Look "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "id": "pCEZ0lTrGiz3",
        "outputId": "8a3360f7-6a88-482b-bfde-aa88d982aa10"
      },
      "source": [
        "all_df_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>X_Mean_Acc_Move</th>\n",
              "      <th>Y_Mean_Acc_Move</th>\n",
              "      <th>Z_Mean_Acc_Move</th>\n",
              "      <th>X_Mean_Magnet</th>\n",
              "      <th>Y_Mean_Magnet</th>\n",
              "      <th>Z_Mean_Magnet</th>\n",
              "      <th>Pitch_Mean_Gyro</th>\n",
              "      <th>Roll_Mean_Gyro</th>\n",
              "      <th>Yaw_Mean_Gyro</th>\n",
              "      <th>X_Acc_Move_FFT_EnergyBands</th>\n",
              "      <th>Y_Acc_Move_FFT_EnergyBands</th>\n",
              "      <th>Z_Acc_Move_FFT_EnergyBands</th>\n",
              "      <th>X_Acc_Move_FFT_DominantFrequency</th>\n",
              "      <th>Y_Acc_Move_FFT_DominantFrequency</th>\n",
              "      <th>Z_Acc_Move_FFT_DominantFrequency</th>\n",
              "      <th>X_Acc_Move_FFT_MaxPower</th>\n",
              "      <th>Y_Acc_Move_FFT_MaxPower</th>\n",
              "      <th>Z_Acc_Move_FFT_MaxPower</th>\n",
              "      <th>X_Acc_Move_FFT_MeanWeightedFrequency</th>\n",
              "      <th>Y_Acc_Move_FFT_MeanWeightedFrequency</th>\n",
              "      <th>Z_Acc_Move_FFT_MeanWeightedFrequency</th>\n",
              "      <th>X_Acc_Move_FFT_SkewnessFrequency</th>\n",
              "      <th>Y_Acc_Move_FFT_SkewnessFrequency</th>\n",
              "      <th>Z_Acc_Move_FFT_SkewnessFrequency</th>\n",
              "      <th>X_Acc_Move_FFT_KurtosisFrequency</th>\n",
              "      <th>Y_Acc_Move_FFT_KurtosisFrequency</th>\n",
              "      <th>Z_Acc_Move_FFT_KurtosisFrequency</th>\n",
              "      <th>X_Magnet_ChangeOfSign</th>\n",
              "      <th>Y_Magnet_ChangeOfSign</th>\n",
              "      <th>Z_Magnet_ChangeOfSign</th>\n",
              "      <th>X_std_Acc_Move</th>\n",
              "      <th>Y_std_Acc_Move</th>\n",
              "      <th>Z_std_Acc_Move</th>\n",
              "      <th>X_std_Magnet</th>\n",
              "      <th>Y_std_Magnet</th>\n",
              "      <th>Z_std_Magnet</th>\n",
              "      <th>Pitch_std_Gyro</th>\n",
              "      <th>Roll_std_Gyro</th>\n",
              "      <th>Yaw_std_Gyro</th>\n",
              "      <th>...</th>\n",
              "      <th>Z_max_Magnet</th>\n",
              "      <th>Pitch_max_Gyro</th>\n",
              "      <th>Roll_max_Gyro</th>\n",
              "      <th>Yaw_max_Gyro</th>\n",
              "      <th>X_min_Acc_Move</th>\n",
              "      <th>Y_min_Acc_Move</th>\n",
              "      <th>Z_min_Acc_Move</th>\n",
              "      <th>X_min_Magnet</th>\n",
              "      <th>Y_min_Magnet</th>\n",
              "      <th>Z_min_Magnet</th>\n",
              "      <th>Pitch_min_Gyro</th>\n",
              "      <th>Roll_min_Gyro</th>\n",
              "      <th>Yaw_min_Gyro</th>\n",
              "      <th>SMA_Acc_Move</th>\n",
              "      <th>SMA_Magnet</th>\n",
              "      <th>SMA_Gyro</th>\n",
              "      <th>Energy_Acc_Move</th>\n",
              "      <th>Energy_Magnet</th>\n",
              "      <th>Energy_Gyro</th>\n",
              "      <th>X_iqr_Acc_Move</th>\n",
              "      <th>Y_iqr_Acc_Move</th>\n",
              "      <th>Z_iqr_Acc_Move</th>\n",
              "      <th>X_iqr_Magnet</th>\n",
              "      <th>Y_iqr_Magnet</th>\n",
              "      <th>Z_iqr_Magnet</th>\n",
              "      <th>Pitch_iqr_Gyro</th>\n",
              "      <th>Roll_iqr_Gyro</th>\n",
              "      <th>Yaw_iqr_Gyro</th>\n",
              "      <th>XY_corr_Acc_Move</th>\n",
              "      <th>XZ_corr_Acc_Move</th>\n",
              "      <th>YZ_corr_Acc_Move</th>\n",
              "      <th>XY_corr_Magnet</th>\n",
              "      <th>XZ_corr_Magnet</th>\n",
              "      <th>YZ_corr_Magnet</th>\n",
              "      <th>Pitch_Roll_corr_Gyro</th>\n",
              "      <th>Pitch_Yaw_corr_Gyro</th>\n",
              "      <th>Roll_Yaw_corr_Gyro</th>\n",
              "      <th>Label_segment</th>\n",
              "      <th>Participant_ID</th>\n",
              "      <th>Participant_Run</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>-0.345651</td>\n",
              "      <td>0.243621</td>\n",
              "      <td>-0.378761</td>\n",
              "      <td>-7.702587</td>\n",
              "      <td>-36.274094</td>\n",
              "      <td>6.544647</td>\n",
              "      <td>-0.001866</td>\n",
              "      <td>-0.004209</td>\n",
              "      <td>0.010049</td>\n",
              "      <td>[ 4.44089210e-16+0.j         -1.36743098e-01-0...</td>\n",
              "      <td>[ 5.55111512e-16+0.j          6.02078568e-02-0...</td>\n",
              "      <td>[ 5.55111512e-16+0.j          6.02078568e-02-0...</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.226947</td>\n",
              "      <td>0.270919</td>\n",
              "      <td>0.270919</td>\n",
              "      <td>1.014269</td>\n",
              "      <td>1.463456</td>\n",
              "      <td>1.463456</td>\n",
              "      <td>1.014269</td>\n",
              "      <td>1.463456</td>\n",
              "      <td>1.463456</td>\n",
              "      <td>1.085933</td>\n",
              "      <td>0.136027</td>\n",
              "      <td>0.136027</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.032882</td>\n",
              "      <td>0.042589</td>\n",
              "      <td>0.044694</td>\n",
              "      <td>0.221493</td>\n",
              "      <td>0.374326</td>\n",
              "      <td>0.246606</td>\n",
              "      <td>0.001253</td>\n",
              "      <td>0.000584</td>\n",
              "      <td>0.000988</td>\n",
              "      <td>...</td>\n",
              "      <td>6.783730</td>\n",
              "      <td>-0.000156</td>\n",
              "      <td>-0.003209</td>\n",
              "      <td>0.011021</td>\n",
              "      <td>-0.393286</td>\n",
              "      <td>0.181635</td>\n",
              "      <td>-0.442786</td>\n",
              "      <td>-8.061852</td>\n",
              "      <td>-36.759109</td>\n",
              "      <td>6.201022</td>\n",
              "      <td>-0.003715</td>\n",
              "      <td>-0.005141</td>\n",
              "      <td>0.007720</td>\n",
              "      <td>0.968032</td>\n",
              "      <td>50.521328</td>\n",
              "      <td>0.016125</td>\n",
              "      <td>0.327178</td>\n",
              "      <td>1418.222109</td>\n",
              "      <td>0.000125</td>\n",
              "      <td>0.062303</td>\n",
              "      <td>0.065942</td>\n",
              "      <td>0.081665</td>\n",
              "      <td>0.338572</td>\n",
              "      <td>0.585278</td>\n",
              "      <td>0.494285</td>\n",
              "      <td>0.001920</td>\n",
              "      <td>0.000705</td>\n",
              "      <td>0.001263</td>\n",
              "      <td>0.493614</td>\n",
              "      <td>-0.501615</td>\n",
              "      <td>0.316065</td>\n",
              "      <td>-0.743477</td>\n",
              "      <td>-0.409541</td>\n",
              "      <td>0.266258</td>\n",
              "      <td>0.241051</td>\n",
              "      <td>0.162547</td>\n",
              "      <td>0.253310</td>\n",
              "      <td>Go</td>\n",
              "      <td>28</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.319342</td>\n",
              "      <td>0.162098</td>\n",
              "      <td>-0.342011</td>\n",
              "      <td>-7.738424</td>\n",
              "      <td>-36.147514</td>\n",
              "      <td>6.689313</td>\n",
              "      <td>-0.001100</td>\n",
              "      <td>-0.004092</td>\n",
              "      <td>0.008219</td>\n",
              "      <td>[-2.22044605e-16+0.j          8.10724443e-02+0...</td>\n",
              "      <td>[-1.11022302e-16+0.j          1.73273293e-01-0...</td>\n",
              "      <td>[-1.11022302e-16+0.j          1.73273293e-01-0...</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.349178</td>\n",
              "      <td>0.331988</td>\n",
              "      <td>0.331988</td>\n",
              "      <td>1.409548</td>\n",
              "      <td>1.535443</td>\n",
              "      <td>1.535443</td>\n",
              "      <td>1.409548</td>\n",
              "      <td>1.535443</td>\n",
              "      <td>1.535443</td>\n",
              "      <td>1.111614</td>\n",
              "      <td>1.028266</td>\n",
              "      <td>1.028266</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.050333</td>\n",
              "      <td>0.048506</td>\n",
              "      <td>0.066542</td>\n",
              "      <td>0.257834</td>\n",
              "      <td>0.426416</td>\n",
              "      <td>0.117972</td>\n",
              "      <td>0.000964</td>\n",
              "      <td>0.000973</td>\n",
              "      <td>0.002203</td>\n",
              "      <td>...</td>\n",
              "      <td>6.783730</td>\n",
              "      <td>-0.000156</td>\n",
              "      <td>-0.002876</td>\n",
              "      <td>0.011021</td>\n",
              "      <td>-0.393286</td>\n",
              "      <td>0.091814</td>\n",
              "      <td>-0.442786</td>\n",
              "      <td>-8.061852</td>\n",
              "      <td>-36.771113</td>\n",
              "      <td>6.386037</td>\n",
              "      <td>-0.003107</td>\n",
              "      <td>-0.006575</td>\n",
              "      <td>0.004726</td>\n",
              "      <td>0.823451</td>\n",
              "      <td>50.575251</td>\n",
              "      <td>0.013411</td>\n",
              "      <td>0.254541</td>\n",
              "      <td>1411.535084</td>\n",
              "      <td>0.000092</td>\n",
              "      <td>0.090104</td>\n",
              "      <td>0.085942</td>\n",
              "      <td>0.099641</td>\n",
              "      <td>0.480858</td>\n",
              "      <td>0.823928</td>\n",
              "      <td>0.138442</td>\n",
              "      <td>0.000823</td>\n",
              "      <td>0.000870</td>\n",
              "      <td>0.003775</td>\n",
              "      <td>-0.686037</td>\n",
              "      <td>0.400664</td>\n",
              "      <td>-0.931307</td>\n",
              "      <td>-0.672780</td>\n",
              "      <td>0.220964</td>\n",
              "      <td>-0.295968</td>\n",
              "      <td>0.735916</td>\n",
              "      <td>0.368056</td>\n",
              "      <td>0.203087</td>\n",
              "      <td>Go</td>\n",
              "      <td>28</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>-0.271131</td>\n",
              "      <td>0.152904</td>\n",
              "      <td>-0.319191</td>\n",
              "      <td>-7.378853</td>\n",
              "      <td>-36.185124</td>\n",
              "      <td>6.572727</td>\n",
              "      <td>-0.000447</td>\n",
              "      <td>-0.003125</td>\n",
              "      <td>0.005925</td>\n",
              "      <td>[ 2.77555756e-17+0.j         -1.63596684e-01-0...</td>\n",
              "      <td>[-2.77555756e-17+0.j         -1.22561277e-01+0...</td>\n",
              "      <td>[-2.77555756e-17+0.j         -1.22561277e-01+0...</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.166835</td>\n",
              "      <td>0.279101</td>\n",
              "      <td>0.279101</td>\n",
              "      <td>1.472690</td>\n",
              "      <td>0.708644</td>\n",
              "      <td>0.708644</td>\n",
              "      <td>1.472690</td>\n",
              "      <td>0.708644</td>\n",
              "      <td>0.708644</td>\n",
              "      <td>0.071999</td>\n",
              "      <td>1.012308</td>\n",
              "      <td>1.012308</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.027377</td>\n",
              "      <td>0.040053</td>\n",
              "      <td>0.049630</td>\n",
              "      <td>0.591822</td>\n",
              "      <td>0.368272</td>\n",
              "      <td>0.125559</td>\n",
              "      <td>0.001518</td>\n",
              "      <td>0.001659</td>\n",
              "      <td>0.000804</td>\n",
              "      <td>...</td>\n",
              "      <td>6.757243</td>\n",
              "      <td>0.001655</td>\n",
              "      <td>-0.000278</td>\n",
              "      <td>0.007255</td>\n",
              "      <td>-0.328298</td>\n",
              "      <td>0.091814</td>\n",
              "      <td>-0.400806</td>\n",
              "      <td>-7.994001</td>\n",
              "      <td>-36.771113</td>\n",
              "      <td>6.386037</td>\n",
              "      <td>-0.003107</td>\n",
              "      <td>-0.006575</td>\n",
              "      <td>0.004726</td>\n",
              "      <td>0.743226</td>\n",
              "      <td>50.136704</td>\n",
              "      <td>0.010305</td>\n",
              "      <td>0.203591</td>\n",
              "      <td>1407.513063</td>\n",
              "      <td>0.000051</td>\n",
              "      <td>0.038717</td>\n",
              "      <td>0.067301</td>\n",
              "      <td>0.069507</td>\n",
              "      <td>1.036439</td>\n",
              "      <td>0.670277</td>\n",
              "      <td>0.184128</td>\n",
              "      <td>0.001735</td>\n",
              "      <td>0.001489</td>\n",
              "      <td>0.001226</td>\n",
              "      <td>0.226927</td>\n",
              "      <td>-0.656599</td>\n",
              "      <td>-0.653995</td>\n",
              "      <td>-0.625427</td>\n",
              "      <td>0.540082</td>\n",
              "      <td>-0.179181</td>\n",
              "      <td>0.780441</td>\n",
              "      <td>-0.404743</td>\n",
              "      <td>-0.199011</td>\n",
              "      <td>Go</td>\n",
              "      <td>28</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>-0.249181</td>\n",
              "      <td>0.161472</td>\n",
              "      <td>-0.330511</td>\n",
              "      <td>-6.654501</td>\n",
              "      <td>-36.508391</td>\n",
              "      <td>6.678391</td>\n",
              "      <td>0.000861</td>\n",
              "      <td>-0.001989</td>\n",
              "      <td>0.005660</td>\n",
              "      <td>[-2.22044605e-16+0.j          6.36372285e-02+0...</td>\n",
              "      <td>[-9.71445147e-17+0.j          3.53273303e-03-0...</td>\n",
              "      <td>[-9.71445147e-17+0.j          3.53273303e-03-0...</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.138219</td>\n",
              "      <td>0.204918</td>\n",
              "      <td>0.204918</td>\n",
              "      <td>1.256147</td>\n",
              "      <td>0.945723</td>\n",
              "      <td>0.945723</td>\n",
              "      <td>1.256147</td>\n",
              "      <td>0.945723</td>\n",
              "      <td>0.945723</td>\n",
              "      <td>-1.023668</td>\n",
              "      <td>0.436389</td>\n",
              "      <td>0.436389</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.025446</td>\n",
              "      <td>0.031178</td>\n",
              "      <td>0.046025</td>\n",
              "      <td>0.638703</td>\n",
              "      <td>0.308809</td>\n",
              "      <td>0.167174</td>\n",
              "      <td>0.000998</td>\n",
              "      <td>0.001147</td>\n",
              "      <td>0.000612</td>\n",
              "      <td>...</td>\n",
              "      <td>6.868314</td>\n",
              "      <td>0.002734</td>\n",
              "      <td>-0.000180</td>\n",
              "      <td>0.006939</td>\n",
              "      <td>-0.293901</td>\n",
              "      <td>0.110970</td>\n",
              "      <td>-0.400806</td>\n",
              "      <td>-7.917060</td>\n",
              "      <td>-36.957818</td>\n",
              "      <td>6.389077</td>\n",
              "      <td>-0.000860</td>\n",
              "      <td>-0.003451</td>\n",
              "      <td>0.004725</td>\n",
              "      <td>0.741164</td>\n",
              "      <td>49.841283</td>\n",
              "      <td>0.008706</td>\n",
              "      <td>0.201140</td>\n",
              "      <td>1422.277127</td>\n",
              "      <td>0.000039</td>\n",
              "      <td>0.029135</td>\n",
              "      <td>0.051315</td>\n",
              "      <td>0.060854</td>\n",
              "      <td>0.266378</td>\n",
              "      <td>0.613136</td>\n",
              "      <td>0.159569</td>\n",
              "      <td>0.001455</td>\n",
              "      <td>0.001763</td>\n",
              "      <td>0.000640</td>\n",
              "      <td>-0.656053</td>\n",
              "      <td>-0.133369</td>\n",
              "      <td>-0.455185</td>\n",
              "      <td>-0.388373</td>\n",
              "      <td>0.943622</td>\n",
              "      <td>-0.430645</td>\n",
              "      <td>0.578240</td>\n",
              "      <td>0.507768</td>\n",
              "      <td>0.566893</td>\n",
              "      <td>Go</td>\n",
              "      <td>28</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>-0.177695</td>\n",
              "      <td>0.146323</td>\n",
              "      <td>-0.286886</td>\n",
              "      <td>-5.571233</td>\n",
              "      <td>-36.757117</td>\n",
              "      <td>6.746565</td>\n",
              "      <td>0.000062</td>\n",
              "      <td>-0.002246</td>\n",
              "      <td>0.005517</td>\n",
              "      <td>[ 5.55111512e-17+0.j         -1.24760001e-01+0...</td>\n",
              "      <td>[ 1.52655666e-16+0.j         -1.15364104e-01+0...</td>\n",
              "      <td>[ 1.52655666e-16+0.j         -1.15364104e-01+0...</td>\n",
              "      <td>10.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.389177</td>\n",
              "      <td>0.224802</td>\n",
              "      <td>0.224802</td>\n",
              "      <td>2.390590</td>\n",
              "      <td>2.304085</td>\n",
              "      <td>2.304085</td>\n",
              "      <td>2.390590</td>\n",
              "      <td>2.304085</td>\n",
              "      <td>2.304085</td>\n",
              "      <td>0.812566</td>\n",
              "      <td>-0.770551</td>\n",
              "      <td>-0.770551</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.058334</td>\n",
              "      <td>0.041323</td>\n",
              "      <td>0.058233</td>\n",
              "      <td>0.912056</td>\n",
              "      <td>0.509485</td>\n",
              "      <td>0.107510</td>\n",
              "      <td>0.001388</td>\n",
              "      <td>0.000865</td>\n",
              "      <td>0.000677</td>\n",
              "      <td>...</td>\n",
              "      <td>6.871146</td>\n",
              "      <td>0.002734</td>\n",
              "      <td>-0.000180</td>\n",
              "      <td>0.006939</td>\n",
              "      <td>-0.249761</td>\n",
              "      <td>0.066792</td>\n",
              "      <td>-0.390163</td>\n",
              "      <td>-6.503804</td>\n",
              "      <td>-37.372203</td>\n",
              "      <td>6.600571</td>\n",
              "      <td>-0.002146</td>\n",
              "      <td>-0.003023</td>\n",
              "      <td>0.004725</td>\n",
              "      <td>0.610904</td>\n",
              "      <td>49.074915</td>\n",
              "      <td>0.008836</td>\n",
              "      <td>0.143791</td>\n",
              "      <td>1428.743417</td>\n",
              "      <td>0.000039</td>\n",
              "      <td>0.121571</td>\n",
              "      <td>0.043195</td>\n",
              "      <td>0.092089</td>\n",
              "      <td>1.520127</td>\n",
              "      <td>1.021965</td>\n",
              "      <td>0.221859</td>\n",
              "      <td>0.001881</td>\n",
              "      <td>0.001138</td>\n",
              "      <td>0.000656</td>\n",
              "      <td>0.236015</td>\n",
              "      <td>0.496750</td>\n",
              "      <td>-0.293949</td>\n",
              "      <td>-0.634931</td>\n",
              "      <td>-0.824047</td>\n",
              "      <td>0.702397</td>\n",
              "      <td>0.724095</td>\n",
              "      <td>0.471444</td>\n",
              "      <td>0.707511</td>\n",
              "      <td>Go</td>\n",
              "      <td>28</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 94 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  X_Mean_Acc_Move  ...  Participant_ID  Participant_Run\n",
              "0           0        -0.345651  ...              28                2\n",
              "1           1        -0.319342  ...              28                2\n",
              "2           2        -0.271131  ...              28                2\n",
              "3           3        -0.249181  ...              28                2\n",
              "4           4        -0.177695  ...              28                2\n",
              "\n",
              "[5 rows x 94 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "id": "TJ-KTwnDGhYv",
        "outputId": "fcd64c89-39c1-4e99-fef3-2f7906fd042a"
      },
      "source": [
        "all_df_test.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>X_Mean_Acc_Move</th>\n",
              "      <th>Y_Mean_Acc_Move</th>\n",
              "      <th>Z_Mean_Acc_Move</th>\n",
              "      <th>X_Mean_Magnet</th>\n",
              "      <th>Y_Mean_Magnet</th>\n",
              "      <th>Z_Mean_Magnet</th>\n",
              "      <th>Pitch_Mean_Gyro</th>\n",
              "      <th>Roll_Mean_Gyro</th>\n",
              "      <th>Yaw_Mean_Gyro</th>\n",
              "      <th>X_Acc_Move_FFT_EnergyBands</th>\n",
              "      <th>Y_Acc_Move_FFT_EnergyBands</th>\n",
              "      <th>Z_Acc_Move_FFT_EnergyBands</th>\n",
              "      <th>X_Acc_Move_FFT_DominantFrequency</th>\n",
              "      <th>Y_Acc_Move_FFT_DominantFrequency</th>\n",
              "      <th>Z_Acc_Move_FFT_DominantFrequency</th>\n",
              "      <th>X_Acc_Move_FFT_MaxPower</th>\n",
              "      <th>Y_Acc_Move_FFT_MaxPower</th>\n",
              "      <th>Z_Acc_Move_FFT_MaxPower</th>\n",
              "      <th>X_Acc_Move_FFT_MeanWeightedFrequency</th>\n",
              "      <th>Y_Acc_Move_FFT_MeanWeightedFrequency</th>\n",
              "      <th>Z_Acc_Move_FFT_MeanWeightedFrequency</th>\n",
              "      <th>X_Acc_Move_FFT_SkewnessFrequency</th>\n",
              "      <th>Y_Acc_Move_FFT_SkewnessFrequency</th>\n",
              "      <th>Z_Acc_Move_FFT_SkewnessFrequency</th>\n",
              "      <th>X_Acc_Move_FFT_KurtosisFrequency</th>\n",
              "      <th>Y_Acc_Move_FFT_KurtosisFrequency</th>\n",
              "      <th>Z_Acc_Move_FFT_KurtosisFrequency</th>\n",
              "      <th>X_Magnet_ChangeOfSign</th>\n",
              "      <th>Y_Magnet_ChangeOfSign</th>\n",
              "      <th>Z_Magnet_ChangeOfSign</th>\n",
              "      <th>X_std_Acc_Move</th>\n",
              "      <th>Y_std_Acc_Move</th>\n",
              "      <th>Z_std_Acc_Move</th>\n",
              "      <th>X_std_Magnet</th>\n",
              "      <th>Y_std_Magnet</th>\n",
              "      <th>Z_std_Magnet</th>\n",
              "      <th>Pitch_std_Gyro</th>\n",
              "      <th>Roll_std_Gyro</th>\n",
              "      <th>Yaw_std_Gyro</th>\n",
              "      <th>...</th>\n",
              "      <th>Z_max_Magnet</th>\n",
              "      <th>Pitch_max_Gyro</th>\n",
              "      <th>Roll_max_Gyro</th>\n",
              "      <th>Yaw_max_Gyro</th>\n",
              "      <th>X_min_Acc_Move</th>\n",
              "      <th>Y_min_Acc_Move</th>\n",
              "      <th>Z_min_Acc_Move</th>\n",
              "      <th>X_min_Magnet</th>\n",
              "      <th>Y_min_Magnet</th>\n",
              "      <th>Z_min_Magnet</th>\n",
              "      <th>Pitch_min_Gyro</th>\n",
              "      <th>Roll_min_Gyro</th>\n",
              "      <th>Yaw_min_Gyro</th>\n",
              "      <th>SMA_Acc_Move</th>\n",
              "      <th>SMA_Magnet</th>\n",
              "      <th>SMA_Gyro</th>\n",
              "      <th>Energy_Acc_Move</th>\n",
              "      <th>Energy_Magnet</th>\n",
              "      <th>Energy_Gyro</th>\n",
              "      <th>X_iqr_Acc_Move</th>\n",
              "      <th>Y_iqr_Acc_Move</th>\n",
              "      <th>Z_iqr_Acc_Move</th>\n",
              "      <th>X_iqr_Magnet</th>\n",
              "      <th>Y_iqr_Magnet</th>\n",
              "      <th>Z_iqr_Magnet</th>\n",
              "      <th>Pitch_iqr_Gyro</th>\n",
              "      <th>Roll_iqr_Gyro</th>\n",
              "      <th>Yaw_iqr_Gyro</th>\n",
              "      <th>XY_corr_Acc_Move</th>\n",
              "      <th>XZ_corr_Acc_Move</th>\n",
              "      <th>YZ_corr_Acc_Move</th>\n",
              "      <th>XY_corr_Magnet</th>\n",
              "      <th>XZ_corr_Magnet</th>\n",
              "      <th>YZ_corr_Magnet</th>\n",
              "      <th>Pitch_Roll_corr_Gyro</th>\n",
              "      <th>Pitch_Yaw_corr_Gyro</th>\n",
              "      <th>Roll_Yaw_corr_Gyro</th>\n",
              "      <th>Label_segment</th>\n",
              "      <th>Participant_ID</th>\n",
              "      <th>Participant_Run</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>-0.682452</td>\n",
              "      <td>-1.537566</td>\n",
              "      <td>1.163282</td>\n",
              "      <td>-31.175807</td>\n",
              "      <td>15.108035</td>\n",
              "      <td>6.015167</td>\n",
              "      <td>0.937977</td>\n",
              "      <td>-0.072320</td>\n",
              "      <td>-0.046816</td>\n",
              "      <td>[-2.22044605e-16+0.j          1.53001337e-01+0...</td>\n",
              "      <td>[ 1.22124533e-15+0.j          1.22016169e+00+2...</td>\n",
              "      <td>[ 1.22124533e-15+0.j          1.22016169e+00+2...</td>\n",
              "      <td>20.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.643152</td>\n",
              "      <td>2.448863</td>\n",
              "      <td>2.448863</td>\n",
              "      <td>4.655601</td>\n",
              "      <td>14.411731</td>\n",
              "      <td>14.411731</td>\n",
              "      <td>4.655601</td>\n",
              "      <td>14.411731</td>\n",
              "      <td>14.411731</td>\n",
              "      <td>-0.661059</td>\n",
              "      <td>0.386908</td>\n",
              "      <td>0.386908</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.109038</td>\n",
              "      <td>0.380652</td>\n",
              "      <td>0.214096</td>\n",
              "      <td>0.662956</td>\n",
              "      <td>1.406793</td>\n",
              "      <td>0.416355</td>\n",
              "      <td>0.222151</td>\n",
              "      <td>0.088708</td>\n",
              "      <td>0.011931</td>\n",
              "      <td>...</td>\n",
              "      <td>6.772522</td>\n",
              "      <td>1.446242</td>\n",
              "      <td>-0.019637</td>\n",
              "      <td>-0.021178</td>\n",
              "      <td>-0.830064</td>\n",
              "      <td>-1.931298</td>\n",
              "      <td>0.771279</td>\n",
              "      <td>-32.231030</td>\n",
              "      <td>12.583961</td>\n",
              "      <td>5.367462</td>\n",
              "      <td>0.653755</td>\n",
              "      <td>-0.305338</td>\n",
              "      <td>-0.062037</td>\n",
              "      <td>3.383299</td>\n",
              "      <td>52.299009</td>\n",
              "      <td>1.057113</td>\n",
              "      <td>4.385696</td>\n",
              "      <td>1238.957808</td>\n",
              "      <td>0.944586</td>\n",
              "      <td>0.140295</td>\n",
              "      <td>0.525360</td>\n",
              "      <td>0.224491</td>\n",
              "      <td>0.294349</td>\n",
              "      <td>0.401318</td>\n",
              "      <td>0.453442</td>\n",
              "      <td>0.187720</td>\n",
              "      <td>0.022940</td>\n",
              "      <td>0.015471</td>\n",
              "      <td>0.666391</td>\n",
              "      <td>-0.695607</td>\n",
              "      <td>-0.953410</td>\n",
              "      <td>0.983856</td>\n",
              "      <td>0.946480</td>\n",
              "      <td>0.928574</td>\n",
              "      <td>-0.878817</td>\n",
              "      <td>0.824730</td>\n",
              "      <td>-0.600255</td>\n",
              "      <td>Go</td>\n",
              "      <td>28</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.570402</td>\n",
              "      <td>-1.360722</td>\n",
              "      <td>1.709553</td>\n",
              "      <td>-32.287807</td>\n",
              "      <td>12.585200</td>\n",
              "      <td>5.150206</td>\n",
              "      <td>1.381306</td>\n",
              "      <td>-0.296202</td>\n",
              "      <td>-0.136848</td>\n",
              "      <td>[-7.21644966e-16+0.j          1.05372356e-01+0...</td>\n",
              "      <td>[ 2.77555756e-15+0.j         -1.88132267e+00-1...</td>\n",
              "      <td>[ 2.77555756e-15+0.j         -1.88132267e+00-1...</td>\n",
              "      <td>20.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.860700</td>\n",
              "      <td>2.244292</td>\n",
              "      <td>2.244292</td>\n",
              "      <td>9.321138</td>\n",
              "      <td>8.889377</td>\n",
              "      <td>8.889377</td>\n",
              "      <td>9.321138</td>\n",
              "      <td>8.889377</td>\n",
              "      <td>8.889377</td>\n",
              "      <td>-0.050429</td>\n",
              "      <td>0.711532</td>\n",
              "      <td>0.711532</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.151184</td>\n",
              "      <td>0.332196</td>\n",
              "      <td>0.796803</td>\n",
              "      <td>0.834394</td>\n",
              "      <td>2.198260</td>\n",
              "      <td>0.604916</td>\n",
              "      <td>0.315140</td>\n",
              "      <td>0.219459</td>\n",
              "      <td>0.140874</td>\n",
              "      <td>...</td>\n",
              "      <td>5.863824</td>\n",
              "      <td>1.718010</td>\n",
              "      <td>-0.023043</td>\n",
              "      <td>-0.021178</td>\n",
              "      <td>-0.829737</td>\n",
              "      <td>-1.874020</td>\n",
              "      <td>0.771279</td>\n",
              "      <td>-33.791976</td>\n",
              "      <td>7.878010</td>\n",
              "      <td>4.060401</td>\n",
              "      <td>0.901326</td>\n",
              "      <td>-0.633810</td>\n",
              "      <td>-0.448732</td>\n",
              "      <td>3.640678</td>\n",
              "      <td>50.023212</td>\n",
              "      <td>1.814355</td>\n",
              "      <td>5.867602</td>\n",
              "      <td>1233.308799</td>\n",
              "      <td>2.181790</td>\n",
              "      <td>0.219628</td>\n",
              "      <td>0.541532</td>\n",
              "      <td>1.328693</td>\n",
              "      <td>1.394364</td>\n",
              "      <td>3.066943</td>\n",
              "      <td>1.099722</td>\n",
              "      <td>0.590682</td>\n",
              "      <td>0.332308</td>\n",
              "      <td>0.122365</td>\n",
              "      <td>-0.061180</td>\n",
              "      <td>0.647081</td>\n",
              "      <td>-0.624960</td>\n",
              "      <td>0.984721</td>\n",
              "      <td>0.980586</td>\n",
              "      <td>0.951740</td>\n",
              "      <td>-0.906847</td>\n",
              "      <td>-0.608250</td>\n",
              "      <td>0.856768</td>\n",
              "      <td>Go</td>\n",
              "      <td>28</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>-0.432210</td>\n",
              "      <td>-1.553906</td>\n",
              "      <td>2.907824</td>\n",
              "      <td>-33.842049</td>\n",
              "      <td>8.614268</td>\n",
              "      <td>4.289888</td>\n",
              "      <td>1.360710</td>\n",
              "      <td>-0.788843</td>\n",
              "      <td>-0.515477</td>\n",
              "      <td>[ 8.60422844e-16+0.j         -1.86008136e-01+0...</td>\n",
              "      <td>[0.        +0.j         0.75013999-0.48745819j...</td>\n",
              "      <td>[0.        +0.j         0.75013999-0.48745819j...</td>\n",
              "      <td>20.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.906017</td>\n",
              "      <td>0.894609</td>\n",
              "      <td>0.894609</td>\n",
              "      <td>9.525538</td>\n",
              "      <td>14.787252</td>\n",
              "      <td>14.787252</td>\n",
              "      <td>9.525538</td>\n",
              "      <td>14.787252</td>\n",
              "      <td>14.787252</td>\n",
              "      <td>0.162686</td>\n",
              "      <td>-0.369606</td>\n",
              "      <td>-0.369606</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.155728</td>\n",
              "      <td>0.212389</td>\n",
              "      <td>0.734981</td>\n",
              "      <td>1.065952</td>\n",
              "      <td>2.695428</td>\n",
              "      <td>0.457061</td>\n",
              "      <td>0.372331</td>\n",
              "      <td>0.351509</td>\n",
              "      <td>0.310274</td>\n",
              "      <td>...</td>\n",
              "      <td>5.337253</td>\n",
              "      <td>1.718010</td>\n",
              "      <td>-0.360445</td>\n",
              "      <td>-0.074735</td>\n",
              "      <td>-0.730284</td>\n",
              "      <td>-1.799700</td>\n",
              "      <td>1.278333</td>\n",
              "      <td>-35.322797</td>\n",
              "      <td>5.257983</td>\n",
              "      <td>3.845828</td>\n",
              "      <td>0.585038</td>\n",
              "      <td>-1.394647</td>\n",
              "      <td>-0.914100</td>\n",
              "      <td>4.893939</td>\n",
              "      <td>46.746205</td>\n",
              "      <td>2.665030</td>\n",
              "      <td>11.666423</td>\n",
              "      <td>1246.503540</td>\n",
              "      <td>3.097979</td>\n",
              "      <td>0.159782</td>\n",
              "      <td>0.112439</td>\n",
              "      <td>0.853469</td>\n",
              "      <td>1.991838</td>\n",
              "      <td>5.399224</td>\n",
              "      <td>0.637311</td>\n",
              "      <td>0.488967</td>\n",
              "      <td>0.584246</td>\n",
              "      <td>0.595479</td>\n",
              "      <td>-0.895770</td>\n",
              "      <td>0.851415</td>\n",
              "      <td>-0.958038</td>\n",
              "      <td>0.974470</td>\n",
              "      <td>0.860691</td>\n",
              "      <td>0.909989</td>\n",
              "      <td>0.948261</td>\n",
              "      <td>0.878602</td>\n",
              "      <td>0.979366</td>\n",
              "      <td>Go</td>\n",
              "      <td>28</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>-0.352377</td>\n",
              "      <td>-1.637925</td>\n",
              "      <td>3.038907</td>\n",
              "      <td>-35.772118</td>\n",
              "      <td>4.248740</td>\n",
              "      <td>4.181738</td>\n",
              "      <td>0.713154</td>\n",
              "      <td>-1.206948</td>\n",
              "      <td>-0.564155</td>\n",
              "      <td>[ 3.88578059e-16+0.j         -2.15915596e-01-0...</td>\n",
              "      <td>[-1.33226763e-15+0.j          9.53482884e-01+0...</td>\n",
              "      <td>[-1.33226763e-15+0.j          9.53482884e-01+0...</td>\n",
              "      <td>20.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.793930</td>\n",
              "      <td>1.080632</td>\n",
              "      <td>1.080632</td>\n",
              "      <td>7.826885</td>\n",
              "      <td>9.307962</td>\n",
              "      <td>9.307962</td>\n",
              "      <td>7.826885</td>\n",
              "      <td>9.307962</td>\n",
              "      <td>9.307962</td>\n",
              "      <td>0.115984</td>\n",
              "      <td>-0.346625</td>\n",
              "      <td>-0.346625</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.132912</td>\n",
              "      <td>0.186944</td>\n",
              "      <td>0.583028</td>\n",
              "      <td>1.308757</td>\n",
              "      <td>2.259052</td>\n",
              "      <td>0.381620</td>\n",
              "      <td>0.421047</td>\n",
              "      <td>0.267814</td>\n",
              "      <td>0.489785</td>\n",
              "      <td>...</td>\n",
              "      <td>4.960015</td>\n",
              "      <td>1.455145</td>\n",
              "      <td>-0.788868</td>\n",
              "      <td>0.665603</td>\n",
              "      <td>-0.526360</td>\n",
              "      <td>-1.862941</td>\n",
              "      <td>1.960098</td>\n",
              "      <td>-37.845148</td>\n",
              "      <td>1.329015</td>\n",
              "      <td>3.845828</td>\n",
              "      <td>0.239873</td>\n",
              "      <td>-1.584809</td>\n",
              "      <td>-0.945598</td>\n",
              "      <td>5.029208</td>\n",
              "      <td>44.202595</td>\n",
              "      <td>2.617379</td>\n",
              "      <td>12.434456</td>\n",
              "      <td>1322.144931</td>\n",
              "      <td>2.772479</td>\n",
              "      <td>0.225547</td>\n",
              "      <td>0.151484</td>\n",
              "      <td>0.857376</td>\n",
              "      <td>0.879157</td>\n",
              "      <td>2.757962</td>\n",
              "      <td>0.181775</td>\n",
              "      <td>0.713078</td>\n",
              "      <td>0.404571</td>\n",
              "      <td>0.507863</td>\n",
              "      <td>0.228421</td>\n",
              "      <td>-0.036238</td>\n",
              "      <td>-0.776747</td>\n",
              "      <td>0.966418</td>\n",
              "      <td>-0.820942</td>\n",
              "      <td>-0.707295</td>\n",
              "      <td>0.762054</td>\n",
              "      <td>-0.165488</td>\n",
              "      <td>0.506342</td>\n",
              "      <td>Go</td>\n",
              "      <td>28</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>-0.212763</td>\n",
              "      <td>-0.706964</td>\n",
              "      <td>2.432414</td>\n",
              "      <td>-37.176428</td>\n",
              "      <td>2.029860</td>\n",
              "      <td>4.338622</td>\n",
              "      <td>0.476103</td>\n",
              "      <td>-0.938140</td>\n",
              "      <td>0.234419</td>\n",
              "      <td>[ 2.22044605e-16+0.j         -1.24612143e+00+0...</td>\n",
              "      <td>[-1.33226763e-15+0.j          2.79013488e+00+6...</td>\n",
              "      <td>[-1.33226763e-15+0.j          2.79013488e+00+6...</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1.372970</td>\n",
              "      <td>6.805745</td>\n",
              "      <td>6.805745</td>\n",
              "      <td>13.081946</td>\n",
              "      <td>89.868421</td>\n",
              "      <td>89.868421</td>\n",
              "      <td>13.081946</td>\n",
              "      <td>89.868421</td>\n",
              "      <td>89.868421</td>\n",
              "      <td>-1.190453</td>\n",
              "      <td>-1.026691</td>\n",
              "      <td>-1.026691</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.262708</td>\n",
              "      <td>1.461577</td>\n",
              "      <td>0.454639</td>\n",
              "      <td>0.740467</td>\n",
              "      <td>0.934479</td>\n",
              "      <td>0.483458</td>\n",
              "      <td>0.257743</td>\n",
              "      <td>0.513069</td>\n",
              "      <td>0.967626</td>\n",
              "      <td>...</td>\n",
              "      <td>4.960015</td>\n",
              "      <td>1.156626</td>\n",
              "      <td>0.217335</td>\n",
              "      <td>2.619490</td>\n",
              "      <td>-0.571140</td>\n",
              "      <td>-1.862941</td>\n",
              "      <td>1.883916</td>\n",
              "      <td>-37.857212</td>\n",
              "      <td>1.234925</td>\n",
              "      <td>3.241310</td>\n",
              "      <td>0.239873</td>\n",
              "      <td>-1.584809</td>\n",
              "      <td>-0.945598</td>\n",
              "      <td>4.254462</td>\n",
              "      <td>43.544910</td>\n",
              "      <td>2.157854</td>\n",
              "      <td>8.873624</td>\n",
              "      <td>1406.686063</td>\n",
              "      <td>2.427703</td>\n",
              "      <td>0.322635</td>\n",
              "      <td>0.850476</td>\n",
              "      <td>0.609160</td>\n",
              "      <td>1.496803</td>\n",
              "      <td>1.391534</td>\n",
              "      <td>0.623725</td>\n",
              "      <td>0.248179</td>\n",
              "      <td>0.605028</td>\n",
              "      <td>0.849905</td>\n",
              "      <td>-0.109258</td>\n",
              "      <td>-0.477004</td>\n",
              "      <td>-0.375772</td>\n",
              "      <td>0.815402</td>\n",
              "      <td>-0.687845</td>\n",
              "      <td>-0.890858</td>\n",
              "      <td>0.895605</td>\n",
              "      <td>0.925753</td>\n",
              "      <td>0.971792</td>\n",
              "      <td>Walk 1</td>\n",
              "      <td>28</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 94 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  X_Mean_Acc_Move  ...  Participant_ID  Participant_Run\n",
              "0           0        -0.682452  ...              28                7\n",
              "1           1        -0.570402  ...              28                7\n",
              "2           2        -0.432210  ...              28                7\n",
              "3           3        -0.352377  ...              28                7\n",
              "4           4        -0.212763  ...              28                7\n",
              "\n",
              "[5 rows x 94 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVPv0iQ6SPeH"
      },
      "source": [
        "# Train Test Split "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlyxtKg4SRMP"
      },
      "source": [
        "# Getting X_train & y_train'\n",
        "X_train = all_df_train.drop(['Unnamed: 0' , 'Label_segment' , 'Participant_ID' , 'Participant_Run', 'X_Acc_Move_FFT_EnergyBands', \t'Y_Acc_Move_FFT_EnergyBands', \t'Z_Acc_Move_FFT_EnergyBands'\t], axis = 1)\n",
        "y_train = all_df_train['Label_segment'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyOL-dTlTDbw"
      },
      "source": [
        "# Getting X_train & y_train\n",
        "X_test = all_df_test.drop(['Unnamed: 0' , 'Label_segment' , 'Participant_ID' , 'Participant_Run',  'X_Acc_Move_FFT_EnergyBands', \t'Y_Acc_Move_FFT_EnergyBands', \t'Z_Acc_Move_FFT_EnergyBands'], axis = 1)\n",
        "y_test = all_df_test['Label_segment'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vM6doFdbvla"
      },
      "source": [
        "---------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tVnwD0csNgw"
      },
      "source": [
        "Standard Scale "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFhyhbcjsO7K"
      },
      "source": [
        "# Set up ss for non-shuffled data\n",
        "ss = StandardScaler()\n",
        "\n",
        "\n",
        "# fit train & transform test\n",
        "X_train_scale = ss.fit_transform(X_train)\n",
        "X_test_scale = ss.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bpApWRNA4f0"
      },
      "source": [
        "-----------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Q9ED2cpU9UY",
        "outputId": "273fae99-1e43-4286-b3be-7d818f0b4937"
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# PCA set for 95% of variance \n",
        "pca = PCA(n_components=0.95)\n",
        "\n",
        "pca.fit(X_train_scale)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PCA(copy=True, iterated_power='auto', n_components=0.95, random_state=None,\n",
              "    svd_solver='auto', tol=0.0, whiten=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7RRf43cVU1X",
        "outputId": "c1226feb-5a6b-4296-f8f5-e9b5d88cde4e"
      },
      "source": [
        "# PCA set for 95% of variance  \n",
        "\n",
        "X_train_scale_pca = pca.transform(X_train_scale)\n",
        "X_test_scale_pca = pca.transform(X_test_scale)\n",
        "\n",
        "# quick print of shapes to see difference\n",
        "print(f'Train data:\\nBefore pca shape: {X_train_scale.shape} , after pca applied: {X_train_scale_pca.shape} ')\n",
        "print(f'\\nTest data:\\nBefore pca shape: {X_test_scale.shape} , after pca applied: {X_test_scale_pca.shape} ')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train data:\n",
            "Before pca shape: (83873, 87) , after pca applied: (83873, 35) \n",
            "\n",
            "Test data:\n",
            "Before pca shape: (38687, 87) , after pca applied: (38687, 35) \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AY2CvefFA3Pd"
      },
      "source": [
        "Check if SMOTE helps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ivu4MogoA3Pe",
        "outputId": "b840661f-2ab1-4922-81b8-eac9257f4b47"
      },
      "source": [
        "print(Counter(y_train))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counter({'Turn 1': 3091, 'Turn 2': 2431, 'Walk 2': 1777, 'sit': 1627, 'Walk 1': 1522, 'Go': 745})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-iIID62gA3Pf",
        "outputId": "bae9f4f3-0947-4d3f-c036-8158b5e70afe"
      },
      "source": [
        "# transform the dataset\n",
        "oversample = SMOTE()\n",
        "X_train_scale_smote, y_train_smote = oversample.fit_resample(X_train_scale_pca, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCzRxVv6A3Ph",
        "outputId": "63d1f084-d6ce-410b-8d9a-2333f8f7bfa8"
      },
      "source": [
        "print(Counter(y_train_smote))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counter({'Go': 3091, 'Walk 1': 3091, 'Turn 1': 3091, 'Walk 2': 3091, 'Turn 2': 3091, 'sit': 3091})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "uMdoaGkNWjTL",
        "outputId": "20c7cbf8-9e9f-4d8a-eeb8-251c23957a6a"
      },
      "source": [
        "# quick print of shapes to see difference\n",
        "print(f'Train data:\\nBefore pca shape: {X_train_scale.shape} , after pca applied: {X_train_scale_smote.shape} ')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-28944ee9ab65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# quick print of shapes to see difference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Train data:\\nBefore pca shape: {X_train_scale.shape} , after pca applied: {X_train_scale_smote.shape} '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train_scale_smote' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZSss6u0jQN_"
      },
      "source": [
        "----------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cgzUsp7ZvsfE"
      },
      "source": [
        "# PCA - No SMOTE \n",
        "\n",
        "Check Some Classifiers "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nu9bDnSz3bZl",
        "outputId": "169b3d3a-061d-470a-a6fc-333a59909b5e"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, log_loss , recall_score , f1_score, precision_score , roc_auc_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.linear_model import PassiveAggressiveClassifier\n",
        "from sklearn.semi_supervised import LabelPropagation\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.tree import ExtraTreeClassifier\n",
        "\n",
        "classifiers = [\n",
        "               \n",
        "    # Too much computation to run now since using entire data and not segmenting on location \n",
        "    ##KNeighborsClassifier(),\n",
        "    ##GradientBoostingClassifier(),\n",
        "    ##LabelPropagation(),\n",
        "\n",
        "    DecisionTreeClassifier(),\n",
        "    RandomForestClassifier(),\n",
        "    AdaBoostClassifier(),\n",
        "    GaussianNB(),\n",
        "    LinearDiscriminantAnalysis(),\n",
        "    QuadraticDiscriminantAnalysis(),\n",
        "    LinearSVC(),\n",
        "    SGDClassifier(),\n",
        "    MLPClassifier(),\n",
        "    PassiveAggressiveClassifier(),\n",
        "    ExtraTreesClassifier(),\n",
        "    BaggingClassifier(),\n",
        "  \n",
        "    \n",
        "     ]\n",
        "\n",
        "\n",
        "# list to hold for dataframe\n",
        "classifier_name_list = []\n",
        "train_acc_list = []\n",
        "train_bacc_list = []\n",
        "test_acc_list = []\n",
        "test_bacc_list = []\n",
        "train_recall_list = []\n",
        "test_recall_list = []\n",
        "train_precision_list = []\n",
        "test_precision_list = []\n",
        "train_f1_list = []\n",
        "test_f1_list = []\n",
        "\n",
        "\n",
        "for clf in classifiers:\n",
        "    \n",
        "    name = clf.__class__.__name__\n",
        "    \n",
        "    print(\"=\"*50)\n",
        "    print(name)\n",
        "\n",
        "    clf.fit(X_train_scale_pca, y_train)\n",
        "    \n",
        "    print('****Results****')\n",
        "\n",
        "    # Test Predictions\n",
        "    test_predictions = clf.predict(X_test_scale_pca)\n",
        "\n",
        "    # Test Metrics\n",
        "    acc            = accuracy_score(y_test, test_predictions)\n",
        "    bal_acc        = balanced_accuracy_score(y_test, test_predictions)\n",
        "    recall_test    = recall_score(y_test, test_predictions, average = 'weighted')\n",
        "    f1_test        = f1_score(y_test, test_predictions ,  average = 'weighted')\n",
        "    precision_test = precision_score(y_test, test_predictions,  average = 'weighted') \n",
        "\n",
        "\n",
        "\n",
        "    # Train Predictions\n",
        "    train_predictions = clf.predict(X_train_scale_pca)\n",
        "\n",
        "    # Train Metrics\n",
        "    train_acc       = accuracy_score(y_train, train_predictions)\n",
        "    train_bal_acc   = balanced_accuracy_score(y_train, train_predictions)\n",
        "    recall_train    = recall_score(y_train, train_predictions , average = 'weighted')\n",
        "    f1_train        = f1_score(y_train, train_predictions ,  average = 'weighted')\n",
        "    precision_train = precision_score(y_train, train_predictions,  average = 'weighted') \n",
        "\n",
        "    print(\"\\n\\nTest Classification Report\\n\")\n",
        "    print(classification_report(y_test, test_predictions))\n",
        "\n",
        "    # append to list to make a dataframe \n",
        "    classifier_name_list.append(name)\n",
        "    train_acc_list.append(train_acc)\n",
        "    test_acc_list.append(acc)\n",
        "\n",
        "    train_bacc_list.append(train_bal_acc)\n",
        "    test_bacc_list.append(bal_acc)\n",
        "\n",
        "    train_recall_list.append(recall_train)\n",
        "    test_recall_list.append(recall_test)\n",
        "\n",
        "    train_precision_list.append(precision_train)\n",
        "    test_precision_list.append(precision_test)\n",
        "\n",
        "    train_f1_list.append(f1_train)\n",
        "    test_f1_list.append(f1_test)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"=\"*50)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "DecisionTreeClassifier\n",
            "****Results****\n",
            "\n",
            "\n",
            "Test Classification Report\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          Go       0.46      0.41      0.44      2214\n",
            "      Turn 1       0.47      0.48      0.47     10801\n",
            "      Turn 2       0.48      0.45      0.46     10754\n",
            "      Walk 1       0.26      0.27      0.26      4790\n",
            "      Walk 2       0.32      0.31      0.32      6471\n",
            "         sit       0.26      0.32      0.29      3657\n",
            "\n",
            "    accuracy                           0.40     38687\n",
            "   macro avg       0.38      0.37      0.37     38687\n",
            "weighted avg       0.40      0.40      0.40     38687\n",
            "\n",
            "==================================================\n",
            "RandomForestClassifier\n",
            "****Results****\n",
            "\n",
            "\n",
            "Test Classification Report\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          Go       0.74      0.47      0.57      2214\n",
            "      Turn 1       0.51      0.75      0.60     10801\n",
            "      Turn 2       0.55      0.67      0.60     10754\n",
            "      Walk 1       0.50      0.22      0.31      4790\n",
            "      Walk 2       0.50      0.29      0.37      6471\n",
            "         sit       0.53      0.35      0.42      3657\n",
            "\n",
            "    accuracy                           0.53     38687\n",
            "   macro avg       0.55      0.46      0.48     38687\n",
            "weighted avg       0.53      0.53      0.51     38687\n",
            "\n",
            "==================================================\n",
            "AdaBoostClassifier\n",
            "****Results****\n",
            "\n",
            "\n",
            "Test Classification Report\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          Go       0.66      0.47      0.55      2214\n",
            "      Turn 1       0.38      0.55      0.45     10801\n",
            "      Turn 2       0.41      0.48      0.44     10754\n",
            "      Walk 1       0.32      0.13      0.19      4790\n",
            "      Walk 2       0.36      0.21      0.26      6471\n",
            "         sit       0.34      0.28      0.31      3657\n",
            "\n",
            "    accuracy                           0.39     38687\n",
            "   macro avg       0.41      0.35      0.37     38687\n",
            "weighted avg       0.39      0.39      0.37     38687\n",
            "\n",
            "==================================================\n",
            "GaussianNB\n",
            "****Results****\n",
            "\n",
            "\n",
            "Test Classification Report\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          Go       0.28      0.21      0.24      2214\n",
            "      Turn 1       0.41      0.16      0.23     10801\n",
            "      Turn 2       0.36      0.25      0.29     10754\n",
            "      Walk 1       0.32      0.10      0.15      4790\n",
            "      Walk 2       0.20      0.66      0.30      6471\n",
            "         sit       0.20      0.12      0.15      3657\n",
            "\n",
            "    accuracy                           0.26     38687\n",
            "   macro avg       0.30      0.25      0.23     38687\n",
            "weighted avg       0.32      0.26      0.24     38687\n",
            "\n",
            "==================================================\n",
            "LinearDiscriminantAnalysis\n",
            "****Results****\n",
            "\n",
            "\n",
            "Test Classification Report\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          Go       0.39      0.21      0.27      2214\n",
            "      Turn 1       0.33      0.55      0.42     10801\n",
            "      Turn 2       0.37      0.45      0.41     10754\n",
            "      Walk 1       0.39      0.12      0.18      4790\n",
            "      Walk 2       0.36      0.18      0.24      6471\n",
            "         sit       0.37      0.19      0.25      3657\n",
            "\n",
            "    accuracy                           0.35     38687\n",
            "   macro avg       0.37      0.28      0.29     38687\n",
            "weighted avg       0.36      0.35      0.33     38687\n",
            "\n",
            "==================================================\n",
            "QuadraticDiscriminantAnalysis\n",
            "****Results****\n",
            "\n",
            "\n",
            "Test Classification Report\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          Go       0.26      0.33      0.29      2214\n",
            "      Turn 1       0.49      0.16      0.25     10801\n",
            "      Turn 2       0.42      0.25      0.31     10754\n",
            "      Walk 1       0.33      0.14      0.19      4790\n",
            "      Walk 2       0.20      0.71      0.31      6471\n",
            "         sit       0.51      0.08      0.14      3657\n",
            "\n",
            "    accuracy                           0.28     38687\n",
            "   macro avg       0.37      0.28      0.25     38687\n",
            "weighted avg       0.39      0.28      0.26     38687\n",
            "\n",
            "==================================================\n",
            "LinearSVC\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "****Results****\n",
            "\n",
            "\n",
            "Test Classification Report\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          Go       0.46      0.26      0.33      2214\n",
            "      Turn 1       0.35      0.55      0.43     10801\n",
            "      Turn 2       0.37      0.52      0.43     10754\n",
            "      Walk 1       0.39      0.08      0.13      4790\n",
            "      Walk 2       0.36      0.17      0.23      6471\n",
            "         sit       0.45      0.18      0.25      3657\n",
            "\n",
            "    accuracy                           0.37     38687\n",
            "   macro avg       0.40      0.29      0.30     38687\n",
            "weighted avg       0.38      0.37      0.34     38687\n",
            "\n",
            "==================================================\n",
            "SGDClassifier\n",
            "****Results****\n",
            "\n",
            "\n",
            "Test Classification Report\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          Go       0.25      0.38      0.30      2214\n",
            "      Turn 1       0.35      0.44      0.39     10801\n",
            "      Turn 2       0.34      0.24      0.28     10754\n",
            "      Walk 1       0.22      0.06      0.10      4790\n",
            "      Walk 2       0.26      0.13      0.17      6471\n",
            "         sit       0.18      0.45      0.26      3657\n",
            "\n",
            "    accuracy                           0.28     38687\n",
            "   macro avg       0.26      0.28      0.25     38687\n",
            "weighted avg       0.29      0.28      0.27     38687\n",
            "\n",
            "==================================================\n",
            "MLPClassifier\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "****Results****\n",
            "\n",
            "\n",
            "Test Classification Report\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          Go       0.74      0.47      0.58      2214\n",
            "      Turn 1       0.58      0.69      0.63     10801\n",
            "      Turn 2       0.60      0.63      0.61     10754\n",
            "      Walk 1       0.42      0.31      0.36      4790\n",
            "      Walk 2       0.45      0.41      0.43      6471\n",
            "         sit       0.46      0.46      0.46      3657\n",
            "\n",
            "    accuracy                           0.54     38687\n",
            "   macro avg       0.54      0.49      0.51     38687\n",
            "weighted avg       0.54      0.54      0.54     38687\n",
            "\n",
            "==================================================\n",
            "PassiveAggressiveClassifier\n",
            "****Results****\n",
            "\n",
            "\n",
            "Test Classification Report\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          Go       0.13      0.04      0.06      2214\n",
            "      Turn 1       0.30      0.40      0.34     10801\n",
            "      Turn 2       0.31      0.37      0.34     10754\n",
            "      Walk 1       0.15      0.14      0.15      4790\n",
            "      Walk 2       0.22      0.14      0.17      6471\n",
            "         sit       0.22      0.16      0.19      3657\n",
            "\n",
            "    accuracy                           0.27     38687\n",
            "   macro avg       0.22      0.21      0.21     38687\n",
            "weighted avg       0.25      0.27      0.26     38687\n",
            "\n",
            "==================================================\n",
            "ExtraTreesClassifier\n",
            "****Results****\n",
            "\n",
            "\n",
            "Test Classification Report\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          Go       0.70      0.38      0.49      2214\n",
            "      Turn 1       0.49      0.77      0.60     10801\n",
            "      Turn 2       0.54      0.69      0.61     10754\n",
            "      Walk 1       0.52      0.18      0.27      4790\n",
            "      Walk 2       0.50      0.25      0.33      6471\n",
            "         sit       0.55      0.29      0.37      3657\n",
            "\n",
            "    accuracy                           0.52     38687\n",
            "   macro avg       0.55      0.42      0.44     38687\n",
            "weighted avg       0.53      0.52      0.49     38687\n",
            "\n",
            "==================================================\n",
            "BaggingClassifier\n",
            "****Results****\n",
            "\n",
            "\n",
            "Test Classification Report\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          Go       0.62      0.53      0.57      2214\n",
            "      Turn 1       0.49      0.68      0.57     10801\n",
            "      Turn 2       0.54      0.58      0.56     10754\n",
            "      Walk 1       0.40      0.25      0.31      4790\n",
            "      Walk 2       0.43      0.30      0.35      6471\n",
            "         sit       0.46      0.34      0.39      3657\n",
            "\n",
            "    accuracy                           0.49     38687\n",
            "   macro avg       0.49      0.45      0.46     38687\n",
            "weighted avg       0.49      0.49      0.48     38687\n",
            "\n",
            "==================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "id": "UvJWRblfuUEh",
        "outputId": "2afa9d26-fd37-4a72-e916-54c6cd44e4e4"
      },
      "source": [
        "train_metrics_df = pd.DataFrame()\n",
        "test_metrics_df = pd.DataFrame()\n",
        "\n",
        "\n",
        "train_metrics_df['Classifier'] = classifier_name_list\n",
        "test_metrics_df['Classifier'] = classifier_name_list\n",
        "\n",
        "# F1 Score First \n",
        "train_metrics_df['Train F1'] = train_f1_list\n",
        "test_metrics_df['Test F1'] = test_f1_list \n",
        "\n",
        "# Recall\n",
        "train_metrics_df['Train Recall'] = train_recall_list\n",
        "test_metrics_df['Test Recall'] = test_recall_list\n",
        "\n",
        "# Precision \n",
        "train_metrics_df['Train Precision'] = train_precision_list\n",
        "test_metrics_df['Test Precision'] = test_precision_list\n",
        "\n",
        "# Bal Acc\n",
        "train_metrics_df['Train Balanced Accuracy'] = train_bacc_list\n",
        "test_metrics_df['Test Balanced Accuracy'] = test_bacc_list\n",
        "\n",
        "# Accuracy \n",
        "train_metrics_df['Train Accuracy'] = train_acc_list\n",
        "test_metrics_df['Test Accuracy'] = test_acc_list \n",
        "\n",
        "\n",
        "train_metrics_df.sort_values(\"Train F1\" , ascending=False , inplace=True)\n",
        "train_metrics_df.set_index('Classifier' , inplace=True)\n",
        "\n",
        "test_metrics_df.sort_values(\"Test F1\" , ascending=False , inplace=True)\n",
        "test_metrics_df.set_index('Classifier' , inplace=True)\n",
        "\n",
        "# display df\n",
        "display(train_metrics_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Train F1</th>\n",
              "      <th>Train Recall</th>\n",
              "      <th>Train Precision</th>\n",
              "      <th>Train Balanced Accuracy</th>\n",
              "      <th>Train Accuracy</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Classifier</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>DecisionTreeClassifier</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RandomForestClassifier</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ExtraTreesClassifier</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BaggingClassifier</th>\n",
              "      <td>0.989060</td>\n",
              "      <td>0.989067</td>\n",
              "      <td>0.989146</td>\n",
              "      <td>0.986900</td>\n",
              "      <td>0.989067</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MLPClassifier</th>\n",
              "      <td>0.632518</td>\n",
              "      <td>0.638024</td>\n",
              "      <td>0.637700</td>\n",
              "      <td>0.587750</td>\n",
              "      <td>0.638024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AdaBoostClassifier</th>\n",
              "      <td>0.395866</td>\n",
              "      <td>0.411002</td>\n",
              "      <td>0.413745</td>\n",
              "      <td>0.366316</td>\n",
              "      <td>0.411002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LinearSVC</th>\n",
              "      <td>0.358644</td>\n",
              "      <td>0.384546</td>\n",
              "      <td>0.421402</td>\n",
              "      <td>0.319141</td>\n",
              "      <td>0.384546</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LinearDiscriminantAnalysis</th>\n",
              "      <td>0.357678</td>\n",
              "      <td>0.377416</td>\n",
              "      <td>0.397676</td>\n",
              "      <td>0.310020</td>\n",
              "      <td>0.377416</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>QuadraticDiscriminantAnalysis</th>\n",
              "      <td>0.299384</td>\n",
              "      <td>0.311626</td>\n",
              "      <td>0.424868</td>\n",
              "      <td>0.316648</td>\n",
              "      <td>0.311626</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SGDClassifier</th>\n",
              "      <td>0.290910</td>\n",
              "      <td>0.309468</td>\n",
              "      <td>0.304447</td>\n",
              "      <td>0.294325</td>\n",
              "      <td>0.309468</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GaussianNB</th>\n",
              "      <td>0.261152</td>\n",
              "      <td>0.274212</td>\n",
              "      <td>0.334545</td>\n",
              "      <td>0.257648</td>\n",
              "      <td>0.274212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PassiveAggressiveClassifier</th>\n",
              "      <td>0.256864</td>\n",
              "      <td>0.268775</td>\n",
              "      <td>0.253551</td>\n",
              "      <td>0.208847</td>\n",
              "      <td>0.268775</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                               Train F1  ...  Train Accuracy\n",
              "Classifier                               ...                \n",
              "DecisionTreeClassifier         1.000000  ...        1.000000\n",
              "RandomForestClassifier         1.000000  ...        1.000000\n",
              "ExtraTreesClassifier           1.000000  ...        1.000000\n",
              "BaggingClassifier              0.989060  ...        0.989067\n",
              "MLPClassifier                  0.632518  ...        0.638024\n",
              "AdaBoostClassifier             0.395866  ...        0.411002\n",
              "LinearSVC                      0.358644  ...        0.384546\n",
              "LinearDiscriminantAnalysis     0.357678  ...        0.377416\n",
              "QuadraticDiscriminantAnalysis  0.299384  ...        0.311626\n",
              "SGDClassifier                  0.290910  ...        0.309468\n",
              "GaussianNB                     0.261152  ...        0.274212\n",
              "PassiveAggressiveClassifier    0.256864  ...        0.268775\n",
              "\n",
              "[12 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzBF3L-dwVlA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "outputId": "d9d91d1b-6db0-4376-e410-1efd77ff6c77"
      },
      "source": [
        "# display df\n",
        "display(test_metrics_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Test F1</th>\n",
              "      <th>Test Recall</th>\n",
              "      <th>Test Precision</th>\n",
              "      <th>Test Balanced Accuracy</th>\n",
              "      <th>Test Accuracy</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Classifier</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>MLPClassifier</th>\n",
              "      <td>0.538490</td>\n",
              "      <td>0.544989</td>\n",
              "      <td>0.541062</td>\n",
              "      <td>0.494314</td>\n",
              "      <td>0.544989</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RandomForestClassifier</th>\n",
              "      <td>0.508290</td>\n",
              "      <td>0.529920</td>\n",
              "      <td>0.531945</td>\n",
              "      <td>0.456896</td>\n",
              "      <td>0.529920</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ExtraTreesClassifier</th>\n",
              "      <td>0.486475</td>\n",
              "      <td>0.517848</td>\n",
              "      <td>0.525762</td>\n",
              "      <td>0.424343</td>\n",
              "      <td>0.517848</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BaggingClassifier</th>\n",
              "      <td>0.481312</td>\n",
              "      <td>0.494817</td>\n",
              "      <td>0.486969</td>\n",
              "      <td>0.446951</td>\n",
              "      <td>0.494817</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DecisionTreeClassifier</th>\n",
              "      <td>0.399402</td>\n",
              "      <td>0.397627</td>\n",
              "      <td>0.402288</td>\n",
              "      <td>0.373485</td>\n",
              "      <td>0.397627</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AdaBoostClassifier</th>\n",
              "      <td>0.374788</td>\n",
              "      <td>0.390803</td>\n",
              "      <td>0.387382</td>\n",
              "      <td>0.352975</td>\n",
              "      <td>0.390803</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LinearSVC</th>\n",
              "      <td>0.338137</td>\n",
              "      <td>0.368237</td>\n",
              "      <td>0.379080</td>\n",
              "      <td>0.292754</td>\n",
              "      <td>0.368237</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LinearDiscriminantAnalysis</th>\n",
              "      <td>0.331651</td>\n",
              "      <td>0.354925</td>\n",
              "      <td>0.362353</td>\n",
              "      <td>0.283442</td>\n",
              "      <td>0.354925</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SGDClassifier</th>\n",
              "      <td>0.268803</td>\n",
              "      <td>0.284230</td>\n",
              "      <td>0.291566</td>\n",
              "      <td>0.283936</td>\n",
              "      <td>0.284230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>QuadraticDiscriminantAnalysis</th>\n",
              "      <td>0.261570</td>\n",
              "      <td>0.277975</td>\n",
              "      <td>0.389372</td>\n",
              "      <td>0.279473</td>\n",
              "      <td>0.277975</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PassiveAggressiveClassifier</th>\n",
              "      <td>0.257145</td>\n",
              "      <td>0.271642</td>\n",
              "      <td>0.254910</td>\n",
              "      <td>0.207243</td>\n",
              "      <td>0.271642</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GaussianNB</th>\n",
              "      <td>0.242343</td>\n",
              "      <td>0.258924</td>\n",
              "      <td>0.323098</td>\n",
              "      <td>0.249174</td>\n",
              "      <td>0.258924</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                Test F1  ...  Test Accuracy\n",
              "Classifier                               ...               \n",
              "MLPClassifier                  0.538490  ...       0.544989\n",
              "RandomForestClassifier         0.508290  ...       0.529920\n",
              "ExtraTreesClassifier           0.486475  ...       0.517848\n",
              "BaggingClassifier              0.481312  ...       0.494817\n",
              "DecisionTreeClassifier         0.399402  ...       0.397627\n",
              "AdaBoostClassifier             0.374788  ...       0.390803\n",
              "LinearSVC                      0.338137  ...       0.368237\n",
              "LinearDiscriminantAnalysis     0.331651  ...       0.354925\n",
              "SGDClassifier                  0.268803  ...       0.284230\n",
              "QuadraticDiscriminantAnalysis  0.261570  ...       0.277975\n",
              "PassiveAggressiveClassifier    0.257145  ...       0.271642\n",
              "GaussianNB                     0.242343  ...       0.258924\n",
              "\n",
              "[12 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icX5ZMlnwPZz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rcBBSUHvqYv"
      },
      "source": [
        "---------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0WIFmVLCJnv"
      },
      "source": [
        "# SMOTE \n",
        "\n",
        "Check Some Classifiers "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7R4NDyQhGgvA",
        "outputId": "0e48c703-c6d7-405d-ae0d-66e1a3bebac5"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, log_loss , recall_score , f1_score, precision_score , roc_auc_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.linear_model import PassiveAggressiveClassifier\n",
        "from sklearn.semi_supervised import LabelPropagation\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.tree import ExtraTreeClassifier\n",
        "\n",
        "classifiers = [\n",
        "    KNeighborsClassifier(3),\n",
        "    DecisionTreeClassifier(),\n",
        "    RandomForestClassifier(),\n",
        "    AdaBoostClassifier(),\n",
        "    GradientBoostingClassifier(),\n",
        "    GaussianNB(),\n",
        "    LinearDiscriminantAnalysis(),\n",
        "    QuadraticDiscriminantAnalysis(),\n",
        "    LinearSVC(),\n",
        "    SGDClassifier(),\n",
        "    MLPClassifier(),\n",
        "    PassiveAggressiveClassifier(),\n",
        "    LabelPropagation(),\n",
        "    ExtraTreesClassifier(),\n",
        "    BaggingClassifier(),\n",
        "    DecisionTreeClassifier(),\n",
        "    ExtraTreeClassifier()    ]\n",
        "\n",
        "\n",
        "# list to hold for dataframe\n",
        "classifier_name_list = []\n",
        "train_acc_list = []\n",
        "train_bacc_list = []\n",
        "test_acc_list = []\n",
        "test_bacc_list = []\n",
        "train_recall_list = []\n",
        "test_recall_list = []\n",
        "train_precision_list = []\n",
        "test_precision_list = []\n",
        "train_f1_list = []\n",
        "test_f1_list = []\n",
        "\n",
        "\n",
        "for clf in classifiers:\n",
        "    clf.fit(X_train_scale_smote, y_train_smote)\n",
        "    name = clf.__class__.__name__\n",
        "    \n",
        "    print(\"=\"*50)\n",
        "    print(name)\n",
        "    \n",
        "    print('****Results****')\n",
        "\n",
        "    # Test Predictions\n",
        "    test_predictions = clf.predict(X_test_scale_pca)\n",
        "\n",
        "    # Test Metrics\n",
        "    acc            = accuracy_score(y_test, test_predictions)\n",
        "    bal_acc        = balanced_accuracy_score(y_test, test_predictions)\n",
        "    recall_test    = recall_score(y_test, test_predictions, average = 'weighted')\n",
        "    f1_test        = f1_score(y_test, test_predictions ,  average = 'weighted')\n",
        "    precision_test = precision_score(y_test, test_predictions,  average = 'weighted') \n",
        "\n",
        "\n",
        "\n",
        "    # Train Predictions\n",
        "    train_predictions = clf.predict(X_train_scale_smote)\n",
        "\n",
        "    # Train Metrics\n",
        "    train_acc       = accuracy_score(y_train_smote, train_predictions)\n",
        "    train_bal_acc   = balanced_accuracy_score(y_train_smote, train_predictions)\n",
        "    recall_train    = recall_score(y_train_smote, train_predictions , average = 'weighted')\n",
        "    f1_train        = f1_score(y_train_smote, train_predictions ,  average = 'weighted')\n",
        "    precision_train = precision_score(y_train_smote, train_predictions,  average = 'weighted') \n",
        "\n",
        "    print(\"\\n\\nTest Classification Report\\n\")\n",
        "    print(classification_report(y_test, test_predictions))\n",
        "\n",
        "    # append to list to make a dataframe \n",
        "    classifier_name_list.append(name)\n",
        "    train_acc_list.append(train_acc)\n",
        "    test_acc_list.append(acc)\n",
        "\n",
        "    train_bacc_list.append(train_bal_acc)\n",
        "    test_bacc_list.append(bal_acc)\n",
        "\n",
        "    train_recall_list.append(recall_train)\n",
        "    test_recall_list.append(recall_test)\n",
        "\n",
        "    train_precision_list.append(precision_train)\n",
        "    test_precision_list.append(precision_test)\n",
        "\n",
        "    train_f1_list.append(f1_train)\n",
        "    test_f1_list.append(f1_test)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"=\"*50)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "KNeighborsClassifier\n",
            "****Results****\n",
            "\n",
            "\n",
            "Test Classification Report\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          Go       0.55      0.61      0.58       745\n",
            "      Turn 1       0.58      0.55      0.57      1322\n",
            "      Turn 2       0.65      0.46      0.54      1558\n",
            "      Walk 1       0.33      0.31      0.32       803\n",
            "      Walk 2       0.41      0.49      0.45       786\n",
            "         sit       0.29      0.47      0.36       553\n",
            "\n",
            "    accuracy                           0.48      5767\n",
            "   macro avg       0.47      0.48      0.47      5767\n",
            "weighted avg       0.51      0.48      0.49      5767\n",
            "\n",
            "==================================================\n",
            "DecisionTreeClassifier\n",
            "****Results****\n",
            "\n",
            "\n",
            "Test Classification Report\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          Go       0.68      0.61      0.65       745\n",
            "      Turn 1       0.54      0.56      0.55      1322\n",
            "      Turn 2       0.64      0.46      0.54      1558\n",
            "      Walk 1       0.29      0.31      0.30       803\n",
            "      Walk 2       0.36      0.41      0.38       786\n",
            "         sit       0.28      0.44      0.35       553\n",
            "\n",
            "    accuracy                           0.47      5767\n",
            "   macro avg       0.47      0.47      0.46      5767\n",
            "weighted avg       0.50      0.47      0.48      5767\n",
            "\n",
            "==================================================\n",
            "RandomForestClassifier\n",
            "****Results****\n",
            "\n",
            "\n",
            "Test Classification Report\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          Go       0.86      0.58      0.69       745\n",
            "      Turn 1       0.61      0.77      0.68      1322\n",
            "      Turn 2       0.73      0.58      0.65      1558\n",
            "      Walk 1       0.43      0.36      0.40       803\n",
            "      Walk 2       0.50      0.59      0.54       786\n",
            "         sit       0.39      0.51      0.44       553\n",
            "\n",
            "    accuracy                           0.59      5767\n",
            "   macro avg       0.59      0.57      0.57      5767\n",
            "weighted avg       0.61      0.59      0.59      5767\n",
            "\n",
            "==================================================\n",
            "AdaBoostClassifier\n",
            "****Results****\n",
            "\n",
            "\n",
            "Test Classification Report\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          Go       0.59      0.84      0.69       745\n",
            "      Turn 1       0.40      0.39      0.40      1322\n",
            "      Turn 2       0.53      0.35      0.42      1558\n",
            "      Walk 1       0.30      0.29      0.30       803\n",
            "      Walk 2       0.24      0.31      0.27       786\n",
            "         sit       0.18      0.20      0.19       553\n",
            "\n",
            "    accuracy                           0.39      5767\n",
            "   macro avg       0.37      0.40      0.38      5767\n",
            "weighted avg       0.40      0.39      0.39      5767\n",
            "\n",
            "==================================================\n",
            "GradientBoostingClassifier\n",
            "****Results****\n",
            "\n",
            "\n",
            "Test Classification Report\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          Go       0.80      0.79      0.79       745\n",
            "      Turn 1       0.59      0.59      0.59      1322\n",
            "      Turn 2       0.71      0.53      0.61      1558\n",
            "      Walk 1       0.40      0.32      0.35       803\n",
            "      Walk 2       0.39      0.55      0.45       786\n",
            "         sit       0.34      0.48      0.40       553\n",
            "\n",
            "    accuracy                           0.55      5767\n",
            "   macro avg       0.54      0.54      0.53      5767\n",
            "weighted avg       0.57      0.55      0.55      5767\n",
            "\n",
            "==================================================\n",
            "GaussianNB\n",
            "****Results****\n",
            "\n",
            "\n",
            "Test Classification Report\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          Go       0.17      0.73      0.28       745\n",
            "      Turn 1       0.28      0.09      0.14      1322\n",
            "      Turn 2       0.47      0.12      0.19      1558\n",
            "      Walk 1       0.19      0.11      0.14       803\n",
            "      Walk 2       0.22      0.30      0.25       786\n",
            "         sit       0.24      0.08      0.12       553\n",
            "\n",
            "    accuracy                           0.21      5767\n",
            "   macro avg       0.26      0.24      0.19      5767\n",
            "weighted avg       0.29      0.21      0.18      5767\n",
            "\n",
            "==================================================\n",
            "LinearDiscriminantAnalysis\n",
            "****Results****\n",
            "\n",
            "\n",
            "Test Classification Report\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          Go       0.33      0.50      0.39       745\n",
            "      Turn 1       0.34      0.20      0.25      1322\n",
            "      Turn 2       0.49      0.40      0.44      1558\n",
            "      Walk 1       0.30      0.32      0.31       803\n",
            "      Walk 2       0.27      0.39      0.32       786\n",
            "         sit       0.18      0.19      0.18       553\n",
            "\n",
            "    accuracy                           0.33      5767\n",
            "   macro avg       0.32      0.33      0.32      5767\n",
            "weighted avg       0.35      0.33      0.33      5767\n",
            "\n",
            "==================================================\n",
            "QuadraticDiscriminantAnalysis\n",
            "****Results****\n",
            "\n",
            "\n",
            "Test Classification Report\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          Go       0.23      0.72      0.35       745\n",
            "      Turn 1       0.56      0.15      0.24      1322\n",
            "      Turn 2       0.60      0.13      0.22      1558\n",
            "      Walk 1       0.32      0.38      0.35       803\n",
            "      Walk 2       0.26      0.54      0.35       786\n",
            "         sit       0.50      0.08      0.14       553\n",
            "\n",
            "    accuracy                           0.30      5767\n",
            "   macro avg       0.41      0.34      0.27      5767\n",
            "weighted avg       0.45      0.30      0.27      5767\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "LinearSVC\n",
            "****Results****\n",
            "\n",
            "\n",
            "Test Classification Report\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          Go       0.33      0.65      0.43       745\n",
            "      Turn 1       0.37      0.18      0.24      1322\n",
            "      Turn 2       0.51      0.46      0.48      1558\n",
            "      Walk 1       0.30      0.33      0.31       803\n",
            "      Walk 2       0.30      0.38      0.33       786\n",
            "         sit       0.22      0.14      0.17       553\n",
            "\n",
            "    accuracy                           0.36      5767\n",
            "   macro avg       0.34      0.36      0.33      5767\n",
            "weighted avg       0.37      0.36      0.35      5767\n",
            "\n",
            "==================================================\n",
            "SGDClassifier\n",
            "****Results****\n",
            "\n",
            "\n",
            "Test Classification Report\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          Go       0.32      0.83      0.47       745\n",
            "      Turn 1       0.38      0.16      0.22      1322\n",
            "      Turn 2       0.49      0.44      0.46      1558\n",
            "      Walk 1       0.19      0.13      0.16       803\n",
            "      Walk 2       0.27      0.26      0.26       786\n",
            "         sit       0.18      0.20      0.18       553\n",
            "\n",
            "    accuracy                           0.33      5767\n",
            "   macro avg       0.31      0.34      0.29      5767\n",
            "weighted avg       0.34      0.33      0.31      5767\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "MLPClassifier\n",
            "****Results****\n",
            "\n",
            "\n",
            "Test Classification Report\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          Go       0.75      0.55      0.63       745\n",
            "      Turn 1       0.67      0.65      0.66      1322\n",
            "      Turn 2       0.77      0.52      0.62      1558\n",
            "      Walk 1       0.41      0.38      0.40       803\n",
            "      Walk 2       0.42      0.63      0.50       786\n",
            "         sit       0.33      0.56      0.42       553\n",
            "\n",
            "    accuracy                           0.56      5767\n",
            "   macro avg       0.56      0.55      0.54      5767\n",
            "weighted avg       0.60      0.56      0.57      5767\n",
            "\n",
            "==================================================\n",
            "PassiveAggressiveClassifier\n",
            "****Results****\n",
            "\n",
            "\n",
            "Test Classification Report\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          Go       0.39      0.57      0.46       745\n",
            "      Turn 1       0.34      0.26      0.30      1322\n",
            "      Turn 2       0.43      0.23      0.30      1558\n",
            "      Walk 1       0.18      0.13      0.15       803\n",
            "      Walk 2       0.24      0.10      0.14       786\n",
            "         sit       0.12      0.41      0.18       553\n",
            "\n",
            "    accuracy                           0.27      5767\n",
            "   macro avg       0.28      0.28      0.25      5767\n",
            "weighted avg       0.31      0.27      0.26      5767\n",
            "\n",
            "==================================================\n",
            "LabelPropagation\n",
            "****Results****\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/semi_supervised/_label_propagation.py:201: RuntimeWarning: invalid value encountered in true_divide\n",
            "  probabilities /= normalizer\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Test Classification Report\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          Go       0.43      0.70      0.53       745\n",
            "      Turn 1       0.60      0.52      0.56      1322\n",
            "      Turn 2       0.65      0.45      0.53      1558\n",
            "      Walk 1       0.37      0.26      0.30       803\n",
            "      Walk 2       0.40      0.46      0.43       786\n",
            "         sit       0.27      0.41      0.33       553\n",
            "\n",
            "    accuracy                           0.47      5767\n",
            "   macro avg       0.45      0.47      0.45      5767\n",
            "weighted avg       0.50      0.47      0.47      5767\n",
            "\n",
            "==================================================\n",
            "ExtraTreesClassifier\n",
            "****Results****\n",
            "\n",
            "\n",
            "Test Classification Report\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          Go       0.84      0.48      0.61       745\n",
            "      Turn 1       0.59      0.77      0.67      1322\n",
            "      Turn 2       0.69      0.59      0.64      1558\n",
            "      Walk 1       0.37      0.34      0.36       803\n",
            "      Walk 2       0.50      0.56      0.53       786\n",
            "         sit       0.39      0.46      0.42       553\n",
            "\n",
            "    accuracy                           0.57      5767\n",
            "   macro avg       0.56      0.53      0.54      5767\n",
            "weighted avg       0.59      0.57      0.57      5767\n",
            "\n",
            "==================================================\n",
            "BaggingClassifier\n",
            "****Results****\n",
            "\n",
            "\n",
            "Test Classification Report\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          Go       0.76      0.59      0.66       745\n",
            "      Turn 1       0.57      0.71      0.63      1322\n",
            "      Turn 2       0.70      0.54      0.61      1558\n",
            "      Walk 1       0.37      0.36      0.36       803\n",
            "      Walk 2       0.44      0.48      0.46       786\n",
            "         sit       0.39      0.48      0.43       553\n",
            "\n",
            "    accuracy                           0.55      5767\n",
            "   macro avg       0.54      0.53      0.53      5767\n",
            "weighted avg       0.57      0.55      0.55      5767\n",
            "\n",
            "==================================================\n",
            "DecisionTreeClassifier\n",
            "****Results****\n",
            "\n",
            "\n",
            "Test Classification Report\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          Go       0.71      0.62      0.66       745\n",
            "      Turn 1       0.53      0.56      0.55      1322\n",
            "      Turn 2       0.65      0.47      0.54      1558\n",
            "      Walk 1       0.31      0.32      0.31       803\n",
            "      Walk 2       0.36      0.42      0.39       786\n",
            "         sit       0.30      0.46      0.36       553\n",
            "\n",
            "    accuracy                           0.48      5767\n",
            "   macro avg       0.48      0.47      0.47      5767\n",
            "weighted avg       0.51      0.48      0.49      5767\n",
            "\n",
            "==================================================\n",
            "ExtraTreeClassifier\n",
            "****Results****\n",
            "\n",
            "\n",
            "Test Classification Report\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          Go       0.38      0.33      0.36       745\n",
            "      Turn 1       0.37      0.37      0.37      1322\n",
            "      Turn 2       0.50      0.33      0.40      1558\n",
            "      Walk 1       0.24      0.26      0.25       803\n",
            "      Walk 2       0.24      0.29      0.26       786\n",
            "         sit       0.16      0.28      0.21       553\n",
            "\n",
            "    accuracy                           0.32      5767\n",
            "   macro avg       0.32      0.31      0.31      5767\n",
            "weighted avg       0.35      0.32      0.33      5767\n",
            "\n",
            "==================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "id": "nz2lOmwMua-f",
        "outputId": "e5cf16ba-84d9-4bde-acc9-47e7f6ee6db5"
      },
      "source": [
        "metrics_df = pd.DataFrame()\n",
        "\n",
        "\n",
        "metrics_df['Classifier'] = classifier_name_list\n",
        "\n",
        "# F1 Score First \n",
        "metrics_df['Train F1'] = train_f1_list\n",
        "metrics_df['Test F1'] = test_f1_list \n",
        "\n",
        "# Recall\n",
        "metrics_df['Train Recall'] = train_recall_list\n",
        "metrics_df['Test Recall'] = test_recall_list\n",
        "\n",
        "# Precision \n",
        "metrics_df['Train Precision'] = train_precision_list\n",
        "metrics_df['Test Precision'] = test_precision_list\n",
        "\n",
        "# Bal Acc\n",
        "metrics_df['Train Balanced Accuracy'] = train_bacc_list\n",
        "metrics_df['Test Balanced Accuracy'] = test_bacc_list\n",
        "\n",
        "# Accuracy \n",
        "metrics_df['Train Accuracy'] = train_acc_list\n",
        "metrics_df['Test Accuracy'] = test_acc_list \n",
        "\n",
        "\n",
        "metrics_df.sort_values(\"Test F1\" , ascending=False , inplace=True)\n",
        "metrics_df.set_index('Classifier' , inplace=True)\n",
        "\n",
        "# display df\n",
        "display(metrics_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Train F1</th>\n",
              "      <th>Test F1</th>\n",
              "      <th>Train Recall</th>\n",
              "      <th>Test Recall</th>\n",
              "      <th>Train Precision</th>\n",
              "      <th>Test Precision</th>\n",
              "      <th>Train Balanced Accuracy</th>\n",
              "      <th>Test Balanced Accuracy</th>\n",
              "      <th>Train Accuracy</th>\n",
              "      <th>Test Accuracy</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Classifier</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>MLPClassifier</th>\n",
              "      <td>0.632518</td>\n",
              "      <td>0.538490</td>\n",
              "      <td>0.638024</td>\n",
              "      <td>0.544989</td>\n",
              "      <td>0.637700</td>\n",
              "      <td>0.541062</td>\n",
              "      <td>0.587750</td>\n",
              "      <td>0.494314</td>\n",
              "      <td>0.638024</td>\n",
              "      <td>0.544989</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RandomForestClassifier</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.508290</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.529920</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.531945</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.456896</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.529920</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ExtraTreesClassifier</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.486475</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.517848</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.525762</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.424343</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.517848</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BaggingClassifier</th>\n",
              "      <td>0.989060</td>\n",
              "      <td>0.481312</td>\n",
              "      <td>0.989067</td>\n",
              "      <td>0.494817</td>\n",
              "      <td>0.989146</td>\n",
              "      <td>0.486969</td>\n",
              "      <td>0.986900</td>\n",
              "      <td>0.446951</td>\n",
              "      <td>0.989067</td>\n",
              "      <td>0.494817</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DecisionTreeClassifier</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.399402</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.397627</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.402288</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.373485</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.397627</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AdaBoostClassifier</th>\n",
              "      <td>0.395866</td>\n",
              "      <td>0.374788</td>\n",
              "      <td>0.411002</td>\n",
              "      <td>0.390803</td>\n",
              "      <td>0.413745</td>\n",
              "      <td>0.387382</td>\n",
              "      <td>0.366316</td>\n",
              "      <td>0.352975</td>\n",
              "      <td>0.411002</td>\n",
              "      <td>0.390803</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LinearSVC</th>\n",
              "      <td>0.358644</td>\n",
              "      <td>0.338137</td>\n",
              "      <td>0.384546</td>\n",
              "      <td>0.368237</td>\n",
              "      <td>0.421402</td>\n",
              "      <td>0.379080</td>\n",
              "      <td>0.319141</td>\n",
              "      <td>0.292754</td>\n",
              "      <td>0.384546</td>\n",
              "      <td>0.368237</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LinearDiscriminantAnalysis</th>\n",
              "      <td>0.357678</td>\n",
              "      <td>0.331651</td>\n",
              "      <td>0.377416</td>\n",
              "      <td>0.354925</td>\n",
              "      <td>0.397676</td>\n",
              "      <td>0.362353</td>\n",
              "      <td>0.310020</td>\n",
              "      <td>0.283442</td>\n",
              "      <td>0.377416</td>\n",
              "      <td>0.354925</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SGDClassifier</th>\n",
              "      <td>0.290910</td>\n",
              "      <td>0.268803</td>\n",
              "      <td>0.309468</td>\n",
              "      <td>0.284230</td>\n",
              "      <td>0.304447</td>\n",
              "      <td>0.291566</td>\n",
              "      <td>0.294325</td>\n",
              "      <td>0.283936</td>\n",
              "      <td>0.309468</td>\n",
              "      <td>0.284230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>QuadraticDiscriminantAnalysis</th>\n",
              "      <td>0.299384</td>\n",
              "      <td>0.261570</td>\n",
              "      <td>0.311626</td>\n",
              "      <td>0.277975</td>\n",
              "      <td>0.424868</td>\n",
              "      <td>0.389372</td>\n",
              "      <td>0.316648</td>\n",
              "      <td>0.279473</td>\n",
              "      <td>0.311626</td>\n",
              "      <td>0.277975</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PassiveAggressiveClassifier</th>\n",
              "      <td>0.256864</td>\n",
              "      <td>0.257145</td>\n",
              "      <td>0.268775</td>\n",
              "      <td>0.271642</td>\n",
              "      <td>0.253551</td>\n",
              "      <td>0.254910</td>\n",
              "      <td>0.208847</td>\n",
              "      <td>0.207243</td>\n",
              "      <td>0.268775</td>\n",
              "      <td>0.271642</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GaussianNB</th>\n",
              "      <td>0.261152</td>\n",
              "      <td>0.242343</td>\n",
              "      <td>0.274212</td>\n",
              "      <td>0.258924</td>\n",
              "      <td>0.334545</td>\n",
              "      <td>0.323098</td>\n",
              "      <td>0.257648</td>\n",
              "      <td>0.249174</td>\n",
              "      <td>0.274212</td>\n",
              "      <td>0.258924</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                               Train F1  ...  Test Accuracy\n",
              "Classifier                               ...               \n",
              "MLPClassifier                  0.632518  ...       0.544989\n",
              "RandomForestClassifier         1.000000  ...       0.529920\n",
              "ExtraTreesClassifier           1.000000  ...       0.517848\n",
              "BaggingClassifier              0.989060  ...       0.494817\n",
              "DecisionTreeClassifier         1.000000  ...       0.397627\n",
              "AdaBoostClassifier             0.395866  ...       0.390803\n",
              "LinearSVC                      0.358644  ...       0.368237\n",
              "LinearDiscriminantAnalysis     0.357678  ...       0.354925\n",
              "SGDClassifier                  0.290910  ...       0.284230\n",
              "QuadraticDiscriminantAnalysis  0.299384  ...       0.277975\n",
              "PassiveAggressiveClassifier    0.256864  ...       0.271642\n",
              "GaussianNB                     0.261152  ...       0.258924\n",
              "\n",
              "[12 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGs_oxsnGhkP"
      },
      "source": [
        "---------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHdchGKGdJiu"
      },
      "source": [
        "SVM "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwV1T9qIda7_"
      },
      "source": [
        "from sklearn.svm import SVC"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-HIwcmkzdKsJ",
        "outputId": "8e4fba8f-2d11-4662-8073-113280db7d55"
      },
      "source": [
        "svc_clf = SVC(C = 0.3)\n",
        "\n",
        "\n",
        "svc_clf.fit(X_train_scale_pca , y_train)\n",
        "\n",
        "# Predict Train\n",
        "preds_svc = svc_clf.predict(X_train_scale_pca)\n",
        "\n",
        "# Classification report \n",
        "print(\"Train Data\")\n",
        "print(classification_report(y_train,preds_svc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Data\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          Go       0.76      0.52      0.62       745\n",
            "      Turn 1       0.64      0.88      0.74      3091\n",
            "      Turn 2       0.61      0.81      0.70      2431\n",
            "      Walk 1       0.69      0.46      0.55      1522\n",
            "      Walk 2       0.65      0.40      0.50      1777\n",
            "         sit       0.66      0.42      0.51      1627\n",
            "\n",
            "    accuracy                           0.64     11193\n",
            "   macro avg       0.67      0.58      0.60     11193\n",
            "weighted avg       0.65      0.64      0.62     11193\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ucj8PBeweA4M",
        "outputId": "c06ab072-87a6-4979-ff7e-5c291663150e"
      },
      "source": [
        "# Predict Test\n",
        "preds_svc = svc_clf.predict(X_test_scale_pca)\n",
        "\n",
        "print(\"Test Data\")\n",
        "# Classification report \n",
        "print(classification_report(y_test,preds_svc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Data\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          Go       0.87      0.44      0.59       745\n",
            "      Turn 1       0.52      0.80      0.63      1322\n",
            "      Turn 2       0.62      0.64      0.63      1558\n",
            "      Walk 1       0.40      0.32      0.35       803\n",
            "      Walk 2       0.49      0.38      0.43       786\n",
            "         sit       0.37      0.32      0.34       553\n",
            "\n",
            "    accuracy                           0.54      5767\n",
            "   macro avg       0.54      0.48      0.50      5767\n",
            "weighted avg       0.56      0.54      0.53      5767\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BfxEcLW9e4SE"
      },
      "source": [
        "---------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HuGIj0Y6fn8w"
      },
      "source": [
        "svc_clf_smote = SVC(C = 0.3)\n",
        "\n",
        "\n",
        "svc_clf.fit(X_train_scale_smote , y_train_smote)\n",
        "\n",
        "# Predict Train\n",
        "preds_svc = svc_clf.predict(X_train_scale_smote)\n",
        "\n",
        "# Classification report \n",
        "print(\"Train Data\")\n",
        "print(classification_report(y_train , preds_svc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RZV7lz-e5UL"
      },
      "source": [
        "def holdout_checker_svc(smote = False ):\n",
        "\n",
        "  # Read in Fresh Data to see what predictions looks like\n",
        "  from google.colab import files\n",
        "  uploaded_test = files.upload()\n",
        "\n",
        "  # getting keys, which is file names of csv\n",
        "  val_file_name = [key for key in uploaded_test.keys()]\n",
        "\n",
        "  # read in csv \n",
        "  signal_test = pd.read_csv(val_file_name[0])\n",
        "\n",
        "\n",
        "  # Getting X_train & y_train\n",
        "  X_data = signal_test.drop(['Unnamed: 0' , 'Label_segment' , 'Participant_ID' , 'Participant_Run','X_Acc_Move_FFT_EnergyBands', \t'Y_Acc_Move_FFT_EnergyBands', \t'Z_Acc_Move_FFT_EnergyBands' ], axis = 1)\n",
        "  y_data = signal_test['Label_segment'].values\n",
        "\n",
        "  # scale with already fit ss \n",
        "  X_data_scale = ss.transform(X_data)\n",
        "\n",
        "  # feature selection\n",
        "  X_data_scale_pca = pca.transform(X_data_scale)\n",
        "\n",
        "\n",
        "\n",
        "  # if selecting smote trained model\n",
        "  if smote == True:\n",
        "    hold_preds = model_smote.predict(X_data_scale_fs)\n",
        "\n",
        "  # else non-smote trained model\n",
        "  else:\n",
        "    hold_preds = svc_clf.predict(X_data_scale_pca)\n",
        "\n",
        "  # take max of predictions \n",
        "  #max_predictions = np.argmax(hold_preds, axis=1)\n",
        "\n",
        "  # metrics \n",
        "  print(\"\\n---------------------- Metrics ----------------------------------------\")\n",
        "\n",
        "  print(\"Accuracy : \\t\\t\" ,accuracy_score(y_data, hold_preds))\n",
        "  print(\"Balanced Accuracy : \\t\" , balanced_accuracy_score(y_data, hold_preds))\n",
        "  #print(\"F1 Score : \\t\\t\" , f1_score(y_data, hold_preds, average='weighted'))\n",
        "\n",
        "\n",
        "  # set up labels \n",
        "  LABELS = ['Go', 'Turn1',  'Turn2' , 'Walk1', 'Walk2', 'Sit']\n",
        "\n",
        "  # classification report \n",
        "  print(\"\\n------------------- HoldOut Classification Report ---------------\")\n",
        "  print(classification_report(y_data , hold_preds))\n",
        "  print(\" \")\n",
        "\n",
        "  # confusion matrix\n",
        "  confusion_matrix_out = metrics.confusion_matrix(y_data, hold_preds )\n",
        "\n",
        "  plt.figure(figsize=(14, 10))\n",
        "  sns.heatmap(confusion_matrix_out, xticklabels=LABELS, yticklabels=LABELS, annot=True ,fmt=\"d\" );\n",
        "  plt.title(\"HoldOut Data Confusion matrix\")\n",
        "  plt.ylabel('True label')\n",
        "  plt.xlabel('Predicted label')\n",
        "  plt.show()\n",
        "\n",
        "  # lastly just printing actual predictions\n",
        "  print(\"\\n0 = Go \\t\\t 1 = Turn 1 \\t 2 = Turn 2\")\n",
        "  print(\"\\n3 = Walk 1 \\t 4 = Walk 2 \\t 5 = Sit\")\n",
        "\n",
        "  print(\" \")\n",
        "  print(hold_preds)\n",
        "\n",
        "  print(Counter(hold_preds))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XxS7yqLyfTYN",
        "outputId": "2836e973-ad2c-43a8-ed23-2f9765e4b5eb"
      },
      "source": [
        "holdout_checker_knn()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e72b678a-0977-4243-9b6e-b76b01fe8678\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e72b678a-0977-4243-9b6e-b76b01fe8678\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving 86_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RCP to 86_7_Participant_SlideSize_10_Handcrafted_Features_DF_Resampled_RCP (1)\n",
            "\n",
            "---------------------- Metrics ----------------------------------------\n",
            "Accuracy : \t\t 0.5708333333333333\n",
            "Balanced Accuracy : \t 0.3029373423044575\n",
            "\n",
            "------------------- HoldOut Classification Report ---------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          Go       0.00      0.00      0.00         9\n",
            "      Turn 1       0.49      0.85      0.62        75\n",
            "      Turn 2       0.72      0.85      0.78        82\n",
            "      Walk 1       0.25      0.04      0.07        24\n",
            "      Walk 2       0.00      0.00      0.00        21\n",
            "         sit       0.50      0.07      0.12        29\n",
            "\n",
            "    accuracy                           0.57       240\n",
            "   macro avg       0.33      0.30      0.27       240\n",
            "weighted avg       0.49      0.57      0.48       240\n",
            "\n",
            " \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1008x720 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "0 = Go \t\t 1 = Turn 1 \t 2 = Turn 2\n",
            "\n",
            "3 = Walk 1 \t 4 = Walk 2 \t 5 = Sit\n",
            " \n",
            "['Turn 1' 'Turn 1' 'Turn 1' 'Walk 1' 'Walk 1' 'Turn 2' 'Turn 1' 'Turn 1'\n",
            " 'Walk 1' 'Walk 1' 'Turn 1' 'Turn 1' 'Turn 1' 'Turn 1' 'Turn 1' 'Turn 1'\n",
            " 'Turn 1' 'Turn 1' 'Turn 1' 'Turn 1' 'Turn 1' 'Turn 1' 'Turn 1' 'Turn 1'\n",
            " 'Turn 1' 'Turn 2' 'Turn 1' 'Turn 1' 'Turn 1' 'Turn 1' 'Turn 1' 'Turn 1'\n",
            " 'Turn 1' 'Turn 1' 'Turn 1' 'Turn 1' 'Turn 1' 'Turn 1' 'Turn 1' 'Turn 1'\n",
            " 'Turn 2' 'Turn 2' 'Turn 2' 'Turn 1' 'Turn 2' 'Turn 1' 'Turn 1' 'Turn 1'\n",
            " 'Turn 1' 'Turn 1' 'Turn 1' 'Turn 1' 'Turn 1' 'Turn 2' 'Turn 1' 'Turn 1'\n",
            " 'Turn 1' 'Turn 1' 'Turn 1' 'Turn 1' 'Turn 1' 'Turn 1' 'Turn 1' 'Turn 1'\n",
            " 'Turn 1' 'Turn 1' 'Turn 1' 'Turn 1' 'Turn 1' 'Turn 1' 'Turn 1' 'Turn 1'\n",
            " 'Turn 1' 'Turn 1' 'Turn 2' 'Turn 1' 'Turn 1' 'Turn 1' 'Turn 1' 'Turn 1'\n",
            " 'Turn 1' 'Turn 1' 'Turn 1' 'Turn 1' 'Turn 1' 'Turn 1' 'Turn 1' 'Turn 1'\n",
            " 'Turn 1' 'Turn 1' 'Turn 1' 'Turn 1' 'Turn 1' 'Turn 1' 'Turn 1' 'Turn 1'\n",
            " 'Turn 1' 'Turn 1' 'Turn 1' 'Turn 1' 'Turn 1' 'Turn 1' 'Turn 1' 'sit'\n",
            " 'Turn 2' 'Turn 2' 'Turn 2' 'sit' 'Turn 1' 'Turn 2' 'Turn 2' 'Turn 2'\n",
            " 'Turn 2' 'Turn 2' 'Turn 2' 'Turn 2' 'Turn 2' 'Turn 2' 'Turn 2' 'Turn 1'\n",
            " 'Turn 1' 'Go' 'Turn 1' 'Turn 2' 'Turn 2' 'Turn 2' 'Turn 2' 'Turn 1'\n",
            " 'Turn 2' 'Turn 2' 'Turn 2' 'Turn 2' 'Turn 2' 'Turn 2' 'Go' 'Go' 'Go' 'Go'\n",
            " 'Turn 1' 'Turn 1' 'Turn 1' 'Turn 1' 'Turn 1' 'Turn 1' 'Turn 2' 'Turn 2'\n",
            " 'Turn 2' 'Turn 2' 'Turn 2' 'Turn 2' 'Turn 2' 'Turn 2' 'Turn 2' 'Turn 2'\n",
            " 'Turn 2' 'Turn 2' 'Turn 2' 'Turn 2' 'Turn 2' 'Turn 2' 'Turn 2' 'Turn 2'\n",
            " 'Turn 2' 'Turn 2' 'Turn 2' 'Turn 2' 'Turn 2' 'Turn 2' 'Turn 2' 'Turn 2'\n",
            " 'Turn 2' 'Turn 2' 'Turn 2' 'Turn 2' 'Turn 2' 'Turn 2' 'Turn 1' 'Turn 2'\n",
            " 'Turn 2' 'Turn 1' 'Turn 2' 'Turn 2' 'Turn 2' 'Turn 2' 'Turn 2' 'Turn 2'\n",
            " 'Turn 2' 'Turn 2' 'Turn 2' 'Turn 2' 'Turn 2' 'Turn 2' 'Turn 2' 'Turn 2'\n",
            " 'Turn 2' 'Turn 2' 'Turn 2' 'Turn 2' 'Turn 2' 'Turn 2' 'Turn 2' 'Turn 2'\n",
            " 'Turn 2' 'Turn 2' 'Turn 2' 'Turn 2' 'Turn 2' 'Turn 2' 'Turn 2' 'Turn 2'\n",
            " 'Turn 2' 'sit' 'Turn 2' 'Turn 1' 'Turn 1' 'sit' 'Turn 1' 'Turn 1'\n",
            " 'Turn 1' 'Turn 1' 'Turn 1' 'Turn 1' 'Turn 1' 'Turn 1' 'Turn 1' 'Turn 1'\n",
            " 'Turn 1' 'Turn 1' 'Turn 1' 'Turn 1' 'Turn 1' 'Turn 1' 'Turn 1' 'Turn 1'\n",
            " 'Turn 1' 'Turn 1' 'Turn 1' 'Turn 1' 'Turn 1' 'Turn 1']\n",
            "Counter({'Turn 1': 130, 'Turn 2': 97, 'Go': 5, 'Walk 1': 4, 'sit': 4})\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}